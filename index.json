[{"Description":"docker GreenPlum 源码编译","date":"2024-01-05","permalink":"https://askyx.github.io/posts/build/","section":"posts","summary":"shell # git clone --depth=1 https://hub.fgit.cf/greenplum-db/gpdb.git -b 7.0.0 docker run -itd --name gpdb --cap-add=SYS_PTRACE --privileged=true --hostname vscode --mount type=bind,source=/home/wen/gpdb,target=/workspaces/gpdb runner bash docker exec -it -u vscode gpdb bash sudo service ssh start ssh-keygen cat ~/.ssh/id_rsa.pub \u0026gt;\u0026gt; ~/.ssh/authorized_keys chmod 700 ~/.ssh chmod 644 ~/.ssh/authorized_keys sudo chown vscode:vscode -R /workspaces/gpdb # 不支持其他文件夹编译，只能在gpdb目录下 cd /workspaces/gpdb sudo apt install -y libkrb5-dev krb5-config iproute2 libossp-uuid-dev libapr1-dev libyaml-dev libxerces-c-dev less rsync pip libevent-dev ./configure --with-perl --enable-orca --with-python --with-libxml --with-gssapi --enable-debug CFLAGS=-O0 CXXFLAGS=-O0 --prefix=/home/vscode/.build make -j64 \u0026amp;\u0026amp; make install # .bashrc 文件 cat \u0026gt; /home/vscode/.bashrc \u0026lt;\u0026lt;EOF source /home/vscode/.build/greenplum_path.sh alias psql=\u0026#39;psql -p 7000\u0026#39; alias gpstart=\u0026#39;gpstart -d /workspaces/gpdb/gpAux/gpdemo/datadirs/qddir/demoDataDir-1\u0026#39; alias gpstop=\u0026#39;gpstop -d /workspaces/gpdb/gpAux/gpdemo/datadirs/qddir/demoDataDir-1\u0026#39; alias sqps=\u0026#34;echo \u0026#39;USER PID PPID VSZ CMD\u0026#39; ; ps -eo user,pid,ppid,vsize,cmd | grep -E \u0026#39;postgres\u0026#39; \u0026#34; EOF source /home/vscode/.","tags":["数据库","Postgres","GreenPlum","源码编译"],"title":"源码编译 GreenPlum 速通版"},{"Description":"docker OpenTenBase 源码编译","date":"2024-01-05","permalink":"https://askyx.github.io/posts/build/","section":"posts","summary":"shell # git clone --depth=1 https://hub.fgit.cf/OpenTenBase/OpenTenBase.git docker run -itd --name tbase --cap-add=SYS_PTRACE --privileged=true --hostname vscode --mount type=bind,source=/home/wen/OpenTenBase,target=/workspaces/OpenTenBase runner bash docker exec -it -u vscode tbase bash sudo service ssh start ssh-keygen cat ~/.ssh/id_rsa.pub \u0026gt;\u0026gt; ~/.ssh/authorized_keys chmod 700 ~/.ssh chmod 644 ~/.ssh/authorized_keys sudo chown vscode:vscode -R /workspaces/OpenTenBase mkdir -p .build/making mkdir .data cd .build/making /workspaces/OpenTenBase/configure --prefix=/home/vscode/.build --enable-user-switch --with-openssl --with-ossp-uuid --enable-alltype-distri CFLAGS=\u0026#34;-fgnu89-inline -g -O0\u0026#34; make -j64 \u0026amp;\u0026amp; make install \u0026amp;\u0026amp; cd contrib \u0026amp;\u0026amp; make -j64 \u0026amp;\u0026amp; make install cd ~ mkdir pgxc_ctl # 写入下面的模板 touch pgxc_ctl/pg.conf # ssh localhost pgxc_ctl -c pg.conf init all createdb -p 6011 vscode # .bashrc 文件 此外，/home/vscode/.","tags":["数据库","Postgres","OpenTenBase","源码编译"],"title":"源码编译 OpenTenBase 速通版"},{"Description":"docker 源码编译 dockerfile 模板","date":"2024-01-05","permalink":"https://askyx.github.io/posts/env_common/","section":"posts","summary":"docker file # FROM ubuntu LABEL description=\u0026#34;build xxxxx regress env\u0026#34; # x86_64 RUN sed -i s@/archive.ubuntu.com/@/mirrors.aliyun.com/@g /etc/apt/sources.list # arm RUN sed -i s@/ports.ubuntu.com/@/mirrors.tuna.tsinghua.edu.cn/@g /etc/apt/sources.list RUN sed -i s@/security.ubuntu.com/@/mirrors.tuna.tsinghua.edu.cn/@g /etc/apt/sources.list RUN apt-get update \u0026amp;\u0026amp; apt-get upgrade -y RUN apt-get install -y flex bison g++ gcc gdb make libzstd-dev libxml2-dev libcurl4-openssl-dev vim libbz2-dev libperl-dev software-properties-common \\ pkg-config libreadline-dev python3-dev libldap-dev zlib1g-dev openssh-server iputils-ping libxslt-dev libpam-dev libssl-dev libreadline6-dev \\ libssh2-1-dev cmake ninja-build sudo locales # GP # libkrb5-dev krb5-config iproute2 libossp-uuid-dev libapr1-dev libyaml-dev libxerces-c-dev less rsync pip # RUN pip install gssapi psycopg2 psutil -i https://pypi.tuna.tsinghua.edu.cn/simple RUN sudo locale-gen en_US.UTF-8 RUN apt-get clean \u0026amp;\u0026amp; apt-get autoclean RUN useradd -ms /bin/bash vscode \u0026amp;\u0026amp; echo \u0026#39;vscode ALL=(ALL) NOPASSWD:ALL\u0026#39; \u0026gt;\u0026gt; /etc/sudoers RUN echo \u0026#39;export LANG=en_US.","tags":["数据库","源码编译"],"title":"源码编译环境准备文件"},{"Description":"重点名词解释，不一定是不知道，只是一下子想不起来，有个提示可以辅助回忆，自用","date":"2023-12-21","permalink":"https://askyx.github.io/posts/one_line/","section":"posts","summary":" 操作系统 # NUMA 多核架构中CPU通过BUS访问RAM，所以有了距离上的区别，带来了速度上的差距，NUMA 通过划分RAM和CPU为不同的node，通过配置不同的程序运行策略来解决此问题 由于默认策略为优先使用同一个node，所以Mysql 在使用大量内存的时候，内存占用多个node，导致内存频繁swap 数据库 # 解释执行\n编译执行\n避免物化 消除虚函数的跳转执行 向量化\nAdaptive Execution of Compiled Queries\n先解释执行，同时异步编译， 执行完部分数据之后， 再检测是否需要编译执行 pipeline\n部分表达式是非阻塞的，不需要物化(从寄存器替换出去)，使用codegen编译为一个完整的执行流程 ","tags":null,"title":"名词一行解释"},{"Description":"cmake 速查模板，自用","date":"2023-08-09","permalink":"https://askyx.github.io/posts/cmake/","section":"posts","summary":"cmake 速记模板 # 添加第三方库 # include(FetchContent) function(get_third_dep dep_name dep_url dep_tag) FetchContent_Declare(${dep_name} QUIET SOURCE_DIR ${CMAKE_BINARY_DIR}/_deps/src/${dep_name} BINARY_DIR ${CMAKE_BINARY_DIR}/_deps/build/${dep_name} SUBBUILD_DIR ${CMAKE_BINARY_DIR}/_deps/sub/${dep_name} GIT_REPOSITORY ${dep_url} GIT_TAG ${dep_tag} GIT_PROGRESS TRUE GIT_SHALLOW TRUE ) FetchContent_MakeAvailable(${dep_name}) endfunction(get_third_dep) get_third_dep(spdlog https://ghproxy.com/https://github.com/gabime/spdlog.git v1.11.0) get_third_dep(googletest https://ghproxy.com/https://github.com/google/googletest.git release-1.12.1) get_third_dep(asio https://ghproxy.com/https://github.com/chriskohlhoff/asio.git asio-1-28-0) # 添加 head only 库 add_library(asio INTERFACE) target_include_directories(asio INTERFACE ${CMAKE_BINARY_DIR}/_deps/src/asio/asio/include ) target_compile_definitions(asio INTERFACE ASIO_STANDALONE ASIO_NO_DEPRECATED ) target_link_libraries(asio INTERFACE pthread ) 添加 yacc lex 编译 # find_package(FLEX REQUIRED) find_package(BISON 3.5.0 REQUIRED) bison_target(parser ${PROJECT_SOURCE_DIR}/src/parser/parser.yy ${PROJECT_SOURCE_DIR}/src/parser/parser.cpp # DEFINES_FILE ${PROJECT_SOURCE_DIR}/src/include/parser/parser.hpp COMPILE_FLAGS ${bison_flags}) flex_target(scanner ${PROJECT_SOURCE_DIR}/src/parser/scanner.lex ${PROJECT_SOURCE_DIR}/src/parser/scanner.cpp) ADD_FLEX_BISON_DEPENDENCY(scanner parser) add_library(ASKY_lib SHARED ${ASKY_SRC} ${BISON_parser_OUTPUTS} ${FLEX_scanner_OUTPUTS} ) 添加单元测试 # function(add_cosmos_test test_name test_file) add_executable(${test_name} ${test_file}) target_link_libraries(${test_name} PRIVATE gtest gtest_main ASKY_lib) add_test(NAME ${test_name} COMMAND ${test_name}) endfunction(add_cosmos_test) foreach(TEST_SOURCE_FILE ${ASKY_TEST_SRC}) file(RELATIVE_PATH ASKY_TEST_CPP_REL \u0026#34;${PROJECT_SOURCE_DIR}/test\u0026#34; ${TEST_SOURCE_FILE}) get_filename_component(NOISEPAGE_TEST_DIR ${ASKY_TEST_CPP_REL} DIRECTORY) get_filename_component(NOISEPAGE_TEST ${TEST_SOURCE_FILE} NAME_WE) add_cosmos_test(${NOISEPAGE_TEST} ${TEST_SOURCE_FILE}) endforeach() 添加 自定义 command # # clang-format add_custom_target(format COMMAND git diff --name-only --diff-filter=d --cached \u0026#39;*.","tags":["C/C++","cmake","模板库"],"title":"cmake 速查模板"},{"Description":"深度优化探索文章的读书笔记","date":"2023-05-08","permalink":"https://askyx.github.io/posts/optimizer/","section":"posts","summary":" 1. 逻辑优化 # 1. 子查询提升 # exist 相关子链接会被提升，非相关子链接不会进行优化， 但是会生成 initplan，只需要执行一次 any 相关子查询不会提升，非相关子查询才能进行优化，实际上any的非相关子查询隐含一个外部引用的条件， 实际上还是相关子查询 如果是 join 条件中的子链接，则需要遵守 \u0026ldquo;any 的 左边需要是对应链接类型中不含输出的那一边\u0026rdquo;， 例如 left join 要求 any 的 左边只能是关联右边的属性，因为如果是左边，提升之后左边现在有约束条件，可能不会全部输出 子链接存在复杂表达式不支持提升，如cte，聚合操作等 子查询类似 2. 表达式优化 # 常量折叠 谓词规范 1. 简化 2. 约束条件拉平 3. 提取公共项 3. group 杂项消除 # 如果group 中包含 主键，则可以直接消除其他\n4. 外连接消除 # 可空测有条件约束绝对不为空，则外连接可转换为内连接 ","tags":null,"title":"Postgres 技术内幕，Optimizer过程分析"},{"Description":"宏模板，自用","date":"2023-02-22","permalink":"https://askyx.github.io/posts/defineinc/","section":"posts","summary":"前置知识 # C语言宏的定义和宏的使用方法\n变长参数 # 这里输出的是相同类型的参数日志，不同的需要特殊处理，或者直接自定义输出格式 缺点： 参数类型固定 #include \u0026lt;stdio.h\u0026gt; double xxa = 1.0f; double xxb = 1.2f; double xxc = 1.3f; double xxd = 1.4f; double xxe = 1.5f; double xxf = 1.6f; double xxg = 1.7f; double xxh = 1.8f; double xxi = 1.9f; #define DUMPVAR(VAR) #VAR \u0026#34;(%.2lf)\u0026#34; #define FL_DOARG1(a, ...) DUMPVAR(a) #define FL_DOARG2(a, v, ...) FL_DOARG1(a) \u0026#34;, \u0026#34; FL_DOARG1(v, __VA_ARGS__) #define FL_DOARG3(a, v, ...) FL_DOARG1(a) \u0026#34;, \u0026#34; FL_DOARG2(v, __VA_ARGS__) #define FL_DOARG4(a, v, ...) FL_DOARG1(a) \u0026#34;, \u0026#34; FL_DOARG3(v, __VA_ARGS__) #define FL_DOARG5(a, v, ...) FL_DOARG1(a) \u0026#34;, \u0026#34; FL_DOARG4(v, __VA_ARGS__) #define FL_DOARG6(a, v, ...) FL_DOARG1(a) \u0026#34;, \u0026#34; FL_DOARG5(v, __VA_ARGS__) #define FL_DOARG7(a, v, .","tags":["C/C++","宏","日志"],"title":"宏使用模板速查"},{"Description":"pg中各个算子的代价计算","date":"2023-02-17","permalink":"https://askyx.github.io/posts/cost/","section":"posts","summary":"表和各个index的物理结构及数据操作 统计信息 cost 计算 demo 选择率的计算 基表cost index cost pageinspect\nPostgreSQL索引系列文章链接汇总\n统计信息与选择率与代价计算 # 当前统计信息会收集下面数据，可以使用视图 pg_stats 查看，在使用统计信息的时候，使用相关信息计算选择率\n* Histogram：直方图，这个数据结构用来描述数据的分布，当前pg中计算的是等高直方图，在每一个范围内，数据数量均等 * Most common values: 出现次数最多的一组值。将它们踢出直方图可以减少极端值造成的估算误差。 * Distinct Number: 即这一列一共有多少个不同的值。值得注意的是 PostgreSQL 并没有为直方图的 每个 bucket 维护一个 bucket 本身的不同的值。 * NULL values: 有多少行的值为 NULL。因为 NULL 是一个非常特殊的值，所以也会将 NULL 单独拿出来进行维护 * Average value width in bytes: 列平均长度，记录这个值可以用来对 SQL 使用的内存大小进行估算，以及 对 IO 开销进行更细致的估算。 * Correlation: 索引和主键（或者说 row id）之间的顺序相关程度。正相关为1，负相关为-1，实际上是统计的协方差 选择率 # 选择率用于计算约束条件过滤之后大的数据量大小，主要用于代价计算中估算执行代价，选择率的计算主要会使用到直方图统计信息和MCV\n对于等值约束，只会使用 MCV 进行计算，MCV是统计的高频值 首先需要判断列 isunique，如果是，则此时是没有mcv ，直接使用公式 selec = 1.0 / rel-\u0026gt;tuples 计算选择率 否则如果条件中常数刚好是 MCV ，则直接返回当前 MCV 对应的概率即可 否则他假设数据是均匀分布，先去除 MCV 和 nullfac 的概率之后，然后再除以 otherdistinct，计算公式为 selec = (1.0 - sumcommon - nullfrac) / otherdistinct 如下例子，100 不是 MCV，对应上面第三条规则\nesoye=# explain select * from t1 where a = 100; QUERY PLAN ------------------------------------------------------------------- Bitmap Heap Scan on t1 (cost=5.","tags":null,"title":"执行计划代价计算规则梳理"},{"Description":"Postgres 执行器 及其扩展 总结","date":"2023-02-10","permalink":"https://askyx.github.io/posts/postgres_executor/","section":"posts","summary":"Tue Feb 7 10:19:24 CST 2023 重构， 不想文章变成无用的流水线\n节点 # refs # openGauss数据库源码解析系列文章——执行器解析（二\nPostgresql查询执行模块README笔记\n执行方式分为两大类，一类是 utility 执行，用于ddl等，底层直接对接某个函数，一类是 dml 算子执行，按树的形式执行，这里关注 dml 算子\n总的四大类\n控制节点 扫描节点 物化节点 链接节点 每一个算子分为\n初始化\n对应函数以 ExecInitxxx 构造 state 结构体，执行时候使用，exestate 也是树形结构，和 plantree 一一对应，保存运行时的关键信息 打开表或者其他资源 初始化子节点 初始化表达式上下文 初始化表达式 初始化tuple type 初始化project 这里其他的都好理解，但是tuple相关的操作每个算子调用的函数看起来大同小异，但是细节作用不一样 一般 execstats 和 plan tree 是一一对应的，但是也是有例外的，如分区裁剪的时候，确定不需要的分区，init 的时候直接不生成对应的子树的 state 执行 主要的执行逻辑，其中会涉及到表达式的执行 清理 清理资源，之前初始化的时候申请的空间 Rescan command to reset a node and make it generate its output sequence over again.\n一个简单总结\nCreateQueryDesc ExecutorStart CreateExecutorState creates per-query context switch to per-query context to run ExecInitNode AfterTriggerBeginQuery ExecInitNode --- recursively scans plan tree ExecInitNode recurse into subsidiary nodes CreateExprContext creates per-tuple context ExecInitExpr ExecutorRun ExecProcNode --- recursively called in per-query context ExecEvalExpr --- called in per-tuple context ResetExprContext --- to free memory ExecutorFinish ExecPostprocessPlan --- run any unfinished ModifyTable nodes AfterTriggerEndQuery ExecutorEnd ExecEndNode --- recursively releases resources FreeExecutorState frees per-query context and child contexts FreeQueryDesc 表达式 # 介绍了pg表达式的具体的运行机制","tags":["数据库","Postgres","执行器"],"title":"Postgres Executor"},{"Description":"事务分析记录，源码分析，关键技术点简记，唬人专用","date":"2023-02-08","permalink":"https://askyx.github.io/posts/tx/","section":"posts","summary":"事务基础 # ACID 事务演进 隔离级别 MVCC 2pl 主流数据库实现 PG事务 # pg高链接数导致tps下降 1|2 # 简单总结\n更新xmin的ping-pong问题，缓存失效，之前的结构设计不合理，xid存放位置不连续，且xmin每次都需要从 pgxact 中获取，此值会被频繁修改 修改 事务相关的组织格式，xids 现在单独存放在数组中 使用 xactCompletionCount 进行事务计算，快照原则上只要没有变化，则不需要重新获取，所以在事务提交或者事务abort的时候，进行自增，只有检测到 xactCompletionCount 变化了才重新获取快照 之前需要 xmin 用于vacuum ，现在使用新机制判断，现在在循环中遍历 xids 取 min ， 不对立刻同步其他的 min， 所以这是一个粗略值，在之后可以简单进行判断，如果在之后获得了比 min 更大的值，才进行精确判断，且更新 min 无锁算法提交事务，减少proc加锁时间，提升并发 # 无锁算法是利用CPU的原子操作实现的数据结构和算法来解决原来只能用锁才能解决的并发控制问题\nCAS Fetch-and-add Test-and-set 内存屏障 # 内存屏障相关函数，包括 compiler barrier 和 read/write barrier 语义上的布尔值（PG代码里叫flag，具体实现上可能映射到一个字节，或一个整数）的原子操作，包括：\npg_atomic_init_flag，初始化一个flag pg_atomic_test_set_flag, Test-And-Set，这也是flag的唯一支持的原子 操作函数 pg_atomic_unlocked_test_flag，检查flag是否没有被设置 pg_atomic_clear_flag，清除已设置的flag 32位无符号整数的原子操作，包括：\npg_atomic_init_u32, pg_atomic_read_u32, pg_atomic_write_u32，初始化、读、写操作 pg_atomic_exchange_u32，给原子变量赋值并返回原值 pg_atomic_compare_exchange_u32, 32位无符号整数的CAS操作，比较原子变量和另一个变量的值， 如果相等就赋一个新值到原子变量里，返回一个布尔值标识是否进行了赋值操作 pg_atomic_fetch_add_u32, pg_atomic_fetch_sub_u32, pg_atomic_fetch_and_u32, pg_atomic_fetch_or_u32 对某个原子变量进行加、减、与、或操作，并返回变量改变之前的值 pg_atomic_add_fetch_u32, pg_atomic_sub_fetch_u32 对某个原子变量进行加、减操作，并返回变量改变之后的值 64位无符号整数的原子操作，与32位的实现的操作函数相似，只是实现的是64位版本，这里需要注意的是， 64位版本并不保证所有平台的都支持，目前在PostgreSQL的源代码中还没有被使用。\n实际案例： # pg中事务在结束之后，需要设置 PGPROC 中的事务信息，确保其他 session 中再次获取 snapshot 的时候，完成事务不会在活跃列表中。此时会使用 ProcArrayLock 尝试对 ProcArray 加排他锁，此时锁竞争严重，后来对此进行优化，使用无锁编程技术，批量进行xid的重置，具体函数为 ProcArrayEndTransaction\nProcArrayGroupClearXid 大意为: 如果竞争锁失败，则把 xid 加入一个数组中，有 leader 进行此数组的 xid 的重置工作，此过程没有加锁，全部使用原子操作 * [v] 主要知道 PGPROC 的具体的组织结构 * [v] 需要只要事务结束的操作函数 ProcArrayEndTransactionInternal 的大致原因 * [v] 需要知道无锁编程带来的收益以及大致的无锁编程技术，以及锁实现 PGPROC数据结构","tags":null,"title":"事务知识简记"},{"Description":"bison 文档重点记录","date":"2022-11-17","permalink":"https://askyx.github.io/posts/note/","section":"posts","summary":"note # As Bison reads tokens, it pushes them onto a stack along with their semantic values. The stack is called the parser stack. Pushing a token is traditionally called shifting. When the last n tokens and groupings shifted match the components of a grammar rule, they can be combined according to that rule. This is called reduction The lookahead token is stored in the variable yychar. Its semantic value and location, if any, are stored in the variables yylval and yylloc. This situation, where either a shift or a reduction would be valid, is called a shift/reduce conflict, Bison is designed to resolve these conflicts by choosing to shift, unless otherwise directed by operator precedence declarations.","tags":null,"title":"Bison Note"},{"Description":"libpqxx分析","date":"2022-11-08","permalink":"https://askyx.github.io/posts/libpqxx/","section":"posts","summary":"定位 # c++的客户端接口，官方指定，特点时使用比较激进的C++实现，最新代码编译需要支持C++17，下个版本需要C++20，和其他pg对外接口实现类似的功能，但是由于使用C++实现，所以源码不多，可以用来快速的熟悉此类工具的大致的结构，后期可以去过一遍ODBC\n01 # 直接全局搜索extern \u0026quot;C\u0026quot;，可以知道它使用了那些libpq的数据结构和接口，grep -A5 -r 'extern \u0026quot;C\u0026quot;' ./*的结果表明次项目只使用了3个关键结构以及一个必要得头文件\nextern \u0026#34;C\u0026#34; { struct pg_conn; struct pg_result; struct pgNotify; } 官方案例为\n#include \u0026lt;iostream\u0026gt; #include \u0026lt;pqxx/pqxx\u0026gt; int main() { try { // Connect to the database. You can have multiple connections open // at the same time, even to the same database. pqxx::connection c; std::cout \u0026lt;\u0026lt; \u0026#34;Connected to \u0026#34; \u0026lt;\u0026lt; c.dbname() \u0026lt;\u0026lt; \u0026#39;\\n\u0026#39;; // Start a transaction. A connection can only have one transaction // open at the same time, but after you finish a transaction, you // can start a new one on the same connection. pqxx::work tx{c}; // Query data of two columns, converting them to std::string and // int respectively.","tags":null,"title":"Libpqxx"},{"Description":"","date":"2022-11-01","permalink":"https://askyx.github.io/posts/memctx/","section":"posts","summary":" 内存上下文 # https://smartkeyerror.com/PostgreSQL-MemoryContext 源码主要在mctx.c中，主要是目的是设置工作空间，避免重复的在系统上申请资源，且为了避免异常情况下的内存泄露问题，所以实现了内存上下文\n目前有三种底层的实现 AllocSet(常规的内存分配机制，先分配block，之后再从block上分配chunk，分配得内存一般不会释放，而是使用空闲链表管理) Generation(新加，内存生命周期相近的时候使用，目前只在gist 和 replication 模块使用) Slab(分配大小等大的chunk，目前只在replication 模块使用) 更多的是因为频繁的malloc会导致内存碎片，且由于malloc需要额外的空间记录head和foot的位置，所以还存在的问题就是空间的浪费，另外最大的问题是内存泄漏问题，使用指针在方法间传递不容易管理 大概类似c++的内存管理方法，把 # ","tags":null,"title":"内存管理"},{"Description":"RocksDB 源码总结分析","date":"2022-10-21","permalink":"https://askyx.github.io/posts/rocksdb/","section":"posts","summary":"note1\nslice # 和levelDB类似，无太大变化\nPinnableSlice # http://kernelmaker.github.io/Rocksdb_pinnableslice\n主要作用是延长数据生命周期，减少数据拷贝。PinnableSlice中记录数据的指针，使用的时候通过指针进行解引用。不需要从最底层进行数据的copy，数据的生命周期使用Reset和其析构函数确定，此时调用cleanup注册的cleanup函数对数据进行处理，\n这种思想在其他地方存在，例如trafodion的queue_entry，或者是向量化中的延迟物化技术，本质上都是避免直接进行数据拷贝，只进行指针传递，只是RocksDB中处理更进一步，添加了委托清理等逻辑 Status # 无变化，只是添加了些特殊状态\nArena # 在levelDB的基础上，添加了大空间的支持，对于huge_blocks。使用mmap申请大空间，使用huge_blocks_保存，和普通的block类似，只是申请和释放方法不一样。\nchar* Arena::AllocateFromHugePage(size_t bytes) { #ifdef MAP_HUGETLB if (hugetlb_size_ == 0) { return nullptr; } // Reserve space in `huge_blocks_` before calling `mmap`. // Use `emplace_back()` instead of `reserve()` to let std::vector manage its // own memory and do fewer reallocations. // // - If `emplace_back` throws, no memory leaks because we haven\u0026#39;t called // `mmap` yet. // - If `mmap` throws, no memory leaks because the vector will be cleaned up // via RAII. huge_blocks_.emplace_back(nullptr /* addr */, 0 /* length */); void* addr = mmap(nullptr, bytes, (PROT_READ | PROT_WRITE), (MAP_PRIVATE | MAP_ANONYMOUS | MAP_HUGETLB), -1, 0); if (addr == MAP_FAILED) { return nullptr; } huge_blocks_.","tags":["源码阅读","RocksDB","存储引擎"],"title":"RocksDB源码分析"},{"Description":"Postgres parser 模块解析，目的是为了学习parser实现机制。编译原理以及bison和flex的使用","date":"2022-10-10","permalink":"https://askyx.github.io/posts/parser/","section":"posts","summary":"BISON # 1.2 From Formal Rules to Bison Input\nTerminal Nonterminal 1.3 Semantic Values A formal grammar selects tokens only by their classifications each token in a Bison grammar has both a token kind and a semantic value 强类型，有类型和值的区别\n1.4 Semantic Actions The action says how to produce the semantic value\n1.5 Writing GLR Parsers 略，默认是LR文法，但是有RR和SR冲突，所以为了不那么严格限制语法，在一定程度上允许冲突。这里不做了解\n1.6 Locations produce verbose and useful error messages\n1.7 Bison Output: the Parser Implementation File The tokens come from a function called the lexical analyzer. The Bison parser calls the lexical analyzer each time it wants a new token supply some additional functions. One is the lexical analyzer.","tags":["数据库","Postgres","Parser","编译原理"],"title":"postgres Parser"},{"Description":"PG 中锁的分析","date":"2022-09-28","permalink":"https://askyx.github.io/posts/locks/","section":"posts","summary":"SpinLock # 使用tas实现的自旋锁。\nwhile (TAS_SPIN(lock)) { perform_spin_delay(\u0026amp;delayStatus); } perform_spin_delay(SpinDelayStatus *status) { /* CPU-specific delay each time through the loop */ SPIN_DELAY(); /* Block the process every spins_per_delay tries */ if (++(status-\u0026gt;spins) \u0026gt;= spins_per_delay) { if (++(status-\u0026gt;delays) \u0026gt; NUM_DELAYS) s_lock_stuck(status-\u0026gt;file, status-\u0026gt;line, status-\u0026gt;func); if (status-\u0026gt;cur_delay == 0) /* first time to delay? */ status-\u0026gt;cur_delay = MIN_DELAY_USEC; pg_usleep(status-\u0026gt;cur_delay); /* increase delay by a random fraction between 1X and 2X */ status-\u0026gt;cur_delay += (int) (status-\u0026gt;cur_delay * pg_prng_double(\u0026amp;pg_global_prng_state) + 0.5); /* wrap back to minimum delay when max is exceeded */ if (status-\u0026gt;cur_delay \u0026gt; MAX_DELAY_USEC) status-\u0026gt;cur_delay = MIN_DELAY_USEC; status-\u0026gt;spins = 0; } } 如果没有tas，则使用信号量实现，属于最底层的锁","tags":["数据库","Postgres","LOCK"],"title":"Locks"},{"Description":"AntDB VACUUM 流程","date":"2022-09-26","permalink":"https://askyx.github.io/posts/vacuum/","section":"posts","summary":"语句的具体信息参考pg说明文档\nhttp://postgres.cn/docs/12/routine-vacuuming.html http://postgres.cn/docs/12/sql-vacuum.html http://postgres.cn/docs/12/sql-analyze.html antdb对功能进行增强，可以cn上执行语句然后收集统计信息，更新cn的元数据信息等操作，且数据变动会同步到其他cn节点和gtm 节点\nvacuum # cn执行vacuum的入口为ExecVacuum，具体执行函数为vacuum，此函数在后续会被其他节点调用，用来更新本节点的元数据信息，所以他按不同的角色执行不同的代码逻辑\n对于当前执行语句的cn，主要任务为\n执行语句 使用ExecClusterCustomFunction通知其他节点进行vacuum操作 进行数据中转 从dn收集统计信息的数据 转发到其他cn和gtm以及slave 其他cn和gtm\n接受cn的消息，启动vacuum操作，但是由于本地没有数据，所以主要目的是为了能执行相同的代码逻辑，进行元数据更新 接收cn的数据，更新本节点元数据信息 dn\n接受cn的消息，启动vacuum操作 更新本节点的元数据信息 发送数据到cn 大致流程如下图\n具体的数据交互过程以vacuum t1为例，如下图\nrecvfrom(11, \u0026#34;Q\\0\\0\\0\\20vacuum t1;\\0\u0026#34;, 8192, 0, NULL, NULL) = 17 sendto(10, \u0026#34;\\1\\0\\0\\0 \\0\\0\\0\\nX\\243\\335\\215\\214\\2\\0\\352\\266\\233\\335\\215\\214\\2\\0w2\\0\\0\\0\\0\\0\\0\u0026#34;, 32, 0, NULL, 0) = 32 sendto(17, \u0026#34;p\\0\\0\\0\\234\\v\\377\\377\\377\\20\\0\\0\\0cluster_vacuum\\0\\0\\1\\0\\0\u0026#34;..., 157, 0, NULL, 0) = 157 sendto(15, \u0026#34;p\\0\\0\\0\\234\\v\\377\\377\\377\\20\\0\\0\\0cluster_vacuum\\0\\0\\1\\0\\0\u0026#34;..., 157, 0, NULL, 0) = 157 sendto(50, \u0026#34;p\\0\\0\\0\\234\\v\\377\\377\\377\\20\\0\\0\\0cluster_vacuum\\0\\0\\1\\0\\0\u0026#34;..., 157, 0, NULL, 0) = 157 sendto(49, \u0026#34;p\\0\\0\\0\\234\\v\\377\\377\\377\\20\\0\\0\\0cluster_vacuum\\0\\0\\1\\0\\0\u0026#34;..., 157, 0, NULL, 0) = 157 recvfrom(17, \u0026#34;W\\0\\0\\0\\7\\1\\0\\0\u0026#34;, 16384, 0, NULL, NULL) = 8 recvfrom(15, \u0026#34;W\\0\\0\\0\\7\\1\\0\\0\u0026#34;, 16384, 0, NULL, NULL) = 8 recvfrom(50, \u0026#34;W\\0\\0\\0\\7\\1\\0\\0\u0026#34;, 16384, 0, NULL, NULL) = 8 recvfrom(49, \u0026#34;W\\0\\0\\0\\7\\1\\0\\0\u0026#34;, 16384, 0, NULL, NULL) = 8 sendto(17, \u0026#34;d\\0\\0\\0\\23\\200\\232\\2\\0\\0public\\0t1\\0\u0026#34;, 20, 0, NULL, 0) = 20 TCP b3b87dd4fb6c:59200-\u0026gt;b3b87dd4fb6c:65032 (ESTABLISHED) cn1 sendto(15, \u0026#34;d\\0\\0\\0\\23\\200\\232\\2\\0\\0public\\0t1\\0\u0026#34;, 20, 0, NULL, 0) = 20 TCP b3b87dd4fb6c:46498-\u0026gt;b3b87dd4fb6c:65011 (ESTABLISHED) gtm sendto(50, \u0026#34;d\\0\\0\\0\\23\\200\\232\\2\\0\\0public\\0t1\\0\u0026#34;, 20, 0, NULL, 0) = 20 TCP b3b87dd4fb6c:54044-\u0026gt;b3b87dd4fb6c:65013 (ESTABLISHED) dn1 sendto(49, \u0026#34;d\\0\\0\\0\\23\\200\\232\\2\\0\\0public\\0t1\\0\u0026#34;, 20, 0, NULL, 0) = 20 TCP b3b87dd4fb6c:55242-\u0026gt;b3b87dd4fb6c:65014 (ESTABLISHED) dn2 recvfrom(50, \u0026#34;d\\0\\0\\0\\266T\\5\\0\\0\\0\\0new_rel_pages\\0\\377\\377\\377\\377\\0\\0\\0\u0026#34;.","tags":["数据库","Postgres","VACUUM"],"title":"vacuum 和 analyze 过程分析"},{"Description":"Postgres_xc 源码编译，集群环境搭建","date":"2022-07-27","permalink":"https://askyx.github.io/trash/postgres_xc_build/","section":"trash","summary":"源码编译 # 下载源码，解压，这里尝试使用-g编译源码，目的是为了可以调试源码\n编译中有flex的一个问题，提示版本不正确，且即使使用export指定FLEX，编译的时候还是会用yylex的一个重定义的错误，从postgres主线上找到解决的patch，这里网上没有太多有用的资料，所以有尝试的建议先直接编译，如果遇到相同的问题再使用下面的解决方法。\ngcc -DPGXC -Wall -Wmissing-prototypes -Wpointer-arith -Wdeclaration-after-statement -Werror=vla -Wendif-labels -Wmissing-format-attribute -Wimplicit-fallthrough=3 -Wcast-function-type -Wformat-security -fno-strict-aliasing -fwrapv -fexcess-precision=standard -Wno-format-truncation -Wno-stringop-truncation -g -I. -I. -I../../../src/include -D_GNU_SOURCE -c -o gram.o gram.c gram.y: In function ‘base_yyparse’: gram.y:9025:11: warning: implicit declaration of function ‘superuser’ [-Wimplicit-function-declaration] 9025 | if (!superuser()) | ^~~~~~~~~ scan.c: At top level: gram.c:68:25: error: conflicting types for ‘base_yylex’ 68 | #define yylex base_yylex | ^~~~~~~~~~ scan.c:9108:12: note: in expansion of macro ‘yylex’ 9108 | extern int yylex \\ | ^~~~~ In file included from gram.y:60: ../../../src/include/parser/gramparse.h:66:12: note: previous declaration of ‘base_yylex’ was here 66 | extern int base_yylex(YYSTYPE *lvalp, YYLTYPE *llocp, | ^~~~~~~~~~ gram.","tags":null,"title":"Postgres_xc 源码编译及环境搭建"},{"Description":"本文从源码级别进行优化器的分析，对Postgres优化器代码调研，具体包括他的数据结构，以及具体的代码架构实现以及核心算法等","date":"2022-07-22","permalink":"https://askyx.github.io/posts/opt/","section":"posts","summary":"Postgres Optimizer Extend # 对文章的技术性验证\nThese directories take the Query structure returned by the parser, and generate a plan used by the executor. The /plan directory generates the actual output plan, the /path code generates all possible ways to join the tables, and /prep handles various preprocessing steps for special cases. /util is utility stuff. /geqo is the separate \u0026ldquo;genetic optimization\u0026rdquo; planner \u0026mdash; it does a semi-random search through the join tree space, rather than exhaustively considering all possible join trees. (But each join considered by /geqo is given to /path to create paths for, so we consider all possible implementation paths for each specific join pair even in GEQO mode.","tags":["数据库","Postgres","优化器"],"title":"Postgres Optimizer"},{"Description":"","date":"2022-07-21","permalink":"https://askyx.github.io/posts/storage/","section":"posts","summary":"存储 # 内存 # 共享内存\n本地内存\n缓存\n内存上下文\n缓存空间管理\n数据块的缓存，减少磁盘IO，有共享缓存和进程缓存\nCache\n数据块之外的缓存，例如系统表\n系统表缓存不会缓存整个表，是以block为单位缓存？ 虚拟文件描述符\n系统中文件有打开的上限，使用VFD可以突破这种限制，本质上是一个LRU缓存\n空闲空间定位\n快速定位磁盘中的空闲空间以插入数据\n进程间通信 使用共享内存或者信号量通信\n读取过程 # 从系统表中读取表的元数据信息构造元组信息 尝试从缓存读取数据 使用SMGR从磁盘读取数据到缓存中，SMGR是一个抽象层，用于实现不同存储介质的管理 SMGR和存储介质之间使用VFD来管理文件描述符，以突破系统的FD限制 标记删除，vacuum清理数据 FSM记录空闲空间 磁盘 # 表文件\nSMGR\nVFD\nFSM\nselect * from pg_relation_filepath(\u0026lsquo;idx\u0026rsquo;);\nPage 结构 # 工具汇总说明\ncreate extension pageinspect; get_raw_page(relname text, fork text, blkno int) 返回执行表的page，text指定类型，默认是main，代表普通page，使用fsm或者vm查看其他类型，可以省略 page_header(page bytea) 查看page头，输入是page数组，使用上面的函数的输出作为参数 fsm_page_contents(page bytea) returns text 查看fsm页面结构 SELECT fsm_page_contents(get_raw_page(\u0026#39;t1\u0026#39;, \u0026#39;fsm\u0026#39;, 0)); === HEAP相关 heap_page_items(page bytea) 查看page的具体信息 heap_tuple_infomask_flags(t_infomask integer, t_infomask2 integer) returns record 查看mask的具体含义，具体的使用方法为 SELECT * FROM heap_page_items(get_raw_page(\u0026#39;a\u0026#39;, 0)), LATERAL heap_tuple_infomask_flags(t_infomask, t_infomask2) WHERE t_infomask IS NOT NULL OR t_infomask2 IS NOT NULL order by lp desc; 输出为 t_infomask2 | t_infomask | t_hoff | t_bits | t_oid | t_data | raw_flags | combined_flags -------------+------------+--------+----------+-------+------------+--------------------------------------------------------------------------+---------------- 3 | 2305 | 24 | 10000000 | | \\x02000000 | {HEAP_HASNULL,HEAP_XMIN_COMMITTED,HEAP_XMAX_INVALID} | {} 8195 | 1281 | 24 | 10000000 | | \\x01000000 | {HEAP_HASNULL,HEAP_XMIN_COMMITTED,HEAP_XMAX_COMMITTED,HEAP_KEYS_UPDATED} | {} 主要目的是查看数据的mask的信息 === Btree相关 bt_metap(relname text) 查看btree元数据信息 bt_page_stats(relname text, blkno int) 查看btree page的统计信息 bt_page_items(relname text, blkno int) 或者 bt_page_items(page bytea) returns setof record 查看具体的信息，可以指定index或者直接使用page byte typedef struct PageHeaderData { /* XXX LSN is member of *any* block, not only page-organized ones */ PageXLogRecPtr pd_lsn; /* LSN: next byte after last byte of xlog record for last change to this page */ uint16 pd_checksum; /* checksum */ uint16 pd_flags; /* flag bits, see below */ LocationIndex pd_lower; /* offset to start of free space */ LocationIndex pd_upper; /* offset to end of free space */ LocationIndex pd_special; /* offset to start of special space */ uint16 pd_pagesize_version; TransactionId pd_prune_xid; /* oldest prunable XID, or zero if none */ ItemIdData pd_linp[FLEXIBLE_ARRAY_MEMBER]; /* line pointer array */ } PageHeaderData; void PageInit(Page page, Size pageSize, Size specialSize) { PageHeader p = (PageHeader) page; specialSize = MAXALIGN(specialSize); Assert(pageSize == BLCKSZ); Assert(pageSize \u0026gt; specialSize + SizeOfPageHeaderData); /* Make sure all fields of page are zero, as well as unused space */ MemSet(p, 0, pageSize); p-\u0026gt;pd_flags = 0; p-\u0026gt;pd_lower = SizeOfPageHeaderData; p-\u0026gt;pd_upper = pageSize - specialSize; p-\u0026gt;pd_special = pageSize - specialSize; PageSetPageSizeAndVersion(page, pageSize, PG_PAGE_LAYOUT_VERSION); /* p-\u0026gt;pd_prune_xid = InvalidTransactionId; done by above MemSet */ } 大小为 pageSize，默认为8k，最开始是PageHeader，","tags":["数据库","Postgres","存储"],"title":"Postgres Storage"},{"Description":"Postges 源码环境搭建，Ubuntu22，VSCode，docker","date":"2022-07-20","permalink":"https://askyx.github.io/posts/env/","section":"posts","summary":"源码编译 # 环境准备，这里使用Ubuntu22，执行命令sed -i s@/archive.ubuntu.com/@/mirrors.aliyun.com/@g /etc/apt/sources.list替换源，更新系统\n源码下载 直接下载最新源码，github上的源码每一个提交都保证是可编译运行的 git clone git@github.com:postgres/postgres.git 依赖安装 sudo apt-get -y install flex \\ bison \\ libreadline-dev \\ libssl-dev \\ libpam-dev \\ libxml2 \\ libxml2-dev \\ libxslt-dev \\ libldap-dev \\ libperl-dev \\ python3-dev\\ zlib1g-dev \\ libssh2-1-dev \\ gdb \\ c++ \\ gcc \\ make 编译 为了能使用gdb调试，需要使用debug模式调试，我自己之前编译的时候发现即使指定-enable-debug在编译的时候发现也使用了-O2，所以这里建议直接修改configure中的-O和-O2为-g，pg的数据指定-D的 位置，所以在一个环境中，一个编译出来的数据库可以有多个运行环境，或者可以有多个编译环境，多个运行环境，所以需要自己按需配置\n./configure --enable-depend --enable-cassert --enable-debug --prefix=/home/vscode/build make sudo make install 启动 /home/vscode/build/bin/initdb -D /home/vscode/data /home/vscode/build/bin/pg_ctl -D /home/vscode/data start /home/vscode/build/bin/pg_ctl -D /home/vscode/data stop /home/vscode/build/bin/psql -p 5432 使用TASK执行 # 可以直接配置上面的语句为VSCode的task，下载源码安装依赖之后直接run task即可直接编译运行\n// 替换自己的路径 { // See https://go.microsoft.com/fwlink/?LinkId=733558 // for the documentation about the tasks.json format \u0026#34;version\u0026#34;: \u0026#34;2.0.0\u0026#34;, \u0026#34;tasks\u0026#34;: [ { \u0026#34;label\u0026#34;: \u0026#34;build env\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;shell\u0026#34;, \u0026#34;command\u0026#34;:[ \u0026#34;mkdir -p /home/vscode/build/making \u0026amp;\u0026amp; \u0026#34;, \u0026#34;cd /home/vscode/build/making \u0026amp;\u0026amp; \u0026#34;, \u0026#34;/workspaces/postgres/configure --prefix=/home/vscode/build \u0026amp;\u0026amp; \u0026#34;, \u0026#34;make \u0026amp;\u0026amp; \u0026#34;, \u0026#34;make install\u0026#34; ] }, { \u0026#34;label\u0026#34;: \u0026#34;pg_start\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;shell\u0026#34;, \u0026#34;command\u0026#34;: \u0026#34;/home/vscode/build/bin/pg_ctl -D /home/vscode/data start\u0026#34;, }, { \u0026#34;label\u0026#34;: \u0026#34;pg_stop\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;shell\u0026#34;, \u0026#34;command\u0026#34;: \u0026#34;/home/vscode/build/bin/pg_ctl -D /home/vscode/data stop\u0026#34;, } ] } 编译完成之后如果执行psql报错没有vscode\u0026hellip;可以执行createdb vscode即可，之后可以正常使用","tags":null,"title":"Postgres源码编译及调试"},{"Description":"","date":"2022-07-20","permalink":"https://askyx.github.io/posts/note/","section":"posts","summary":"爬虫 # import requests from bs4 import BeautifulSoup prefix = \u0026#39;http://mysql.taobao.org\u0026#39; # 获取文章名和url（文章名,url） def query_name_url(url: str): resp = requests.get(url) soup = BeautifulSoup(resp.content.decode(\u0026#39;utf-8\u0026#39;), \u0026#34;html.parser\u0026#34;) tags = soup.findAll(\u0026#39;a\u0026#39;, {\u0026#39;target\u0026#39;: {\u0026#39;_blank\u0026#39;}}) urls = [v for v in tags if v[\u0026#39;href\u0026#39;].find(\u0026#39;/monthly/\u0026#39;) != -1] return [(str(v.string).strip(), prefix + v[\u0026#39;href\u0026#39;]) for v in urls] # 获取所有月报链接（月报名,url） def query_monthly_url(): resp = requests.get(\u0026#39;http://mysql.taobao.org/monthly/\u0026#39;) soup = BeautifulSoup(resp.content.decode(\u0026#39;utf-8\u0026#39;), \u0026#34;html.parser\u0026#34;) tags = soup.findAll(\u0026#39;a\u0026#39;, {\u0026#39;class\u0026#39;: {\u0026#39;main\u0026#39;}}) urls = [v for v in tags if v[\u0026#39;href\u0026#39;].find(\u0026#39;/monthly/\u0026#39;) != -1] return [(str(v.string).strip(), prefix + v[\u0026#39;href\u0026#39;]) for v in urls] # 获取所有文章名、URL和对应的月报链接（文章类型，文章名，url，月报名，url） def query_all_name_url(): result = [] monthly_urls = query_monthly_url() for data1 in monthly_urls: name_urls = query_name_url(data1[1]) for data2 in name_urls: result.","tags":["资源","数据库"],"title":"数据库文章资源汇总"},{"Description":"","date":"2022-06-10","permalink":"https://askyx.github.io/posts/note/","section":"posts","summary":"https://15445.courses.cs.cmu.edu/fall2021/notes/02-advancedsql.pdf\noutput control 控制输出结果，例如order，limit等 窗口函数 CTE Common Table Expressions，把一个语句的输出视为一张临时表参与下面的语句的运算 WITH cte1 (col1) AS (SELECT 1), cte2 (col2) AS (SELECT 2) SELECT * FROM cte1, cte2; Database Storage # 数据库的存储介质当前还是磁盘，IO慢 数据库存储要点之一是使用缓存维护数据在磁盘和内存之间的数据交换，以实现数据的快速读写 顺序读写和随机读写 顺序读写的意思是需要定位到读写的位置才能操作，例如链表。 随机读写的意思是可以直接定位到读写的位置，例如数组。 由于磁盘上随机读写速度不如顺序读写，所以当前数据库还是需要想办法使用顺序读写，例如LSM，GFS等架构都是因为这个原因导致的 磁盘和内存中数据的组织格式 # 数据全部在磁盘上，按page组织数据，内存中使用buffer pool维护缓存，磁盘中有一个page专门维护page的位置信息，使用的时候先读取此page到内存，然后 然后读取其他page到buffer pool，使用buffer pool维护page的置换情况，例如LRU，或者其他算法\n可以参考lab1和slide，还是比较明显的\nbuffer pool中的page可以用于上层的数据运算\n使用mmap可以完成类似的操作，但是实际上在使用中，如果在发生缺页中断的时候，mmap需要进行置换操作，所以会阻碍程序进程。且mmap是通用的组件，所以没有对数据库 的使用场景进行一些优化，\nYou never want to use mmap in your DBMS if you need to write. The DBMS (almost) always wants to control things itself and can do a better job at it since it knows more about the data being accessed and the queries being processed. The operating system is not your friend. 最好是需要什么就自己实现什么，\n数据组织形式 # 文件","tags":["课程","数据库","15445"],"title":"15445课程笔记"},{"Description":"","date":"2022-05-30","permalink":"https://askyx.github.io/posts/raft/","section":"posts","summary":"译文 原文 有用的飞书文档 和其他的算法相比 Strong leader\n日志只能从领导者发送到其他节点 Leader election\n随机计时器选举领导，在心跳机制上加上一些额外的工作 Membership changes\n角色变换 Replicated state machines # 复制状态机一般基于日志实现，通俗的理解只要所有的机器按照相同的顺序执行指令，那么每个节点的状态都是确定的，所以需要把指令日志复制到其他节点上去，这就是一致性算法的工作\n如果只是要求最终所有的节点都执行一样顺序的指令，而不要求实时性，则可以限定\n只有一个节点可以进行写操作，因为只有写操作才可以改变系统的状态 写节点同步指令到其他节点，最终所有节点指令顺序一致 一致性算法的共有特性\n安全性\n不会返回一个错误结果，只要是在非拜占庭错误情况下，包括网络延迟，乱序，丢包，分区，冗余等都可以保障正确性 可用性\n集群只要大多数机器可以正常通信，就可以确保可用，失败节点可以忽略或者后续恢复状态，大多数指的是半数以上 不依赖时序保证一致性\n时钟错误或者消息延迟只有在极端情况下才会导致可用性 慢节点不会影响消息的反馈，消息可以快速的响应 拜占庭将军问题\nPaxos # 难以理解 没有公认的可以实现的基础架构，大部分系统从Paxos开始，在遇到问题的时候自行想办法解决，导致最后的系统实现只能是类似Paxos的算法 Raft # 管理复制状态机的一种算法，他会在集群中选举一个leader，之后会复制所有的日志到其他节点实现一致性\n他可以分解为三个问题\n领导选举 一个新的领导人需要被选举出来，当先存的领导人宕机的时候 日志复制\n领导人必须从客户端接收日志然后复制到集群中的其他节点，并且强制要求其他节点的日志保持和自己相同 安全性\n在 Raft 中安全性的关键是在图 3 中展示的状态机安全：如果有任何的服务器节点已经应用了一个确定的日志条目到它的状态机中，那么其他服务器节点不能在同一个日志索引位置应用一个不同的指令 可以在这个网站查看实例\n节点有三种状态 Follower Candidate Leader 他们之间的转换关系如下图 任期在 Raft 算法中充当逻辑时钟的作用，这会允许服务器节点查明一些过期的信息比如陈旧的领导者。每一个节点存储一个当前任期号，这一编号在整个时期内单调的增长。当服务器之间通信的时候会交换当前任期号；如果一个服务器的当前任期号比其他人小，那么他会更新自己的编号到较大的编号值。如果一个候选人或者领导者发现自己的任期号过期了，那么他会立即恢复成跟随者状态。如果一个节点接收到一个包含过期的任期号的请求，那么他会直接拒绝这个请求。\n下面是详细的细节参数 下面的参数要求在节点上持久存在\ncurrentTerm\n服务器最后一次知道的任期号，初始化为 0，持续递增 votedFor\n当前获得选票的候选人的Id log[]\n日志条目集；每一个条目包含一个用户状态机执行的指令，和收到时的任期号 下面的参数在节点上是随时变化的\ncommitIndex\n已知的最大的已经被提交的日志条目的索引值 lastApplied\n最后被应用到状态机的日志条目索引值，初始化为 0，持续递增 下面的参数需要在leader重新选举之后变化的\nnextIndex[]\n对于每一个服务器，需要发送给他的下一个日志条目的索引值，初始化为领导人最后索引值加一 matchIndex[]\n对于每一个服务器，已经复制给他的日志的最高索引值 这篇图表示的是rpc的参数信息以及返回值，由领导人负责调用来复制日志指令；也会用作heartbeat 参数\nterm\n领导人的任期号 leaderId\n领导人的 Id，以便于跟随者重定向请求 prevLogIndex\n新的日志条目紧随之前的索引值 prevLogTerm\nprevLogIndex 条目的任期号 entries[]\n准备存储的日志条目，表示心跳时为空；一次性发送多个是为了提高效率 leaderCommit\n领导人已经提交的日志的索引值 返回值\nterm\n当前的任期号，用于领导人去更新自己 success\n跟随者包含了匹配上 prevLogIndex 和 prevLogTerm 的日志时为真 如果 term \u0026lt; currentTerm 就返回 false 如果日志在 prevLogIndex 位置处的日志条目的任期号和 prevLogTerm 不匹配，则返回 false 如果已经已经存在的日志条目和新的产生冲突（相同偏移量但是任期号不同），删除这一条和之后所有的 附加任何在已有的日志中不存在的条目 如果 leaderCommit \u0026gt; commitIndex，令 commitIndex 等于 leaderCommit 和 新日志条目索引值中较小的一个 由候选人负责调用用来征集选票","tags":["论文","Raft","6.824"],"title":"Raft"},{"Description":"","date":"2022-05-30","permalink":"https://askyx.github.io/posts/gfs/","section":"posts","summary":"GFS是一个大规模可扩展的可容错的分布式文件系统。Google三大篇论文之一\n翻译文章在这里\n论文在这里\n6.824 Q\u0026amp;A\nGFS的特点 运行在廉价的机器上，节约成本 灵活性强，可随意扩展，容错性强 文件尾部追加数据，不会有太多的数据变动 架构 # 一个单独的master节点和多个datachunk节点，maste管理元数据信息，包括chunkhandle信息，文件和chunk的映射信息，以及chunkserver的变动信息等。master使用心跳定时和chunkserver同步关键信息。使用单个master的目的是为了简化设计，同时为了避免单点故障，master节点每次操作都和backup master同步数据，master存储的3种关键元数据为\n文件和Chunk的命名空间 文件和Chunk的对应关系 每个Chunk副本的存放地点\n存放在master上，在chunkserver变动的时候难以维护，每个server自己维护自己的信息，然后让master自行同步的方式会简单许多。 这些信息保存在内存中，且1和2的数据变动会保存在日志文件中，每次mater故障恢复的时候，只需要使用此日志就可以恢复到原来的状态，至于3，则保存在chunkserver中，master会使用心跳定时从chunkserver更新此信息到内存中，master的内存承载能力一般是可以维护这些数据，一条master中的信息可以维护一个chunk，一般一条信息可以在64内保存下来，且由于数据的在小范围变化不大，使用一定的压缩方法可以大大的节约空间。 日志记录上面1和2的数据变动信息，用于故障恢复，为了避免日志信息过于庞大，加入检查点机制，恢复时只要回放检查点之后的日志即可。\nchunkserver保存chunk数据，同时维护server上的chunk信息，GFS把大文件切分为64M的chunk文件，64M的原因是\nGoogle实际存储的数据较大其大部分时候使用顺序读写文件，所以大文件的读写时间可以在接受范围内 大文加可以减少master中的元数据信息，读写的时候，可以对一个大文件进行多次读写，避免了小文件需要多次向master查询位置信息 大文件可以避免小文件反复从server读取，使server变成热点 chunk一般是3个数据副本\n读取操作 # C sends filename and offset to coordinator (CO) (if not cached) CO finds chunk handle for that offset CO replies with list of chunkhandles + chunkservers only those with latest version C caches handle + chunkserver list C sends request to nearest chunkserver chunk handle, offset chunk server reads from chunk file on disk, returns to client 一致性问题 # 弱一致性。易实现， 随机写会有offset重复的问题，但是master限定操作顺序，理论上最终的数据是一致的，但是在client看来，数据是不确定的，因为副本不是要求立刻同步的， append only限定append的offset，所以每个offset上数据是一致的","tags":["论文","GFS","6.824"],"title":"GFS"},{"Description":"","date":"2022-05-29","permalink":"https://askyx.github.io/posts/mapreduce/","section":"posts","summary":"利用普通机器组成的大规模计算集群进行并行的,高容错,高性能的数据处理函数框架\n原始论文点这里,论文翻译点这里，有时间的话，自行对比翻译和原文\n最终实现的目标是\u0026ndash;实现一个分布式系统，对程序员隐藏底层分布式细节，程序员只需要定义map和reduce 函数即可。\nmap reduce实现为简单的kv输出，其中map接受源数据，生成kv的中间结果，中间结果保存在worker节点上。 reduce负责处理map产生的中间结果的kv数据，只是简单的数据处理过程.\n他最先是受到lisp中map和reduce原语的启发，再加上当时Google现实的处理大量数据的需求，从他们现有的系统抽象而来的。\n在论文中，使用了一个单词统计的案例，此时实现map函数用来分割文本，切分出最基本的单词。然后再使用reduce进行聚合操作，\n// 输出单词以及出现的次数，map端输出1 map(String key,String value): // key: 文档名 // value: 文档内容 for each word w in value: EmitIntermediate(w,\u0026#34;1\u0026#34;); // 针对相同的key，次数+1 reduce(String key, Iterator values): // key: 一个单词 // value: 计数值列表 int result = 0; for each v in values: result += ParseInt(v); Emit(AsString(result)); 执行过程 文件划分 主节点划分任务 按照划分的任务启动worker，执行map任务 worker节点的数据生成为中间结果，保存在本节点 所有map任务执行完成之后，reduce得到对应中间节点的文件路径，通过rpc读取文件，进行reduce任务 reduce任务完成之后，最终结果写入目标文件 一个mr任务完成之后，回得到n(reduce)个结果文件，可以按照需求处理文件，可以直接使用，或者继续作为其他mr的输入，mr任务是可以嵌套的。\n主节点\n记录map和reduce任务的状态，例如是否开始，是否结束，执行时间等 协调工作节点，确定工作状态。确定任务是否需要重试，是否需要back up等 容错性\n工作节点失败\n主机点定时检测工作节点状态，如果无法链接，此时需要把此丢失的工作节点上的所有的任务重新安排到其他节点上执行。包括已完成的map任务，因为mr任务是需要等所有map任务结束之后才能执行reduce任务，其map任务的数据在保存在worker节点上的。所以需要重新执行map任务。至于reduce任务，由于他的输出之最终的数据结果，且需要记录到文件。所以为了避免重复的数据产生，已完成的reduce任务不重试，前提是输出数据已经保存到其他节点上。 主节点错误 一般是直接重试整个mr任务，因为mr的主节点应该是需要选择集群中比较可靠的节点，此时有理由怀疑其他节点也可能出现问题，所以此时选择整个重新执行，当然也可以恢复主节点，从记录的回复点重新执行 backup task mr中由于任务切分不一定均衡或者不同节点计算能力不同，有的任务执行格外慢，此时可以在其他空闲节点上执行相同的任务，此时集群中可能有多个相同的任务，最终哪一个任务先完成，主节点就会终止其他未完成的工作节点。\n上面就是原始的mr描述，理所当然的可以想到一些提升的地方\n平均的划分任务文件，尽量任务均衡 流式计算，在中间结果产生的时候，直接保存中间文件到reduce节点，避免最后集中处理中间结果时候的网络带宽消耗 本地计算mr，有的mr任务没必要在不同节点上执行，直接划分到一个节点或把的某些任务划分到一个节点上，实现本地计算。避免网络IO 提前进行reduce操作，可以使用reduce任务提前处理中间结果，减少中间结果的大小 记录计算节点的状态，多次执行任务的时候，可以记录某节点的处理速度，在下一个mr任务划分的时候，按照此信息划分任务 https://www.zhihu.com/question/303101438\nmap和reduce之间是完全串行的，如果有多个MR任务嵌套的话，由于每个mr必须实现map和reduce，会导致链路过长，实现和调试困难 性能无法达到要求 6.824 LAB # 先掌握go，重点为go的协程，管道，以及channel 代码框架已经给出来了，需要自己实现分布式的worker和master 可以先实现简单的无状态的mr，可以通过test-mr.sh中的前面的测试 worker # map和reduce的执行节点，需要从master获得任务，按照任务的类型，执行不同的job\nfunc Worker(mapf func(string, string) []KeyValue,\treducef func(string, []string) string) { for { job := getJob() if job.","tags":["论文","Mapreduce","6.824"],"title":"Mapreduce"},{"Description":"","date":"2022-05-17","permalink":"https://askyx.github.io/posts/go_1/","section":"posts","summary":"2022-05-17 基础语法 2022-05-24 复合类型，goroutine，channel 基础语法 # Packages # go使用Packages维护模块，使用import导入模块，import最后一个元素才是需要导入的模块\nimport ( \u0026#34;fmt\u0026#34; \u0026#34;math/rand\u0026#34; ) import 可以单独一个导入一个模块，也可以批量导入， 与之对应的是export，go不显示声明export，首字母大写的变量或方法自动export，外部只能使用导出的变量或者方法，类似c++中类的私有和共有的概念。\nFunctions # 与c++或者Java或者其他语言不同的是，go的函数签名格式为func func_name(parm1 [type], parm2 [type]....) retype {}，先声明名字，再声明变量的类型，参数列表中有多个参数且类型一致的时候，前面的参数类型可以省略，只需要保留之后一个\nfunc add(x, y int) int { return x + y } 且go可以很轻易的实现多返回值的功能，如下\nfunc swap(x, y string) (string, string) { return y, x } func main() { a, b := swap(\u0026#34;hello\u0026#34;, \u0026#34;world\u0026#34;) fmt.Println(a, b) } 上面的功能在c++中需要使用结构体或者tuple或者Paris才能实现。\ngo的return还可以使用不带参数的 \u0026ldquo;naked\u0026rdquo; return，此时要求函数签名中的return参数必须有名字，且在函数体中必须为参数赋值，此时使用return直接返回，参数可以直接传递到外部，但是需要注意的时候，如果函数体过于庞大且有多个出口，不建议使用，难于阅读\nfunc split(sum int) (x, y int) { x = sum * 4 / 9 y = sum - x return } 变量 # 使用var声明变量，声明多个变量的时候可以类似参数列表中的参数，前面参数不需要声明类型。初始化的时候按顺序初始化，且初始化的参数个数必须前后一致\nvar i, j, k int = 1,2,0 // true var i, j, k int = 1,2 // false 初始化的时候还可以省略类型，程序会进行参数推导。 函数内部还可以使用 :=替换var声明变量，此时必须初始化，但是在函数体外部，由于go规定，每条语句必须由特定的关键字开头，所以外部不可使用此语法。","tags":null,"title":"A Tour of Go速通"},{"Description":"","date":"2022-05-17","permalink":"https://askyx.github.io/posts/coursenote/","section":"posts","summary":"随堂笔记 # Why do people build distributed systems? to increase capacity via parallel processing to tolerate faults via replication to match distribution of physical devices e.g. sensors to achieve security via isolation\n分布式的困难点：\n大量的并发操作 具有容错性 难于实现 Lab 1: distributed big-data framework (like MapReduce) Lab 2: fault tolerance library using replication (Raft) Lab 3: a simple fault-tolerant database Lab 4: scalable database performance via sharding\nA big goal: hide the complexity of distribution from applications.\nTopic: fault tolerance 1000s of servers, big network -\u0026gt; always something broken We\u0026rsquo;d like to hide these failures from the application.\n\u0026ldquo;High availability\u0026rdquo;: service continues despite failures","tags":null,"title":"Coursenote"},{"Description":"leveldb 源码总结分析","date":"2022-05-15","permalink":"https://askyx.github.io/posts/leveldb/","section":"posts","summary":"LevelDB: version 1.23 Date: Thu Oct 20 15:32:47 2022 CPU: 16 * AMD Ryzen 9 5900HS with Radeon Graphics CPUCache: 512 KB Keys: 16 bytes each Values: 100 bytes each (50 bytes after compression) Entries: 1000000 RawSize: 110.6 MB (estimated) FileSize: 62.9 MB (estimated) ------------------------------------------------ fillseq : 1.394 micros/op; 79.3 MB/s fillsync : 1208.178 micros/op; 0.1 MB/s (1000 ops) fillrandom : 1.948 micros/op; 56.8 MB/s overwrite : 2.448 micros/op; 45.2 MB/s readrandom : 3.251 micros/op; (864322 of 1000000 found) readrandom : 2.947 micros/op; (864083 of 1000000 found) readseq : 0.126 micros/op; 878.1 MB/s readreverse : 0.216 micros/op; 511.4 MB/s compact : 473557.","tags":["源码阅读","LevelDB","存储引擎"],"title":"LevelDB源码阅读"},{"Description":"","date":"2022-04-04","permalink":"https://askyx.github.io/posts/volcanooptimizer/","section":"posts","summary":"NOTE # 论文阅读笔记The Volcano Optimizer Generator: Extensibility and Efficient Search\n可扩展\n面向对象\n自顶向下\n剪枝\n原型是EXODUS， Volcano是对他的改进\n可以单独使用的优化器 优化搜索时间和搜索空间 可扩展 可以使用启发式算法和有效的代价模型来扩展和减少搜索空间，【剪枝】 灵活的成本计算模型 一个框架，优化器生成器，可以由“optimizer implementor”自行实现关键函数，整个优化器框架的输入是AST，输出是一个执行计划，算子的集合\nSQL是基于关系代数，Volcano把关系表达式分为逻辑表达式和物理表达式，逻辑表达式之间使用transformation进行转换，物理表达式使用基于代价的implementation和逻辑表达式映射的，关系不一定是意义对应的，例如scan可以同时一起实现projection\n在表达式进行转换的时候可以使用condition进行模式判断，满足条件的时候可以进行变换\n表达式使用特征描述输出，\nenforcers会强制添加某属性，用于指导优化器进行优化，例如指定表的scan方式\nLogical Operator\nOperator set，也就是可以描述在目标data model上可以执行的代数运算合\nTransformation rules + Condition，对每条等价变换规则，在满足condition时才可以应用\nLogical properties : 逻辑属性，用来描述代数运算的输出所具有的一些特征，这些特征与运算的具体执行方式无关，是逻辑的，例如输出的行数，结果集的schema等\nPhysical Operator\nAlgorithm + Enforcer set，即可应用的物理实现算法 + 可添加的Enforcer集合\nImplementation rules + Condition，满足Condition的前提下，可以尝试该物理算法\nCost model + Cost formula，基于cost选择最优的物理算法\nPhysical property，与logical property对应，物理属性是选择了特定的算法实现后，输出的数据所具有的物理上的特性，例如数据是否有序、是否具有唯一性，数据在多机上的分布情况等，不同的物理算法，会决定执行该operator产生的物理属性，例如sort merge join会在join key上产生有序属性\nApplicability function : 决定一个物理算法，其输出是否可以满足要求父算子对自身的physical property要求，且决定它对自身的输入具有什么样的physical property要求\nEnforcer是search engine中一个重要的概念，它用来强制产生某种物理属性。例如上层是join算子，在枚举时会考虑使用sort merge join的物理执行方式(Implementation），但当递归到下层时，子节点可以选择table scan（无序输出），或者index scan（目标序输出），当选择table scan时，由于输出不满足父算子对自身输出的物理属性要求，就可以通过Order Enforcer来产生目标输出，Enforcer表示了排序这个操作，同时也包含了排序操作会产生的代价。\nThe Search Engine # 搜索实现\n// PhysProp：： 此LogExpr锁具有的物理属性的要求 FindBestPlan (LogExpr, PhysProp, Limit) // 如果可以在look-up table找到满足的计划，则代表以及算过，直接返回 if the pair LogExpr and PhysProp is in the look-up table if the cost in the look-up table \u0026lt; Limit return Plan and Cost else return failure /* else: optimization required */ // 否则进行优化，由三种优化方式 // 1.","tags":null,"title":"VolcanoOptimizer"},{"Description":"","date":"2022-04-02","permalink":"https://askyx.github.io/posts/columbia-optimizer/","section":"posts","summary":" start # EFFICIENCY IN THE COLUMBIA DATABASE QUERY OPTIMIZER\n优化器发展版本 # 第一代\n模块化的，分层的，可扩展的，基于规则的优化器 扩展的复杂性，搜索性能 第二代\n类似Volcano，更加优秀的优化规则，且使用物理属性参与优化，使用新的搜索方式 更加灵活，但是还是难与扩展 第三代\n使用面对象的思想实现的优化器，易于扩展，更灵活 可以按照搜索策略分为两类 1. 自底向上 2. 自顶向下 Cascades Optimizer Framework 对关键操作定义为抽象类，通过实现抽象类来添加规则或者进行表达式变换来扩展优化器， * 使用hash来消除重复的表达式 * 再group中把逻辑表达式和物理表达式分开 * 剪枝 先计算上层group的cost 阈值，在计算下层节点的时候，直接判断是否还需要继续进行优化 预先对执行计划设置阈值，当执行计划的代价和阈值足够接近的时候，则判定已完成搜索\n术语 # ","tags":null,"title":"Columbia Optimizer"},{"Description":"","date":"2022-03-24","permalink":"https://askyx.github.io/posts/log/","section":"posts","summary":"面试 # 只是一个技术汇总\nC++基础 [2 days] [课程- https://github.com/parallel101/course.git]\n内存 内存结构 [https://segmentfault.com/a/1190000039348996] | c++ 编译出来的是可执行文件，是ELF格式的，他本来就有一些格式上的划分，C++在他的基础上进行了更细的划分，分为五个部分，从高地址到底地址依次为：\n\u0026mdash; 1. 内核虚拟内存\n进程的虚拟印象 2. 栈\n程序自动控制，具体为程序的函数调用，保存局部变量，有大小，可以使用ulimit -s 查看，也可以自行设置，但是建议系统默认即可 * 函数调用机制\n调用的时候是一个一个的栈帧，函数参数会在调用者的栈帧中开辟空间，从右到左，所以函数列表的默认值必须从右到左的初始化， 可能和这个有关系，然后被调用者构造栈帧，依次执行\n3. 共享库的内存印象 3. 堆 空间有程序员自行维护，向上增长(TIPS: 由于C的历史原因，C++的内存结构还是说堆区，但是在区别new/malloc 和delete/free 的时候，他们的差别之一可能会在内存上有点区别 C的malloc/free可能会说是在堆上分配空间，但是对于C++可能会说的是在自由存储区上分配，自由存储区和堆是不同的概念，堆是操作系统上的概念，但是自由存储区是一个抽象概念 一般new可以是在堆上分配空间，但是可能存在在其他情况，例如在栈上使用new，所以他们不是一个概念，面试的时候说到这里，可以装逼😎) 4. 可写/全局区 对应elf中data段和bss段，data段保存的是已初始化的全局变量或者静态变量，bss保存的是未初始化的数据 5. 只读区/代码段 text段，保存编译之后的指令，不可变 6. 常量区 保存全局变量，不可变，rodata段，记得使用其他手段去尝试修改常量的时候会报错。 TIPS: const修饰的参数不一定是常量，例如他修饰一个函数的参数的时候，参数还是只是在栈中，只是约定不能修改。 7. 未使用 static\n全局变量和静态变量存储位置一样，处于数据段，区别是全局变量项目可见， 静态变量当前文件可见\n局部静态变量数据static变量，存储位置一样，但是限定作用域为当前声明范围\n静态函数类似，全局函数全局可见，static函数当前文件可见\n类static 属性和函数属于类，不属于具体的对象\nextern\n表明此函数在其他文件中定义，这里避免重复声明，所以使用extern，仅仅是一种声明，不是定义\n内存管理\nnew C++有对象的概念，所以他的new大意上是malloc的封装，先申请对象的内存空间，然后调用对象的构造函数构造对象，用在数组上是，先申请所有的空间，然后再依次调用构造函数 delete 删除对象，先调用析构函数，然后再释放空间 对象数组 如果调用的是delete[]，如果是基础类型，则删除的时候使用delete和delete[] 都没有区别，因为空间连续的，有额外的空间记录内存的大小，直接使用delete的时候可以直接伤处 如果是自定义对象，如果有指针这类的属性，则必须调用delete[]， 否则他只会调用第一个对象的析构函数，可能会导致内存泄露 \u0026ndash; new malloc 的区别 \u0026ndash; 1. 空间分配的概念上 一个是堆区，一个是自由存储区 2. 使用上 new会调用构造函数，且new会自行计算对象所需的空间大小，malloc需要自行指定 3. 概念上 malloc是标准函数，而new是关键字\n虚表\n实现\n虚表是多态的一种实现，但是不是C++的规定，而是编译器的自行的实现方法，在函数中只要声明虚函数，则对象中就会有额外的空间用于保存虚表，他是一个指针，指向虚表，所以对于有虚表的对象 sizeof的时候会计算这个指针的大小，指针指向虚表的第三个槽位，gdb查看地址的时候会显示+16的字样，因为这是实际的函数指针的开始位置，前两个槽位一个一般是0，另一个一般是typeinfo的地址， 虚表和他的附属信息在内存中都是一起的，其实从根本原理上来说，他只是做了一层转换，实际上函数的调用最终的实现都是面向过程的函数的调用，函数才是C++ 的核心，\n而且虚表由于调用的时候需要寻址，所以会导致性能问题，主要是由于需要进行地址跳转，跳转会有性能损耗，且由于局部性原理，指令会有预读机制，跳转之后可能导致cache miss，导致流水线失效 验证方法\n编译的时候使用参数-fdump-lang-class，gdb调试的时候使用set print asm-demangle on，然后x/b打印地址 或者使用 Compiler Explorer 虚继承 同样使用到虚表，父类只有一份副本 共享内存中的对象问题","tags":null,"title":"面试"},{"Description":"","date":"2022-03-06","permalink":"https://askyx.github.io/posts/%E7%8E%B0%E4%BB%A3c-%E7%99%BD%E7%9A%AE%E4%B9%A6/","section":"posts","summary":" 读者序 # 之前没有好好的阅读过一本任何技术书籍，一般都是打开前几张，然后慢慢的失去耐心，所有造成的问题是一些书籍上的知识，只会对前面的章节有记忆，而大多数的书籍前面的章节也只是他书籍的入门介绍而已，所以我是个半吊子程序员，工作两年半之后，这个问题越来越困扰着我，有时候看见别人的面帖，感觉那些问题其实都因该是知道答案的，但是当我想要在脑海中把答案整理出来的时候却无从说起，简单的来说就是有的东西我是知道的，但是无法表示出来，不成体系，这给我一个错觉就是我感觉我能力可以，但是落到实地的时候却啥也做不了，脱离了谷歌百度或者其他我之前的资料，我啥都不行。\n我个人觉得问题的解决方式是学会输出，把自己的知识整理输出，通过自己让别人知道一项新技能，新知识，那就代表自己其实已经有了闹靠的基础，知识的输出需要一个载体，我不是老师，公司也没有这个渠道，因为公司的知识交流与工作内容是密切相关的，所以这也是我搭建这个博客的原因，但愿我可以长期的坚持下去，说实话，之前已经有了还几次类似的经历，但是都半途而废了，我希望这是最后一次\n前言 # 书籍是Bjarne Stroustup为HOPL所撰写的论文，目的是介绍c++在过去到现在的发展历程，以及其中一些大的功能点的演化。促发展上来划分C++可以分为两个阶段，一是C++98之前的类C版C++，二是之后的C++11之后的现代C++，在进40年的时间里C++还没有被取代，还可以在如此多的编程语言中占据一些之地，引用Bjarne Stroustup大佬的话说就是因为他填补了编程语言中一个重要的生态位。C++的核心是直接映射硬件和林开销抽象，\nISO 编程语言可以分为三种，一是有公司主导的编程语言，例如Google的go，C#以及苹果的swift等，二是由社区主导如php，python等，这两种在除了显而易见的好处之外的，都有各自的问题，公司主导的语言的，可能哎公司强势的时候还可以得到发展，但是公司没落之后，语言没有支持可能就无了，还有那家公司主导，那语言就是那家公司的产品，技术上的map由公司指定，小公司没有能力可以影响到语言的后续发展，对于社区，则可能会由于没有一个核心的个人或者组织来引导方向，导致语言偏离最初顶下的发展道路。Bjarne Stroustup就是基于以上的原因，提出组建一个标准委员会来引导C++ 的发展，\n语言特性 具体的定义的语言的规则，有对应的具体的实现\n1. 起源 # C++核心特性\n语言到设备之间的直接映射 零开销抽象 不使用的东西就不需要付出任何代价 使用到的东西就是可以实现的最好的 抽象具体为类，函数，模板，概念和别名 simula 最早的面向对象的语言，之后几乎所有的面向对象的语言都是直接或者间接的受奥他的印象。\nC++最初是在1979年推出的，那时候是真正的带类的C。 Bjarne Stroustup的目的是想要一个可以直接映射硬件，同时又有类似于simula的具有抽象能力的语言，那是一个实验性质的语言的，实现就是把编码从C++逐行翻译到C，之后的1982年，随着人数的增加，他重写了前端，实现了一个功能完整的编译器，但是实际上在代码生成的是时候，还是生成的是C，\n之后就是平稳的发展到推出98版本的C++，不考虑最近的一些新特性的话，我们大部分人的C++ 知识就到这里了。此时C++实现了\n类 多态 运算符重载 类型安全连接 抽象类 模板 更好的泛型编程。大佬最初的时候使用宏实现的泛型编程 异常 RAII *_cast bool STL标准库 上述就是最初的98的C++实现的功能点，实际上也是大多是C++的开发人员知道的最详细的C++知识。之后就是漫长过渡期，直到11版本的推出，使C++进入新时代， 06年单核处理器新能几乎不再提升，所以大部分应用开始寻找可以提升性能的编程语言， C++11 新时代 # 许多新的特性的引入，使得C++类似一个新语言 特性如下\n内存模型 高效的为现代硬件设计的底层抽象，描述并发的基础， auto|declytype range for 更好的遍历容器 移动语义和右值引用 统一初始化 nullptrt constexpr 用户自定义字面量 原始字符串字面量 属性 lambda表达式 变参模板 模板别名 noexcept override和final static_assert longlong 默认成员初始化 enum class 组件如下\n智能指针 unique_ptr和shared_ptr atomic thread库 future，promise等 tuple type trait 正则 随机数 时间 容器 上面的东西就是后续C++在98 的基础上推出的新11功能点，在我自己写这边文档的时候，其实有些东西我是没概念的😂，这些看似不相关的东西，可以分为下面的几个大的主题\n并发支持 简化使用 泛型编程的改进 增加静态类型的安全 支持对库的开发 标准库组件 1. 并发支持 # ","tags":["读书笔记","C++"],"title":"现代C++白皮书"},{"Description":"","date":"2022-02-21","permalink":"https://askyx.github.io/about/","section":"","summary":"ヾ(•ω•`)o # 比较胆小，出门都得贴墙走","tags":null,"title":"关于我"},{"Description":"","date":"2022-02-21","permalink":"https://askyx.github.io/posts/envs/","section":"posts","summary":"hugo # wget https://github.com/gohugoio/hugo/releases/download/v0.92.1/hugo_0.92.1_Linux-64bit.deb https://github.91chi.fun/https://github.com//gohugoio/hugo/releases/download/v0.92.2/hugo_extended_0.92.2_Linux-64bit.deb sudo dpkg -i hugo*.deb\n140.82.113.3\naria2c -s 5 https://github.com/gohugoio/hugo/releases/download/v0.92.1/hugo_0.92.1_Linux-64bit.deb\nhttps://github.com/gohugoio/hugo/releases/download/v0.92.1/hugo_0.92.1_Linux-64bit.deb\n可以使用aria2下载，ubuntu使用apt install aria2直接安装工具，使用-s开启多路下载 aria2c -s 5 https://github.com/gohugoio/hugo/releases/download/v0.92.1/hugo_0.92.1_Linux-64bit.deb\nmanager用户\nhttps://www.jianshu.com/p/a76a93e8c662\nUnix # 分区问题，集群上多块磁盘分区挂载到指定目录\nfdisk disk 可以对一个磁盘进行分区的添加和删除等操作 p d w h 添加磁盘挂载\nlsblk -f 查看磁盘 mkfs.xfs -f -n ftype=1 /dev/sdb1 格式化磁盘 mount /dev/sdb1 /var/lib/docker 挂载 xfs_info /dev/sdb1 | grep ftype=1 blkid /dev/sdb1 查看UUID UUID=\u0026lt;UUID\u0026gt; /var/lib/docker xfs defaults 0 0 写进/etc/fstab 问题Couldn't find device with uuid 4mhUbb-Ls1h-jp0d-JuJK-C38V-T3tX-f7s2IN\n原因未知，疑似但是这个UUID是前面挂载的分区格式化之前的UUID，所以可能是挂载的时候出了什么问题，但是之前对其他机器操作无问题，此问题只出现在集群中的一两太机器上。\n解决：\n使用 vgreduce --removemissing --verbose lvname 解决，但是需要视情况而定，需要知道自己在做什么 其中会使用的命令 lsblk vgscan pvscan cat /etc/lvm/archive/* | less 查看UUID和盘符之前的关系 lvextend -L +300G /dev/mapper/centos-root 扩展分区大小 xfs_growfs /dev/mapper/centos-root 扩展且生效 lvremove /dev/mapper/centos-home 删除lv lvcreate -L 100G -n /dev/mapper/centos-home\t创建lv mkdf.","tags":null,"title":"Envs"},{"Description":"docker 常用命令速查，私用","date":"2022-02-20","permalink":"https://askyx.github.io/posts/docker/","section":"posts","summary":"基础概念 # Docker使用go开发的一种沙箱工具，他使得应用可以单独运行在沙箱中，通过端口映射或者volumes与外界进行交互。这可以让一个机器上可以运行多种不同环境的应用且互不干扰，例如一个比较大型的引用，使用的此方式单独维护一个模块，使得系统的可靠性大大增强\n容器\n镜像运行的实例，一个镜像可以运行多个实例。 镜像\n一个完整的可运行的资源集合 仓库\n保存镜像 使用 # 这里记录高频次使用的功能，其他的后续记录\n镜像的管理\npull push commit\n修改一个容器之后，使用commit在此基础上构建自己的容器 build\n创建一个镜像，使用docker build语句创建，需要自己编写Dockerfile，具体的编写规则可以参考nosipage rmi 容器的管理\nrun\n创建新的容器，且会使用run指定启动规则，例如端口的映射，volumes文件的指定，以及其他重要参数等，这个命令可以说重要，因为同一个镜像，使用不同参数启动之后，效果是不一样的，对于开发来时，更多的是参与后期的开发，如果不是前期的项目设计，这里了解即可，但是最好的是知道他的只要参数的意义，因为和其他命令有的是通用的，例如-i -t -p等 start stop restart exec\n使用此命令可以进入运行中的容器中区，exec -it xxx command attach rm logs cp\n在本地和容器中传输文件 export ps 其他命令基本在遇到的时候，再去查看\n权限问题 # Got permission denied while trying to connect to the Docker daemon socket at unix:///var/run/docker.sock: Get \u0026#34;http://%2Fvar%2Frun%2Fdocker.sock/v1.39/containers/json\u0026#34;: dial unix /var/run/docker.sock: connect: permission denied sudo groupadd docker #添加docker用户组 sudo gpasswd -a $USER docker #将当前用户添加到docker用户组 newgrp docker #更新docker用户组 System has not been booted with systemd as init system (PID 1). Can’t operate. # 使用 \u0026ndash;privileged=true /sbin/init 从一开始就最基础的镜像手动构建，使用docker file 构建镜像之后，即使指定 privileged 也无效 systemctl 验证 docker file 指定用户之后， 后续即使容器 systemctl 失败，暂时没有解决方案，gitlab中又需要指定非root用户~~ gitlab 不支持指定容器用户，gitlab有issue，也有解决方案，但是当前版本runner不支持 指定user 解决方案 使用ssh到容器中执行， 无法任务并行，会有端口冲突这类的问题 ssh到宿主机中启动docker，然后copy代码到docker 中，或者build镜像然后执行 可任务并发，后续研究怎么实现 常用命令 # docker run -dit --name centos-p centos /sbin/init docker run \\ --mount type=bind,source=/home/asky/asky,target=/workspaces/asky \\ --mount type=bind,source=/home/asky/.","tags":["Docker"],"title":"Docker"},{"Description":"","date":"2022-02-20","permalink":"https://askyx.github.io/posts/cpp/","section":"posts","summary":"编译器 # 把高级语言编译成可执行语言工具，分为前端后后端，前端值得是高级语言的解析，后端是指翻译解析之后的结果为机器语言\n多文件 ** 连接 多文件编译可以有两种方式，一是直接编译为一个可以执行文件，二是按模块或者按文件编译为库，然后连接到执行文件\n连接方式有两种， 一是静态连接，把所有的库文件打包到最后的生成文件中，优点是不需要额外的依赖外部环境，独立性强，缺点是文件体积大 二是动态链接，为了解决静态链接的缺点，执行文件在执行到库相关的代码的时候才加载库，有一点需要注意的是，程序运行的时候，在使用到动态库的时候才映射动态库到内存空间中。原理是编译待援在编译的时候，会更具声明生成函数的调用逻辑，但是只是一个地址跳转语句，所以，只要不调用，就不会有问题，当调用到了。才会加载库然后映射库的地址，这个完整的过程称为重定向。 动态连接 C语言编程透视 声明 声明是为了在编译的时候编译器能进行完整的上下文编译。他需要更具声明来确定编译信息，否则编译器无法确定编译中的语句信息，声明可以辅助完成这个情况， 所以理论上编译的时候是可以不需要实现的，可以在其他编译单元中实现声明的函数，其声明的文件可以不引用头文件，即两个编译单元完全可以无任何联系，除了声明之外，在连接的时候，连接器会根据编译出来的信息去确定函数调用情况，这里有一个问题，按上述的描述，是一个声明对应一个实现，如果有一个声明对应多个实现呢 == ： 会有覆盖问题，如果多个动态链接库都有同一个声明的实现，则连接的时候连接第一个，后面的则忽略，这也提醒我们，在大型项目中，避免同名全局函数或者变量，使用namespace或者static限制作用域，\ng++ -o tt ../main.cpp -ldl ./libhellolib.so ./libhellolib1.so LD_LIBRARY_PATH=$PWD ./tt 头文件，避免公用代码的重复，预处理时展开头文件，需要使用#pragma once避免重复引用，头文件只是简单的文件替换，理论上的可以替换任何文本。 cmake * 子模块，使用add_subdirectory引入 * 第三方库 * 只是头文件，直接指定头文件目录编译即可 * 使用子模块 * 使用为连接库 * 使用git模块\nSTL\n重点为容器和算法 lambda表达式，实质上是仿函数，是一个结构体实现()运算的重载，捕获的时候按照声明的新式捕获参数，建议使用的时候明确使用的参数，使用哪个就捕获哪一个，否则他实际上会占据一定的大小的，配合std::function使用\nCTAD \u0026mdash; complie-time argument deduction，编译器参数推断，C++17引入的，可以在编译器按照上下文推断类型，具体表现在lambda参数可以使用auto，容器可以不适用\u0026lt;\u0026gt;\nranges https://zhuanlan.zhihu.com/p/350068132\nmodule\nraii 获取资源即初始化，释放资源即销毁，具体的实现是使用构造函数和析构函数，当前的实现为智能指针，其他用户自己管理的资源最好也使用raii，遮这样在函数有多个出口的时候，就不会有意外的情况，本质上还是自己管理资源，不想其他的语言有GC\n异常安全，C++中异常机制在回溯栈的时候会析构对象，所以如果没有实现RAII，则自己管理的内存则无法释放，C++的异常可以发生在任何地方，如果发生在析构函数中，则需要自己处理，不要在析构函数中抛出异常的，在构造函数中的时候，也需要捕获异常然后释放已经申请的资源，构造函数异常的时候，是不会调用析构函数的， 构造函数\n构造函数有时候会隐士的生成对象，即使没有显示声明，使用explicit避免这种情况，单参数的时候会，多参数使用{}，调用的时候也会 直接使用多参数的时候，()和{}是有区别的，()除了正常的使用外，其他情况不具备特殊含义 int a = (10, 11); int a = {10, 11}; tt t(1, 2); tt q{1, 3}; tt w = {1, 4}; tests({1,5}); ``` 上面的语句1正确，a的值为11，2错误，{}这种用法的意义是参数列表，是会构造对象的。ps，调用构造函数的时候，有具体的对象的时候两种括号无差别，但是无对象的时候有区别，如上，细品\n默认构造函数 拷贝构造( A(A const \u0026amp; a) ) A a = aa; 移动构造( A(A \u0026amp;\u0026amp; a) ) 赋值构造( A\u0026amp;operator=(A const\u0026amp; a) ) A a; a = aa; 移动赋值( A\u0026amp;operator=(A \u0026amp;\u0026amp; a) ) =delte和=default 类内部变量可以赋初值 三五法则 拷贝构造或者赋值构造需要区分深拷贝和浅拷贝，这也是构造函数肯可能引入的问题，例如浅拷贝导致内存的重复释放， 各种构造函数更多的是需要考虑当前对象的来源，如果是直接从零开始的，则是普通的构造函数，如果是从别的对象来的，则需要考虑深浅拷贝的问题，以及构造之后别的对象是否还需要的问题，简而言之，就是资源细节上的考虑，只要内涉及到资源的操作，则需要多话费一些心思区考虑， 函数返回多值","tags":["读书笔记","C++"],"title":"C++ Primer Plus"},{"Description":"","date":"0001-01-01","permalink":"https://askyx.github.io/posts/adbplan/","section":"posts","summary":"issues # 1490 # 1921 # 1699 # http://10.20.16.216:9090/ADB/AntDB/-/issues/1490 http://10.20.16.216:9090/ADB/AntDB/-/issues/1921 http://10.20.16.216:9090/ADB/AntDB/-/issues/1699\n问题 # 使用到reduce的地方（包括查询）偶现以下错误，再次执行sql就正常；\nERROR: remote node 16389 closed socket CONTEXT: dynamic reduce 复现方法 # 使用修改分布方式的方式去复现问题，过程如下： 创建100张表，然后并发100，不停执行下面的语句，5分钟之内会出现报错：\nalter table xxx distribute by replication; alter table xxx distribute by random; 无法直接复现 1779 # http://10.20.16.216:9090/ADB/AntDB/-/issues/1779\n问题 # 执行计划不正确导致dyreduce执行出错\n复现方法 # create table tttb1( c1 int,c2 varchar(100),c3 varchar(100)); create table tttb2(c1 int,sheet_num varchar(100)); create table tttb3(c1 int,order_no varchar(100)); explain select count(distinct c2) from tttb1 where c2 in (select distinct sheet_num from tttb2,tttb3 where sheet_num=order_no and c3=\u0026#39;1\u0026#39;); create table tb1(c1 int,c2 varchar(100),c3 varchar(100)); create table tb2(c1 int,sheet_num varchar(100)); create table tb3(c1 int,order_no varchar(100)); explain select count(distinct c2) from tb1 where c2 in (select distinct sheet_num from tb2,tb3 where sheet_num=order_no and c3=\u0026#39;1\u0026#39;); insert into tb1 select (random()*10000000)::int, (random()*10000000)::int, (random()*10000000)::int from generate_series(1,100000); insert into tb2 select (random()*10000000)::int, (random()*10000000)::int from generate_series(1,100000); insert into tb3 select (random()*10000000)::character varying, (random()*10000000)::int from generate_series(1,100000); create table tb1int(c1 int, c2 int,c3 int); create table tb2int(c1 int, sheet_num int); create table tb3int(c1 int, order_no int); explain select count(distinct c2) from tb1int where c2 in (select distinct sheet_num from tb2int,tb3int where sheet_num=order_no and c3=1); insert into tb1int select (random()*10000000)::int, (random()*10000000)::int, (random()*10000000)::int from generate_series(1,100000); insert into tb2int select (random()*10000000)::int, (random()*10000000)::int from generate_series(1,100000); insert into tb3int select (random()*10000000)::int, (random()*10000000)::int from generate_series(1,100000); 1875 # http://10.","tags":null,"title":""},{"Description":"","date":"0001-01-01","permalink":"https://askyx.github.io/posts/log/","section":"posts","summary":"语句\nprepare s3(int, int) as select no_o_id from bmsql_new_order where no_w_id = $1 and no_d_id = $2 order by no_o_id asc; QUERY PLAN --------------------------------------------------------------------------------------------------- Cluster Gather (cost=291.52..430.37 rows=459 width=4) Remote node: 16386 -\u0026gt; Sort (cost=291.52..292.67 rows=459 width=4) Output: no_o_id Sort Key: bmsql_new_order.no_o_id -\u0026gt; Bitmap Heap Scan on public.bmsql_new_order (cost=13.46..271.23 rows=459 width=4) Output: no_o_id Recheck Cond: ((bmsql_new_order.no_w_id = 1) AND (bmsql_new_order.no_d_id = 1)) -\u0026gt; Bitmap Index Scan on bmsql_new_order_pkey (cost=0.00..13.34 rows=918 width=0) Index Cond: ((bmsql_new_order.no_w_id = 1) AND (bmsql_new_order.no_d_id = 1)) Remote node: 16386 (11 rows) QUERY PLAN -------------------------------------------------------------------------------------------------------------------- Data Node Scan on \u0026#34;__REMOTE_SORT_QUERY__\u0026#34; (cost=0.00..0.00 rows=1000 width=4) Output: bmsql_new_order.no_o_id Node/s: data_1 Remote query: SELECT no_o_id FROM ONLY public.","tags":null,"title":""},{"Description":"","date":"0001-01-01","permalink":"https://askyx.github.io/posts/%E5%87%BD%E6%95%B0%E8%BF%90%E8%A1%8C%E9%80%BB%E8%BE%91/","section":"posts","summary":"predicate_refuted_by 和 make_new_qual_list的运行逻辑以及PARAM 无法选出一个节点的原因\nmake_new_qual_list需要使用表达式和分区信息构造新的表达式，但是PARAM不是常量，所以无法构造， 所以predicate_refuted_by判定变大时和约束的时候无法正确的选择节点，动态语句只要使用到分区键都不行\nnode_count = 2 Table \u0026#34;public.bmsql_new_order\u0026#34; Column | Type | Nullable | Storage | ---------+---------+----------+---------+ no_w_id | integer | not null | plain | no_d_id | integer | not null | plain | no_o_id | integer | not null | plain | Indexes: \u0026#34;bmsql_new_order_pkey\u0026#34; PRIMARY KEY, btree (no_w_id, no_d_id, no_o_id) Foreign-key constraints: \u0026#34;no_order_fkey\u0026#34; FOREIGN KEY (no_w_id, no_d_id, no_o_id) REFERENCES bmsql_oorder(o_w_id, o_d_id, o_id) DISTRIBUTE BY HASH(no_w_id) TO NODE(dn1, dn2) Access method: heap 数据分布 benchmarksql=# execute direct on (dn1) \u0026#39;select distinct no_w_id from public.bmsql_new_order\u0026#39;; no_w_id --------- 1 5 2 (3 rows) benchmarksql=# execute direct on (dn2) \u0026#39;select distinct no_w_id from public.","tags":null,"title":""},{"Description":"","date":"0001-01-01","permalink":"https://askyx.github.io/posts/%E7%AE%80%E5%8E%86/","section":"posts","summary":" 文磊 # 个人信息 # 性 别：男 年 龄：28 手 机：18705169510 邮 箱：404061090@qq.com\n工作及教育经历 # 湖南亚信安慧科技有限公司 2022.7~now AntDB-T SQL内核研发工程师\n主要负责优化器对分布式执行计划的优化 星环科技有限公司 2022.2~2022.3 基础架构部-数据库研发工程师\n主要职责为负责ArgoDB数据库存储引擎的研发工作 易鲸捷信息技术有限公司 2019.7~2022.1 SQL内核研发工程师\n负责EsgynDB和Oracle的SQL兼容工作 负责BUG修复 负责一些需求开发 与交付同事一起排查项目现场问题，SQL语句优化等 南京邮电大学 2015.9~2019.6 软件工程-本科\n专业技能 # 编程语言 c++(熟悉)，Java(了解)，GO(了解)\n数据库\n工作开始就从事数据库内核开发，有一定的数据库基础，曾系统学习过相关课程\n熟悉多种数据库内核实现原理，主要为trafodion和postgres。对其他pg类数据库也有一定的理解，\n如greenplum，opengause等\n了解SQL优化器的原理，了解常用逻辑优化规则及代价优化规则等\n了解执行器的实现原理，对于其常用优化手段有一定了解，了解postgres执行器原理\n了解存储引擎，对于一些通用存储架构有一定了解，如B+tree，LSM等\n工作中常常进行BUG修复或者性能调优等，所以具备良好的问题定位，分析能力\n主要工作环境为Linux，掌握基础的Linux命令，掌握基础开发工具以及Linux下的调试工具的使用\n掌握基础数据结构和算法，具备常规操作系统知识\nCET-6\n项目经历 # AntDB\n2022.7-now\n主要工作范围为优化器及执行器部分 fast query ship功能优化 进入优化器之前快速判断语句能否从cn直接下发到dn，优化其判断规则，支持较复杂语句 odbc项目维护 项目支持 EsgynDB\n2019.7-2022.1\n分区表功能实现 兼容Oracle分区表实现 range 分区表功能 主要负责分区表的部分SQL DDL、DML语句，以及index的设计和实现，且后期负责分区表功能的主要维护工作 memtable(简易分布式内存表)功能实现 由于数据库的架构问题，导致语句执行链路过长，部分场景无法满足客户性能需求，所以设计实现内存表，加速查询 负责具体功能的实现，主要功能点为 内存表架构实现 缓存一致性的检查机制 缓存操作及维护的DDL语句，DML语句等 性能明显有比较大的提升，表宽为1K，大小为10W行的数据，进行查询操性能较原来提 升有10X，满足现场同事的性能需求 一些现场支援，需求开发、SQL兼容、SQL函数实现、SQL优化等，例如 greatest，least，beginkey，endkey等SQL函数实现 临时表，in语句，reverse scan，大字段查询的优化 ","tags":null,"title":""},{"Description":"","date":"0001-01-01","permalink":"https://askyx.github.io/posts/remotequery/","section":"posts","summary":"remote Query # 精确选择数据源，需要从语句的约束条件中计算出具体的执行数据源节点，然后把语句下发的对应的 DN 操作尽可能下推，下推一些操作到对应的DN上执行 remote query当前使用两阶段优化\n第一阶段是FQS，对语句进行简单的判断，如果语句可以完全在DN上执行，则直接在这里创建remote plan，然后直接返回，如下例子\nbenchmarksql=# explain select * from t1; QUERY PLAN ---------------------------------------------------------------------------- Data Node Scan on \u0026#34;__REMOTE_FQS_QUERY__\u0026#34; (cost=0.00..0.00 rows=0 width=0) Primary node/s: dn1 Node/s: dn1, dn2 (3 rows) 第二阶段，FQS判断失败的语句，此时需要进行常规优化，一般是语句需要DN之间的数据发生交换的时候，例如join使用多表， 但是关联条件不是分区键，此时需要把DN的数据读取到 CN 上，然后进行关联，\npostgres=# explain select * from t1 join t2 on t1.c1 = t2.c1; QUERY PLAN --------------------------------------------------------------------------------------------------- Hash Join (cost=2752.50..5509.65 rows=3000 width=16) Hash Cond: (t2.c1 = t1.c1) -\u0026gt; Data Node Scan on t2 \u0026#34;_REMOTE_TABLE_QUERY_\u0026#34; (cost=0.00..2715.90 rows=3001 width=8) Primary node/s: dn1 Node/s: dn1, dn2, dn3 -\u0026gt; Hash (cost=2715.00..2715.00 rows=3000 width=8) -\u0026gt; Data Node Scan on t1 \u0026#34;_REMOTE_TABLE_QUERY__1\u0026#34; (cost=0.00..2715.00 rows=3000 width=8) Primary node/s: dn1 Node/s: dn1, dn2, dn3 (9 rows) 1.","tags":null,"title":""},{"Description":"","date":"0001-01-01","permalink":"https://askyx.github.io/posts/sublink/","section":"posts","summary":"typedef struct SubPlan { pg_node_attr(no_query_jumble) Expr xpr; /* Fields copied from original SubLink: */ SubLinkType subLinkType; /* see above */ /* The combining operators, transformed to an executable expression: */ Node *testexpr; /* OpExpr or RowCompareExpr expression tree */ List *paramIds; /* IDs of Params embedded in the above */ /* Identification of the Plan tree to use: */ int plan_id; /* Index (from 1) in PlannedStmt.subplans */ /* Identification of the SubPlan for EXPLAIN and debugging purposes: */ char *plan_name; /* A name assigned during planning */ /* Extra data useful for determining subplan\u0026#39;s output type: */ Oid firstColType; /* Type of first column of subplan result */ int32 firstColTypmod; /* Typmod of first column of subplan result */ Oid firstColCollation; /* Collation of first column of subplan result */ /* Information about execution strategy: */ bool useHashTable; /* true to store subselect output in a hash table (implies we are doing \u0026#34;IN\u0026#34;) */ bool unknownEqFalse; /* true if it\u0026#39;s okay to return FALSE when the * spec result is UNKNOWN; this allows much * simpler handling of null values */ bool parallel_safe; /* is the subplan parallel-safe?","tags":null,"title":""},{"Description":"","date":"0001-01-01","permalink":"https://askyx.github.io/posts/%E9%85%8D%E7%BD%AE/","section":"posts","summary":"配置文件guc.c\nhttp://www.postgres.cn/docs/12/view-pg-settings.html\nColumn | Type | Collation | Nullable | Default | Storage | Description \u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash;+\u0026mdash;\u0026mdash;\u0026mdash;+\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash;+\u0026mdash;\u0026mdash;\u0026mdash;-+\u0026mdash;\u0026mdash;\u0026mdash;+\u0026mdash;\u0026mdash;\u0026mdash;-+\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;- name | text | | | | extended | 名称 setting | text | | | | extended | 配置 unit | text | | | | extended | 单位 category | text | | | | extended | 分类 short_desc | text | | | | extended | 描述 extra_desc | text | | | | extended | 附加描述 context | text | | | | extended | 上下文 vartype | text | | | | extended | 参数类型 source | text | | | | extended | 来源 min_val | text | | | | extended | 最小值 max_val | text | | | | extended | 最大值 enumvals | text[] | | | | extended | 枚举的允许值 boot_val | text | | | | extended | 默认值 reset_val | text | | | | extended | 当前session中reset 之后会设置的值 sourcefile | text | | | | extended | 设置文件 sourceline | integer | | | | plain | 文件行号 pending_restart | boolean | | | | plain | 修改文件是否需要重启生效 select name, setting, boot_val, reset_val, sourcefile, sourceline, pending_restart from pg_settings ; View definition: SELECT a.","tags":null,"title":""},{"Description":"","date":"0001-01-01","permalink":"https://askyx.github.io/posts/mysql/","section":"posts","summary":"","tags":null,"title":""},{"Description":"","date":"0001-01-01","permalink":"https://askyx.github.io/trash/docs/","section":"trash","summary":"The Internals of PostgreSQL # 这里相当于阅读笔记，但是会从源码进行更细节的分析，原文没有提到的，这里会进行适当的扩展\nPostgreSQL is a well-designed open-source multi-purpose relational database system which is widely used throughout the world. It is one huge system with the integrated subsystems, each of which has a particular complex feature and works with each other cooperatively. Although understanding of the internal mechanism is crucial for both administration and integration using PostgreSQL, its hugeness and complexity prevent it. The main purposes of this document are to explain how each subsystem works, and to provide the whole picture of PostgreSQL.","tags":null,"title":"Docs"},{"Description":"","date":"0001-01-01","permalink":"https://askyx.github.io/search/","section":"","summary":"","tags":null,"title":"Search Results"}]