<!doctype html><html lang=en><head><title>Postgres Hash Join ::
Asky — My note blog
</title><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="理论依据 # 使用 hybrid hash join 实现的hash join，大意是：
outer 和 inner 无法完全使用内存实现 hash join，所以需要把数据分区 dump 到磁盘中，每个分区称为一个 batch，在 优化阶段，会使用已有的统计信息决定分区大小，但是实际执行中， 如果有偏差，则分区按2倍扩容，分区运行时不会减少
nbatch // number of batches nbuckets // buckets in the in-memory hash table bucketno = hashvalue % nbuckets batchno = (hashvalue / nbuckets) % nbatch hybrid hash join batch 0 不会落盘，算是一种优化
大致过程 # 1. Scan inner table ，构造 hashtable # 可以细分为下面几种情况
如果判断内存完全可以存下 innert table 的数据，则只使用一个 batch 否则计算 hashvalue， 使用 hashvalue 计算 batchno ，不属于 batch 0 的数据写到磁盘中对应批次的文件 如果内存中 hahstable 由于实际使用的数据超过内存上限，则需要进行分裂
1. nbatch 翻倍， scan hashtable , 使用新的 nbatch 计算 batchno
2. 属于 batch 0 的数据继续放在内存中，其他的 dump 到磁盘对应的文件
3. 原来磁盘中已有的文件不动， 后续 probe 的时候才需要重新计算 batch，也可能会写文件 2."><meta name=keywords content="程序员、码农、database、C++"><meta name=robots content="noodp"><link rel=canonical href=https://askyx.github.io/posts/hashjoin/><link rel=stylesheet href=//cdn.staticfile.org/lxgw-wenkai-screen-webfont/1.6.0/lxgwwenkaiscreen.css media=print onload='this.media="all"'><link rel=stylesheet href=https://askyx.github.io/assets/style.css><link rel=stylesheet href=https://askyx.github.io/style.css><link rel=apple-touch-icon-precomposed sizes=144x144 href=https://askyx.github.io/img/apple-touch-icon-144-precomposed.png><link rel="shortcut icon" href=https://askyx.github.io/favicon.ico><link rel=apple-touch-icon href=https://askyx.github.io/favicon.ico><link rel=bookmark href=https://askyx.github.io/favicon.ico><link rel=apple-touch-icon-precomposed sizes=180x180 href=https://askyx.github.io/favicon.ico><meta name=twitter:card content="summary"><meta name=twitter:title content="Postgres Hash Join"><meta name=twitter:description content="Postgre hash join 总结"><meta property="og:title" content="Postgres Hash Join"><meta property="og:description" content="Postgre hash join 总结"><meta property="og:type" content="article"><meta property="og:url" content="https://askyx.github.io/posts/hashjoin/"><meta property="article:section" content="posts"><meta property="article:published_time" content="2024-03-08T09:01:31+08:00"><meta property="article:modified_time" content="2024-03-08T09:01:31+08:00"></head><body class=light-theme><div class=container><header class=header><span class=header__inner><a href=https://askyx.github.io/ class=logo style=text-decoration:none><span class=logo__mark><svg xmlns="http://www.w3.org/2000/svg" class="greater-icon" viewBox="0 0 44 44"><path fill="none" d="M15 8l14.729 14.382L15 35.367"/></svg></span><span class=logo__text>Asky</span>
<span class=logo__cursor></span>
</a><span class=header__right><nav class=menu><ul class="menu__inner menu__inner--desktop"><li><a href=/about>About</a></li><li><a href=/archive>Archive</a></li><li><a href=/search>🔍</a></li><li><a href=javascript:; onclick=randomPost() title=随机访问一篇文章><svg t="1660103436159" class="icon search-box-icon" viewBox="0 0 1024 1024" xmlns="http://www.w3.org/2000/svg" p-id="1184" width="32" height="32"><path d="M421.376 481.28s117.248 24.576 175.104-8.704c0 0-89.6 70.144-89.6 166.4.512-.512-8.192-121.344-85.504-157.696zm17.408 487.936s68.608 6.656 68.608-80.896c0 0 3.072 88.576 65.024 78.336.0.512-50.688 22.016-133.632 2.56zM161.28 238.08s-30.208 65.536 11.264 91.648c0 0-67.072-17.408-81.408 37.376.0.0 8.704-82.944 70.144-129.024zM857.6 227.328s49.152 50.176 1.024 81.408c0 0 58.88-18.432 66.56 36.352.0.0 5.12-69.632-67.584-117.76z" p-id="1185"/><path d="M443.392 970.752c-5.632.0-10.752-1.024-15.36-3.072L157.184 810.496l-1.536-1.024s-1.024-1.024-4.608-2.56c-51.2-29.184-62.976-94.208-65.536-120.832V386.56c0-3.072.512-7.168 1.024-11.264l.512-3.584 1.024-2.56c19.456-50.688 76.8-51.2 103.936-44.032l-1.536 5.632 4.096-6.144L476.16 486.4l18.944 37.888c20.992 36.864 29.184 77.824 32.768 99.84v258.048c-4.608 56.32-36.864 76.288-55.808 82.944-1.024.512-15.36 5.632-28.672 5.632zM181.248 774.656l263.168 152.576c12.288-.512 36.864-6.656 40.448-48.128V628.736c-4.608-31.744-20.992-103.936-72.192-128L322.56 445.44l1.536 3.072L181.76 366.08c-2.048-.512-40.448-9.216-52.736 15.872-.512 2.56-.512 4.608-.512 6.144v294.4c1.536 16.896 9.728 67.072 43.52 86.528 3.584 2.048 6.656 4.096 9.216 5.632z" p-id="1186"/><path d="M837.632 212.992c6.656 4.096 12.8 7.168 18.432 10.752l1.536 1.024 1.536 1.536c5.12 4.096 10.752 9.216 16.384 15.36 6.144 11.776 5.632 33.28 4.608 49.152-1.024 12.288-6.656 30.208-26.624 44.544l-1.024.512-247.808 156.672c-26.624 14.336-62.976 18.432-96.256 18.432-40.96.0-77.824-6.656-89.088-8.704l-3.072-.512-245.248-142.336c-39.424-29.696-28.16-85.504-15.36-113.664l2.56-6.144 263.68-166.912c29.184-14.336 104.448-43.008 173.056-1.024 3.584 2.56 58.368 34.304 119.296 69.632M431.616 460.8c40.448 7.168 114.176 13.824 152.576-6.144L828.928 299.52c7.168-5.632 8.192-10.24 8.704-12.8 1.024-11.264-9.728-26.624-15.36-32.768-55.808-32.256-243.712-141.312-250.368-145.408-49.664-30.72-107.008-9.216-130.048 2.56L192.512 268.8c-4.096 12.288-12.288 42.496 3.584 55.808L431.616 460.8z" p-id="1187"/><path d="M831.488 299.008c4.096-1.024 38.4-11.264 66.048 6.144 7.168 4.608 17.92 11.776 24.064 24.576 1.024 5.632 4.096 10.752 4.608 16.896v2.048l-1.024 323.072c-5.12 35.328-22.528 91.648-77.312 125.44l-5.12 3.584h-1.024L579.584 966.656l-4.608.512c-4.096.512-8.704 1.024-12.8 1.024-15.872.0-30.208-5.12-41.984-14.848-24.576-20.48-32.768-55.808-35.328-73.728l-1.024-252.928h1.536c6.144-96.768 88.576-164.864 96.768-171.008l-.512-.512L829.44 299.52M528.384 867.328c.512 10.24 5.12 41.472 19.968 53.76 3.072 2.56 7.68 5.632 16.384 5.12L829.44 758.272c56.32-38.4 53.76-115.712 53.76-116.224l-.512-32.256 1.024-250.368h-.512c-1.536-12.8-7.168-16.384-8.704-17.408-8.704-5.632-23.552-3.072-28.672-2.048L610.304 488.96c-1.024.512-80.896 65.024-80.896 149.504h-1.536l.512 228.864zM435.2 264.192c0 27.648 31.744 50.176 71.168 50.176s71.168-22.528 71.168-50.176-31.744-50.176-71.168-50.176S435.2 236.544 435.2 264.192z" p-id="1188"/><path d="M663.552 782.848c0 30.72-22.528 67.072-49.664 80.384-27.648 13.824-50.176-.512-50.176-31.232s22.528-67.072 50.176-80.384c27.136-13.824 49.664.0 49.664 31.232zM760.32 602.624c0 30.72-22.528 67.072-49.664 80.384-27.648 13.824-49.664-.512-49.664-31.232s22.528-67.072 49.664-80.384c27.136-13.824 49.664.512 49.664 31.232zM867.84 428.032c0 30.72-22.528 67.072-49.664 80.384C790.528 522.24 768 507.904 768 477.184s22.528-67.072 50.176-80.384c27.136-13.824 49.664.0 49.664 31.232zM270.848 538.112c0 30.72-22.016 41.984-48.64 24.576-27.136-16.896-48.64-55.808-48.64-86.528s22.016-41.984 48.64-24.576c26.624 16.896 48.64 55.808 48.64 86.528zm161.28 285.184c0 30.72-22.016 41.984-48.64 24.576-26.624-17.408-48.64-55.808-48.64-86.528s22.016-41.984 48.64-24.576c26.624 16.896 48.64 55.808 48.64 86.528z" p-id="1189"/></svg></a></li></ul><ul class="menu__inner menu__inner--mobile"><li><a href=/about>About</a></li><li><a href=/archive>Archive</a></li><li><a href=/search>🔍</a></li></ul></nav><span class=menu-trigger><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M0 0h24v24H0z" fill="none"/><path d="M3 18h18v-2H3v2zm0-5h18v-2H3v2zm0-7v2h18V6H3z"/></svg></span><span class=theme-toggle><svg class="theme-toggler" width="24" height="24" viewBox="0 0 48 48" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M22 41c10.4934.0 19-8.5066 19-19C41 11.5066 32.4934 3 22 3 11.5066 3 3 11.5066 3 22s8.5066 19 19 19zM7 22C7 13.7157 13.7157 7 22 7V37C13.7157 37 7 30.2843 7 22z"/></svg></span></span></span></header><div class=content><div class=post><div class=breadcrumb><li><a href=https://askyx.github.io/>首页</a></li><li><a href=https://askyx.github.io/posts/>Posts</a></li><li class=active><a href=https://askyx.github.io/posts/hashjoin/>Postgres Hash Join</a></li></div><h2 class=post-title><a href=https://askyx.github.io/posts/hashjoin/>Postgres Hash Join</a></h2><div class=post-meta><span class=post-date>2024-03-08</span></div><div class=post-content><aside class=table-of-contents><nav id=TableOfContents><ul><li><a href=#理论依据>理论依据</a></li><li><a href=#大致过程>大致过程</a><ul><li><a href=#1-scan-inner-table-构造-hashtable>1. Scan <code>inner table</code> ，构造 <code>hashtable</code></a></li><li><a href=#2-scan-outer-table-尝试匹配数据>2. Scan <code>outer table</code> ，尝试匹配数据</a></li></ul></li><li><a href=#并行>并行</a></li><li><a href=#checkpoint>CheckPoint</a></li><li><a href=#其他-数据库-hash-join-实现及优化方案>其他 数据库 Hash join 实现及优化方案</a></li></ul></nav></aside><h2 id=理论依据>理论依据
<a href=#%e7%90%86%e8%ae%ba%e4%be%9d%e6%8d%ae class=h-anchor aria-hidden=true>#</a></h2><p>使用 <code>hybrid hash join</code> 实现的hash join，大意是：<br>outer 和 inner 无法完全使用内存实现 hash join，所以需要把数据分区 dump 到磁盘中，每个分区称为一个 batch，在
优化阶段，会使用已有的统计信息决定分区大小，但是实际执行中， 如果有偏差，则分区按2倍扩容，分区运行时不会减少</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-c++ data-lang=c++><span style=display:flex><span>nbatch    <span style=color:#75715e>// number of batches 
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>nbuckets  <span style=color:#75715e>// buckets in the in-memory hash table
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>
</span></span><span style=display:flex><span>bucketno <span style=color:#f92672>=</span> hashvalue <span style=color:#f92672>%</span> nbuckets
</span></span><span style=display:flex><span>batchno <span style=color:#f92672>=</span> (hashvalue <span style=color:#f92672>/</span> nbuckets) <span style=color:#f92672>%</span> nbatch
</span></span></code></pre></div><p><code>hybrid hash join</code> batch 0 不会落盘，算是一种优化</p><h2 id=大致过程>大致过程
<a href=#%e5%a4%a7%e8%87%b4%e8%bf%87%e7%a8%8b class=h-anchor aria-hidden=true>#</a></h2><h3 id=1-scan-inner-table-构造-hashtable>1. Scan <code>inner table</code> ，构造 <code>hashtable</code>
<a href=#1-scan-inner-table-%e6%9e%84%e9%80%a0-hashtable class=h-anchor aria-hidden=true>#</a></h3><p>可以细分为下面几种情况</p><ol><li>如果判断内存完全可以存下 innert table 的数据，则只使用一个 batch</li><li>否则计算 hashvalue， 使用 hashvalue 计算 batchno ，不属于 batch 0 的数据写到磁盘中对应批次的文件</li><li>如果内存中 hahstable 由于实际使用的数据超过内存上限，则需要进行分裂<br>1. nbatch 翻倍， scan hashtable , 使用新的 nbatch 计算 batchno<br>2. 属于 batch 0 的数据继续放在内存中，其他的 dump 到磁盘对应的文件<br>3. 原来磁盘中已有的文件不动， 后续 probe 的时候才需要重新计算 batch，也可能会写文件</li></ol><h3 id=2-scan-outer-table-尝试匹配数据>2. Scan <code>outer table</code> ，尝试匹配数据
<a href=#2-scan-outer-table-%e5%b0%9d%e8%af%95%e5%8c%b9%e9%85%8d%e6%95%b0%e6%8d%ae class=h-anchor aria-hidden=true>#</a></h3><p>和第一步情况类似</p><ol><li>读取 outer table 的数据，计算 hashvalue， 使用 nbatch 计算 batchno ，这里需要注意的是 nbatch 是最新值，前面构造 hashtable 的时候可能发生变化</li><li>如果 batchno 匹配当前 hashtable ， 则尝试进行匹配</li><li>否则写磁盘到对应批次的文件中<ul><li>这里需要注意的是，由于之前 inner table 构造 hashtable 的过程中，如果发生 分裂， 则批次较前的临时文件比较大，因为文件中的数据可能不全 属于这一批， 但是对于 outer table，由于是使用新的 nbatch 计算的，所以 tuple 会更分散，所以直观的感受就是临时文件大小是明显小于 inner table 的文件</li></ul></li><li>处理完当前 批次，则读取磁盘中下一个 batch 文件，此时 inner 表的 hahstable 可能是分裂之前的批次，需要使用新的 nbatch 处理，也可能写磁盘</li><li>重复处理完所有的文件即可</li></ol><h2 id=并行>并行
<a href=#%e5%b9%b6%e8%a1%8c class=h-anchor aria-hidden=true>#</a></h2><p>并行需要区分不同的执行计划</p><ol><li>hash join 并行，但是 hash 不并行<br>inner 侧会在各自得 worker 私有内存中构建 hashtable，然后并行 scan outer，进行 hash join，最终得结果就是 gather 之后得结果</li><li>hash join 并行，hash 并行<br>inner 侧会在 共享内存中构建一个 hashtable，大小为 <code>work_memo * hash_mem_multiplier * num_workers</code>， 所有的 inner tuple 存入这个 hashtable 中。并行 scan outer，进行 hash join</li></ol><p>再加上非并行 hash ， hash join 一般有三种情况， inner 并行。 但是 outer 不并行的情况一般没有， 因为 outer 一般是大表</p><p>并行有下面几点需要注意：</p><ul><li>hash 是一个单独得算子，所以是否并行是可以单独使用参数 enable_parallel_hash 控制的</li><li>hash 的并行也需要考虑内存中是否能完全处理 inner tuple 的情况<ul><li>如果不能，则除了 batch 0 之外的数据需要 dump 到磁盘</li><li>由于此时是使用 SharedTuplestore 进行管理，所以可能存在多个 worker 都写如到一个文件的情况， 可能导致文件太大，后面 load 的时候超过内存限制<ul><li>所以判断如果此时文件太大，是否需要增加 nbatch 重新计算位置</li></ul></li></ul></li><li>如果 nbatch 大于1， outer table 也需要 进行类似的分区操作，把不属于 batch 0 的数据 dump 到文件<ul><li>nbatch 0 则直接读取即可</li></ul></li><li>batch 0 消耗完，则读取下一个文件，构造 hashtable</li></ul><h2 id=checkpoint>CheckPoint
<a href=#checkpoint class=h-anchor aria-hidden=true>#</a></h2><ol><li><p>避免频繁文件读写， 可以适当加大 work_mem, 或者调节 <code>hash_mem_multiplier</code></p></li><li><p>优化器会读取统计信息， 避免数据倾斜的情况，如果存在数据倾斜，则优先把倾斜的数据存放在内存中，使用专门的 skewBucket 管理</p><ul><li>但是也需要注意内存的使用量，如果 hashtable 达到内存限制， 则会把最后一个 skewBucket dump 到其对应的临时文件中</li></ul></li><li><p>但是对于 NULL 值</p><ul><li>并不收集 MCV 信息，所以 key 存在大量 NULL ，且是 outer join 得时候， 可能由于估算不准确，导致 hahstable 分裂频繁</li><li>此时会 NULL 值的 hashtable 会消耗大量 内存</li><li>并且由于此时 nbatch 增加，所以可能导致数据分散到大量的文件中，可能导致产生大量的临时文件，且由每个文件的大小达不到 flush 的标准，不但会消耗 inode， 又会加剧内存的消耗</li></ul></li><li><p>对于是否需要保留 null 值取决于是不是 outer join ， 使用 HJ_FILL_INNER 和 HJ_FILL_OUTER 判断</p><ul><li>输出的时候，由状态 HJ_FILL_OUTER_TUPLE 和 HJ_FILL_INNER_TUPLES 管理</li></ul></li><li><p>对于并行</p><ul><li>这里是 能者多劳 的原则，当新 worker 需要工作的时候， 如果没有多余的任务，例如空闲的 file ，是不会处于等待状态的，他也会加入到 probe 状态中</li><li>使用 barrier 划分整个 hash join 为 不同的阶段， 用于不同 worker 之间的任务同步</li><li>读取文件构造 hashtable 的时候，不一定是一个 worker 独占一个 file 。会存在 不同的 worker 读取同一个 file 的可能</li><li>假如 batch0 频繁分裂，部分数据已经写到文件了，此时处理后续数据的时候，没有看见重新计算之前文件的 tuple hash，在 <code>ExecParallelHashJoinNewBatch</code> 中的 <code>ExecParallelHashTableInsertCurrentBatch</code> 看见 <code>Assert(batchno == hashtable->curbatch);</code> ，这是怎么保证的 ？</li></ul></li></ol><h2 id=其他-数据库-hash-join-实现及优化方案>其他 数据库 Hash join 实现及优化方案
<a href=#%e5%85%b6%e4%bb%96-%e6%95%b0%e6%8d%ae%e5%ba%93-hash-join-%e5%ae%9e%e7%8e%b0%e5%8f%8a%e4%bc%98%e5%8c%96%e6%96%b9%e6%a1%88 class=h-anchor aria-hidden=true>#</a></h2><ul><li>比较明显的一点是 Hash join 需要在 inner table 构造完 hahstable 之后才启动 outer table，所以完全可以在构造 inner table 的时候，采集 inner table 的信息，用于提前过滤 outer table 的信息<ul><li>当前部分 MPP 数据库已经实现功能 <code>Runtime Filter</code></li><li>可进行动态分区裁剪，和 <code>Runtime Filter</code> 类似的思路</li></ul></li><li>特殊 条件下，可以在 build hash table 之后，直接判定 join 是否有结果返回， 例如 <code>left anti semi join (not in)</code>，gp 实现 <a href=https://smartkeyerror.com/Greenplum-Squelch>Squelch</a> 功能(当然此功能不仅仅只是 hash join 使用)</li><li>Partition Hash Join， 对 hash table 进行分区，确保所有分区可以 fit in cache</li><li>Hash Join 最大问题在于 cache miss ， 其性能损耗可能超过 70%<ul><li><a href=https://zhuanlan.zhihu.com/p/666465496>使用计算掩盖 cache miss 的时间</a>，使用 coroutine 实现，依据就是 协程的切换时间需要小于 cache miss 的 prefetch 时间</li><li>协程 需要是 无栈协程，有栈协程 可能 没有这个先决条件 ？</li><li>没有深究，但是有效， mark 一下</li></ul></li></ul><hr><ul><li><p>需要继续了解 pg 的内存模型以及进程间的消息通信机制</p></li><li><p><a href=https://zhuanlan.zhihu.com/p/636313646>ref1</a></p></li><li><p><a href=https://blog.csdn.net/qq_42604176/article/details/119275967>ref2</a></p></li><li><p><a href=https://blog.csdn.net/weixin_54551388/article/details/127020336>ref3</a></p></li><li><p><a href=https://zhuanlan.zhihu.com/p/112003245>ref4</a></p></li></ul></div><div class=pagination><div class=pagination__title><span class=pagination__title-h>Read other posts</span><hr></div><div class=pagination__buttons><span class="button previous"><a href=https://askyx.github.io/posts/orca/><span class=button__icon>←</span>
<span class=button__text>orca 简记</span>
</a></span><span class="button next"><a href=https://askyx.github.io/posts/build/><span class=button__text>源码编译 OpenTenBase 速通版</span>
<span class=button__icon>→</span></a></span></div></div></div></div><footer class=footer><div class=footer__inner><a href=https://askyx.github.io/ class=logo style=text-decoration:none><span class=logo__mark><svg xmlns="http://www.w3.org/2000/svg" class="greater-icon" viewBox="0 0 44 44"><path fill="none" d="M15 8l14.729 14.382L15 35.367"/></svg></span><span class=logo__text>Asky</span>
<span class=logo__cursor></span></a><div class=copyright><span>© 2025 Powered by
<a href=https://gohugo.io target=_blank rel=noopener>Hugo</a></span>
<span>Theme created by
<a href=https://twitter.com/panr target=_blank rel=noopener>panr</a></span></div></div></footer><script src=https://askyx.github.io/assets/main.js></script><script src=https://askyx.github.io/assets/prism.js></script></div></body></html>