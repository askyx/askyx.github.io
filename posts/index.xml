<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Posts on Asky</title><link>https://askyx.github.io/posts/</link><description>Recent content in Posts on Asky</description><generator>Hugo -- gohugo.io</generator><language>en</language><lastBuildDate>Fri, 10 May 2024 15:01:17 +0800</lastBuildDate><atom:link href="https://askyx.github.io/posts/index.xml" rel="self" type="application/rss+xml"/><item><title>TPC-DS 测试</title><link>https://askyx.github.io/posts/tpc-ds/</link><pubDate>Fri, 10 May 2024 15:01:17 +0800</pubDate><guid>https://askyx.github.io/posts/tpc-ds/</guid><description>
TPC-DS 测试简记</description></item><item><title>Postgres Hash Join</title><link>https://askyx.github.io/posts/hashjoin/</link><pubDate>Fri, 08 Mar 2024 09:01:31 +0800</pubDate><guid>https://askyx.github.io/posts/hashjoin/</guid><description>
Postgre hash join 总结</description></item><item><title>源码编译 GreenPlum 速通版</title><link>https://askyx.github.io/posts/build/</link><pubDate>Fri, 05 Jan 2024 11:07:23 +0800</pubDate><guid>https://askyx.github.io/posts/build/</guid><description>
docker GreenPlum 源码编译</description></item><item><title>源码编译 OpenTenBase 速通版</title><link>https://askyx.github.io/posts/build/</link><pubDate>Fri, 05 Jan 2024 11:07:23 +0800</pubDate><guid>https://askyx.github.io/posts/build/</guid><description>
docker OpenTenBase 源码编译</description></item><item><title>源码编译环境准备文件</title><link>https://askyx.github.io/posts/env_common/</link><pubDate>Fri, 05 Jan 2024 09:07:23 +0800</pubDate><guid>https://askyx.github.io/posts/env_common/</guid><description>
docker 源码编译 dockerfile 模板</description></item><item><title>名词一行解释</title><link>https://askyx.github.io/posts/one_line/</link><pubDate>Thu, 21 Dec 2023 16:28:35 +0800</pubDate><guid>https://askyx.github.io/posts/one_line/</guid><description>
重点名词解释，不一定是不知道，只是一下子想不起来，有个提示可以辅助回忆，自用</description></item><item><title>cmake 速查模板</title><link>https://askyx.github.io/posts/cmake/</link><pubDate>Wed, 09 Aug 2023 17:34:54 +0800</pubDate><guid>https://askyx.github.io/posts/cmake/</guid><description>
cmake 速查模板，自用</description></item><item><title>gdb 要点简记</title><link>https://askyx.github.io/posts/gdb/</link><pubDate>Tue, 11 Jul 2023 10:17:52 +0800</pubDate><guid>https://askyx.github.io/posts/gdb/</guid><description>
gdb 中的一些常用方法，一些常用的命令，记忆 gdb 的 python 扩展的使用方法</description></item><item><title>Postgres 技术内幕，Optimizer过程分析</title><link>https://askyx.github.io/posts/optimizer/</link><pubDate>Mon, 08 May 2023 11:33:02 +0800</pubDate><guid>https://askyx.github.io/posts/optimizer/</guid><description>
深度优化探索文章的读书笔记</description></item><item><title>宏使用模板速查</title><link>https://askyx.github.io/posts/defineinc/</link><pubDate>Wed, 22 Feb 2023 14:00:48 +0800</pubDate><guid>https://askyx.github.io/posts/defineinc/</guid><description>
宏模板，自用</description></item><item><title>执行计划代价计算规则梳理</title><link>https://askyx.github.io/posts/cost/</link><pubDate>Fri, 17 Feb 2023 09:38:28 +0800</pubDate><guid>https://askyx.github.io/posts/cost/</guid><description>
pg中各个算子的代价计算</description></item><item><title>Postgres Executor</title><link>https://askyx.github.io/posts/postgres_executor/</link><pubDate>Fri, 10 Feb 2023 09:26:50 +0800</pubDate><guid>https://askyx.github.io/posts/postgres_executor/</guid><description>
Postgres 执行器 及其扩展 总结</description></item><item><title>事务知识简记</title><link>https://askyx.github.io/posts/tx/</link><pubDate>Wed, 08 Feb 2023 09:58:09 +0800</pubDate><guid>https://askyx.github.io/posts/tx/</guid><description>
事务分析记录，源码分析，关键技术点简记，唬人专用</description></item><item><title>Bison Note</title><link>https://askyx.github.io/posts/note/</link><pubDate>Thu, 17 Nov 2022 14:34:14 +0800</pubDate><guid>https://askyx.github.io/posts/note/</guid><description>
bison 文档重点记录</description></item><item><title>Libpqxx</title><link>https://askyx.github.io/posts/libpqxx/</link><pubDate>Tue, 08 Nov 2022 14:35:50 +0800</pubDate><guid>https://askyx.github.io/posts/libpqxx/</guid><description>
libpqxx分析</description></item><item><title>内存管理</title><link>https://askyx.github.io/posts/memctx/</link><pubDate>Tue, 01 Nov 2022 12:01:31 +0800</pubDate><guid>https://askyx.github.io/posts/memctx/</guid><description>
内存上下文 # https://smartkeyerror.com/PostgreSQL-MemoryContext 源码主要在mctx.c中，主要是目的是设置工作空间，避免重复的在系统上申请资源，且为了避免异常情况下的内存泄露问题，所以实现了内存上下文
目前有三种底层的实现 AllocSet(常规的内存分配机制，先分配block，之后再从block上分配chunk，分配得内存一般不会释放，而是使用空闲链表管理) Generation(新加，内存生命周期相近的时候使用，目前只在gist 和 replication 模块使用) Slab(分配大小等大的chunk，目前只在replication 模块使用) 更多的是因为频繁的malloc会导致内存碎片，且由于malloc需要额外的空间记录head和foot的位置，所以还存在的问题就是空间的浪费，另外最大的问题是内存泄漏问题，使用指针在方法间传递不容易管理 大概类似c++的内存管理方法，把 #</description></item><item><title>RocksDB源码分析</title><link>https://askyx.github.io/posts/rocksdb/</link><pubDate>Fri, 21 Oct 2022 16:38:26 +0800</pubDate><guid>https://askyx.github.io/posts/rocksdb/</guid><description>
RocksDB 源码总结分析</description></item><item><title>postgres Parser</title><link>https://askyx.github.io/posts/parser/</link><pubDate>Mon, 10 Oct 2022 12:03:18 +0800</pubDate><guid>https://askyx.github.io/posts/parser/</guid><description>
Postgres parser 模块解析，目的是为了学习parser实现机制。编译原理以及bison和flex的使用</description></item><item><title>Locks</title><link>https://askyx.github.io/posts/locks/</link><pubDate>Wed, 28 Sep 2022 15:42:18 +0800</pubDate><guid>https://askyx.github.io/posts/locks/</guid><description>
PG 中锁的分析</description></item><item><title>vacuum 和 analyze 过程分析</title><link>https://askyx.github.io/posts/vacuum/</link><pubDate>Mon, 26 Sep 2022 16:37:37 +0800</pubDate><guid>https://askyx.github.io/posts/vacuum/</guid><description>
AntDB VACUUM 流程</description></item><item><title>Postgres Optimizer</title><link>https://askyx.github.io/posts/opt/</link><pubDate>Fri, 22 Jul 2022 09:24:24 +0800</pubDate><guid>https://askyx.github.io/posts/opt/</guid><description>
本文从源码级别进行优化器的分析，对Postgres优化器代码调研，具体包括他的数据结构，以及具体的代码架构实现以及核心算法等</description></item><item><title>Postgres Storage</title><link>https://askyx.github.io/posts/storage/</link><pubDate>Thu, 21 Jul 2022 09:15:05 +0800</pubDate><guid>https://askyx.github.io/posts/storage/</guid><description>
存储 # 内存 # 共享内存
本地内存
缓存
内存上下文
缓存空间管理
数据块的缓存，减少磁盘IO，有共享缓存和进程缓存
Cache
数据块之外的缓存，例如系统表
系统表缓存不会缓存整个表，是以block为单位缓存？ 虚拟文件描述符
系统中文件有打开的上限，使用VFD可以突破这种限制，本质上是一个LRU缓存
空闲空间定位
快速定位磁盘中的空闲空间以插入数据
进程间通信 使用共享内存或者信号量通信
读取过程 # 从系统表中读取表的元数据信息构造元组信息 尝试从缓存读取数据 使用SMGR从磁盘读取数据到缓存中，SMGR是一个抽象层，用于实现不同存储介质的管理 SMGR和存储介质之间使用VFD来管理文件描述符，以突破系统的FD限制 标记删除，vacuum清理数据 FSM记录空闲空间 磁盘 # 表文件
SMGR
VFD
FSM
select * from pg_relation_filepath(&amp;lsquo;idx&amp;rsquo;);
Page 结构 # 工具汇总说明
create extension pageinspect; get_raw_page(relname text, fork text, blkno int) 返回执行表的page，text指定类型，默认是main，代表普通page，使用fsm或者vm查看其他类型，可以省略 page_header(page bytea) 查看page头，输入是page数组，使用上面的函数的输出作为参数 fsm_page_contents(page bytea) returns text 查看fsm页面结构 SELECT fsm_page_contents(get_raw_page(&amp;#39;t1&amp;#39;, &amp;#39;fsm&amp;#39;, 0)); === HEAP相关 heap_page_items(page bytea) 查看page的具体信息 heap_tuple_infomask_flags(t_infomask integer, t_infomask2 integer) returns record 查看mask的具体含义，具体的使用方法为 SELECT * FROM heap_page_items(get_raw_page(&amp;#39;a&amp;#39;, 0)), LATERAL heap_tuple_infomask_flags(t_infomask, t_infomask2) WHERE t_infomask IS NOT NULL OR t_infomask2 IS NOT NULL order by lp desc; 输出为 t_infomask2 | t_infomask | t_hoff | t_bits | t_oid | t_data | raw_flags | combined_flags -------------+------------+--------+----------+-------+------------+--------------------------------------------------------------------------+---------------- 3 | 2305 | 24 | 10000000 | | \x02000000 | {HEAP_HASNULL,HEAP_XMIN_COMMITTED,HEAP_XMAX_INVALID} | {} 8195 | 1281 | 24 | 10000000 | | \x01000000 | {HEAP_HASNULL,HEAP_XMIN_COMMITTED,HEAP_XMAX_COMMITTED,HEAP_KEYS_UPDATED} | {} 主要目的是查看数据的mask的信息 === Btree相关 bt_metap(relname text) 查看btree元数据信息 bt_page_stats(relname text, blkno int) 查看btree page的统计信息 bt_page_items(relname text, blkno int) 或者 bt_page_items(page bytea) returns setof record 查看具体的信息，可以指定index或者直接使用page byte typedef struct PageHeaderData { /* XXX LSN is member of *any* block, not only page-organized ones */ PageXLogRecPtr pd_lsn; /* LSN: next byte after last byte of xlog record for last change to this page */ uint16 pd_checksum; /* checksum */ uint16 pd_flags; /* flag bits, see below */ LocationIndex pd_lower; /* offset to start of free space */ LocationIndex pd_upper; /* offset to end of free space */ LocationIndex pd_special; /* offset to start of special space */ uint16 pd_pagesize_version; TransactionId pd_prune_xid; /* oldest prunable XID, or zero if none */ ItemIdData pd_linp[FLEXIBLE_ARRAY_MEMBER]; /* line pointer array */ } PageHeaderData; void PageInit(Page page, Size pageSize, Size specialSize) { PageHeader p = (PageHeader) page; specialSize = MAXALIGN(specialSize); Assert(pageSize == BLCKSZ); Assert(pageSize &amp;gt; specialSize + SizeOfPageHeaderData); /* Make sure all fields of page are zero, as well as unused space */ MemSet(p, 0, pageSize); p-&amp;gt;pd_flags = 0; p-&amp;gt;pd_lower = SizeOfPageHeaderData; p-&amp;gt;pd_upper = pageSize - specialSize; p-&amp;gt;pd_special = pageSize - specialSize; PageSetPageSizeAndVersion(page, pageSize, PG_PAGE_LAYOUT_VERSION); /* p-&amp;gt;pd_prune_xid = InvalidTransactionId; done by above MemSet */ } 大小为 pageSize，默认为8k，最开始是PageHeader，</description></item><item><title>Postgres源码编译及调试</title><link>https://askyx.github.io/posts/env/</link><pubDate>Wed, 20 Jul 2022 17:54:05 +0800</pubDate><guid>https://askyx.github.io/posts/env/</guid><description>
Postges 源码环境搭建，Ubuntu22，VSCode，docker</description></item><item><title>数据库文章资源汇总</title><link>https://askyx.github.io/posts/note/</link><pubDate>Wed, 20 Jul 2022 17:44:29 +0800</pubDate><guid>https://askyx.github.io/posts/note/</guid><description>
爬虫 # import requests from bs4 import BeautifulSoup prefix = &amp;#39;http://mysql.taobao.org&amp;#39; # 获取文章名和url（文章名,url） def query_name_url(url: str): resp = requests.get(url) soup = BeautifulSoup(resp.content.decode(&amp;#39;utf-8&amp;#39;), &amp;#34;html.parser&amp;#34;) tags = soup.findAll(&amp;#39;a&amp;#39;, {&amp;#39;target&amp;#39;: {&amp;#39;_top&amp;#39;}}) urls = [v for v in tags if v[&amp;#39;href&amp;#39;].find(&amp;#39;/monthly/&amp;#39;) != -1] return [(str(v.string).strip(), prefix + v[&amp;#39;href&amp;#39;]) for v in urls] # 获取所有月报链接（月报名,url） def query_monthly_url(): resp = requests.get(&amp;#39;http://mysql.taobao.org/monthly/&amp;#39;) soup = BeautifulSoup(resp.content.decode(&amp;#39;utf-8&amp;#39;), &amp;#34;html.parser&amp;#34;) tags = soup.findAll(&amp;#39;a&amp;#39;, {&amp;#39;class&amp;#39;: {&amp;#39;main&amp;#39;}}) urls = [v for v in tags if v[&amp;#39;href&amp;#39;].find(&amp;#39;/monthly/&amp;#39;) != -1] return [(str(v.string).strip(), prefix + v[&amp;#39;href&amp;#39;]) for v in urls] # 获取所有文章名、URL和对应的月报链接（文章类型，文章名，url，月报名，url） def query_all_name_url(): result = [] monthly_urls = query_monthly_url() for data1 in monthly_urls: name_urls = query_name_url(data1[1]) for data2 in name_urls: result.</description></item><item><title>15445课程笔记</title><link>https://askyx.github.io/posts/note/</link><pubDate>Fri, 10 Jun 2022 11:07:10 +0800</pubDate><guid>https://askyx.github.io/posts/note/</guid><description>
https://15445.courses.cs.cmu.edu/fall2021/notes/02-advancedsql.pdf
output control 控制输出结果，例如order，limit等 窗口函数 CTE Common Table Expressions，把一个语句的输出视为一张临时表参与下面的语句的运算 WITH cte1 (col1) AS (SELECT 1), cte2 (col2) AS (SELECT 2) SELECT * FROM cte1, cte2; Database Storage # 数据库的存储介质当前还是磁盘，IO慢 数据库存储要点之一是使用缓存维护数据在磁盘和内存之间的数据交换，以实现数据的快速读写 顺序读写和随机读写 顺序读写的意思是需要定位到读写的位置才能操作，例如链表。 随机读写的意思是可以直接定位到读写的位置，例如数组。 由于磁盘上随机读写速度不如顺序读写，所以当前数据库还是需要想办法使用顺序读写，例如LSM，GFS等架构都是因为这个原因导致的 磁盘和内存中数据的组织格式 # 数据全部在磁盘上，按page组织数据，内存中使用buffer pool维护缓存，磁盘中有一个page专门维护page的位置信息，使用的时候先读取此page到内存，然后 然后读取其他page到buffer pool，使用buffer pool维护page的置换情况，例如LRU，或者其他算法
可以参考lab1和slide，还是比较明显的
buffer pool中的page可以用于上层的数据运算
使用mmap可以完成类似的操作，但是实际上在使用中，如果在发生缺页中断的时候，mmap需要进行置换操作，所以会阻碍程序进程。且mmap是通用的组件，所以没有对数据库 的使用场景进行一些优化，
You never want to use mmap in your DBMS if you need to write. The DBMS (almost) always wants to control things itself and can do a better job at it since it knows more about the data being accessed and the queries being processed. The operating system is not your friend. 最好是需要什么就自己实现什么，
数据组织形式 # 文件</description></item><item><title>Raft</title><link>https://askyx.github.io/posts/raft/</link><pubDate>Mon, 30 May 2022 18:51:02 +0800</pubDate><guid>https://askyx.github.io/posts/raft/</guid><description>
译文 原文 有用的飞书文档 和其他的算法相比 Strong leader
日志只能从领导者发送到其他节点 Leader election
随机计时器选举领导，在心跳机制上加上一些额外的工作 Membership changes
角色变换 Replicated state machines # 复制状态机一般基于日志实现，通俗的理解只要所有的机器按照相同的顺序执行指令，那么每个节点的状态都是确定的，所以需要把指令日志复制到其他节点上去，这就是一致性算法的工作
如果只是要求最终所有的节点都执行一样顺序的指令，而不要求实时性，则可以限定
只有一个节点可以进行写操作，因为只有写操作才可以改变系统的状态 写节点同步指令到其他节点，最终所有节点指令顺序一致 一致性算法的共有特性
安全性
不会返回一个错误结果，只要是在非拜占庭错误情况下，包括网络延迟，乱序，丢包，分区，冗余等都可以保障正确性 可用性
集群只要大多数机器可以正常通信，就可以确保可用，失败节点可以忽略或者后续恢复状态，大多数指的是半数以上 不依赖时序保证一致性
时钟错误或者消息延迟只有在极端情况下才会导致可用性 慢节点不会影响消息的反馈，消息可以快速的响应 拜占庭将军问题
Paxos # 难以理解 没有公认的可以实现的基础架构，大部分系统从Paxos开始，在遇到问题的时候自行想办法解决，导致最后的系统实现只能是类似Paxos的算法 Raft # 管理复制状态机的一种算法，他会在集群中选举一个leader，之后会复制所有的日志到其他节点实现一致性
他可以分解为三个问题
领导选举 一个新的领导人需要被选举出来，当先存的领导人宕机的时候 日志复制
领导人必须从客户端接收日志然后复制到集群中的其他节点，并且强制要求其他节点的日志保持和自己相同 安全性
在 Raft 中安全性的关键是在图 3 中展示的状态机安全：如果有任何的服务器节点已经应用了一个确定的日志条目到它的状态机中，那么其他服务器节点不能在同一个日志索引位置应用一个不同的指令 可以在这个网站查看实例
节点有三种状态 Follower Candidate Leader 他们之间的转换关系如下图 任期在 Raft 算法中充当逻辑时钟的作用，这会允许服务器节点查明一些过期的信息比如陈旧的领导者。每一个节点存储一个当前任期号，这一编号在整个时期内单调的增长。当服务器之间通信的时候会交换当前任期号；如果一个服务器的当前任期号比其他人小，那么他会更新自己的编号到较大的编号值。如果一个候选人或者领导者发现自己的任期号过期了，那么他会立即恢复成跟随者状态。如果一个节点接收到一个包含过期的任期号的请求，那么他会直接拒绝这个请求。
下面是详细的细节参数 下面的参数要求在节点上持久存在
currentTerm
服务器最后一次知道的任期号，初始化为 0，持续递增 votedFor
当前获得选票的候选人的Id log[]
日志条目集；每一个条目包含一个用户状态机执行的指令，和收到时的任期号 下面的参数在节点上是随时变化的
commitIndex
已知的最大的已经被提交的日志条目的索引值 lastApplied
最后被应用到状态机的日志条目索引值，初始化为 0，持续递增 下面的参数需要在leader重新选举之后变化的
nextIndex[]
对于每一个服务器，需要发送给他的下一个日志条目的索引值，初始化为领导人最后索引值加一 matchIndex[]
对于每一个服务器，已经复制给他的日志的最高索引值 这篇图表示的是rpc的参数信息以及返回值，由领导人负责调用来复制日志指令；也会用作heartbeat 参数
term
领导人的任期号 leaderId
领导人的 Id，以便于跟随者重定向请求 prevLogIndex
新的日志条目紧随之前的索引值 prevLogTerm
prevLogIndex 条目的任期号 entries[]
准备存储的日志条目，表示心跳时为空；一次性发送多个是为了提高效率 leaderCommit
领导人已经提交的日志的索引值 返回值
term
当前的任期号，用于领导人去更新自己 success
跟随者包含了匹配上 prevLogIndex 和 prevLogTerm 的日志时为真 如果 term &amp;lt; currentTerm 就返回 false 如果日志在 prevLogIndex 位置处的日志条目的任期号和 prevLogTerm 不匹配，则返回 false 如果已经已经存在的日志条目和新的产生冲突（相同偏移量但是任期号不同），删除这一条和之后所有的 附加任何在已有的日志中不存在的条目 如果 leaderCommit &amp;gt; commitIndex，令 commitIndex 等于 leaderCommit 和 新日志条目索引值中较小的一个 由候选人负责调用用来征集选票</description></item><item><title>GFS</title><link>https://askyx.github.io/posts/gfs/</link><pubDate>Mon, 30 May 2022 16:36:40 +0800</pubDate><guid>https://askyx.github.io/posts/gfs/</guid><description>
GFS是一个大规模可扩展的可容错的分布式文件系统。Google三大篇论文之一
翻译文章在这里
论文在这里
6.824 Q&amp;amp;A
GFS的特点 运行在廉价的机器上，节约成本 灵活性强，可随意扩展，容错性强 文件尾部追加数据，不会有太多的数据变动 架构 # 一个单独的master节点和多个datachunk节点，maste管理元数据信息，包括chunkhandle信息，文件和chunk的映射信息，以及chunkserver的变动信息等。master使用心跳定时和chunkserver同步关键信息。使用单个master的目的是为了简化设计，同时为了避免单点故障，master节点每次操作都和backup master同步数据，master存储的3种关键元数据为
文件和Chunk的命名空间 文件和Chunk的对应关系 每个Chunk副本的存放地点
存放在master上，在chunkserver变动的时候难以维护，每个server自己维护自己的信息，然后让master自行同步的方式会简单许多。 这些信息保存在内存中，且1和2的数据变动会保存在日志文件中，每次mater故障恢复的时候，只需要使用此日志就可以恢复到原来的状态，至于3，则保存在chunkserver中，master会使用心跳定时从chunkserver更新此信息到内存中，master的内存承载能力一般是可以维护这些数据，一条master中的信息可以维护一个chunk，一般一条信息可以在64内保存下来，且由于数据的在小范围变化不大，使用一定的压缩方法可以大大的节约空间。 日志记录上面1和2的数据变动信息，用于故障恢复，为了避免日志信息过于庞大，加入检查点机制，恢复时只要回放检查点之后的日志即可。
chunkserver保存chunk数据，同时维护server上的chunk信息，GFS把大文件切分为64M的chunk文件，64M的原因是
Google实际存储的数据较大其大部分时候使用顺序读写文件，所以大文件的读写时间可以在接受范围内 大文加可以减少master中的元数据信息，读写的时候，可以对一个大文件进行多次读写，避免了小文件需要多次向master查询位置信息 大文件可以避免小文件反复从server读取，使server变成热点 chunk一般是3个数据副本
读取操作 # C sends filename and offset to coordinator (CO) (if not cached) CO finds chunk handle for that offset CO replies with list of chunkhandles + chunkservers only those with latest version C caches handle + chunkserver list C sends request to nearest chunkserver chunk handle, offset chunk server reads from chunk file on disk, returns to client 一致性问题 # 弱一致性。易实现， 随机写会有offset重复的问题，但是master限定操作顺序，理论上最终的数据是一致的，但是在client看来，数据是不确定的，因为副本不是要求立刻同步的， append only限定append的offset，所以每个offset上数据是一致的</description></item><item><title>Mapreduce</title><link>https://askyx.github.io/posts/mapreduce/</link><pubDate>Sun, 29 May 2022 21:05:46 +0800</pubDate><guid>https://askyx.github.io/posts/mapreduce/</guid><description>
利用普通机器组成的大规模计算集群进行并行的,高容错,高性能的数据处理函数框架
原始论文点这里,论文翻译点这里，有时间的话，自行对比翻译和原文
最终实现的目标是&amp;ndash;实现一个分布式系统，对程序员隐藏底层分布式细节，程序员只需要定义map和reduce 函数即可。
map reduce实现为简单的kv输出，其中map接受源数据，生成kv的中间结果，中间结果保存在worker节点上。 reduce负责处理map产生的中间结果的kv数据，只是简单的数据处理过程.
他最先是受到lisp中map和reduce原语的启发，再加上当时Google现实的处理大量数据的需求，从他们现有的系统抽象而来的。
在论文中，使用了一个单词统计的案例，此时实现map函数用来分割文本，切分出最基本的单词。然后再使用reduce进行聚合操作，
// 输出单词以及出现的次数，map端输出1 map(String key,String value): // key: 文档名 // value: 文档内容 for each word w in value: EmitIntermediate(w,&amp;#34;1&amp;#34;); // 针对相同的key，次数+1 reduce(String key, Iterator values): // key: 一个单词 // value: 计数值列表 int result = 0; for each v in values: result += ParseInt(v); Emit(AsString(result)); 执行过程 文件划分 主节点划分任务 按照划分的任务启动worker，执行map任务 worker节点的数据生成为中间结果，保存在本节点 所有map任务执行完成之后，reduce得到对应中间节点的文件路径，通过rpc读取文件，进行reduce任务 reduce任务完成之后，最终结果写入目标文件 一个mr任务完成之后，回得到n(reduce)个结果文件，可以按照需求处理文件，可以直接使用，或者继续作为其他mr的输入，mr任务是可以嵌套的。
主节点
记录map和reduce任务的状态，例如是否开始，是否结束，执行时间等 协调工作节点，确定工作状态。确定任务是否需要重试，是否需要back up等 容错性
工作节点失败
主机点定时检测工作节点状态，如果无法链接，此时需要把此丢失的工作节点上的所有的任务重新安排到其他节点上执行。包括已完成的map任务，因为mr任务是需要等所有map任务结束之后才能执行reduce任务，其map任务的数据在保存在worker节点上的。所以需要重新执行map任务。至于reduce任务，由于他的输出之最终的数据结果，且需要记录到文件。所以为了避免重复的数据产生，已完成的reduce任务不重试，前提是输出数据已经保存到其他节点上。 主节点错误 一般是直接重试整个mr任务，因为mr的主节点应该是需要选择集群中比较可靠的节点，此时有理由怀疑其他节点也可能出现问题，所以此时选择整个重新执行，当然也可以恢复主节点，从记录的回复点重新执行 backup task mr中由于任务切分不一定均衡或者不同节点计算能力不同，有的任务执行格外慢，此时可以在其他空闲节点上执行相同的任务，此时集群中可能有多个相同的任务，最终哪一个任务先完成，主节点就会终止其他未完成的工作节点。
上面就是原始的mr描述，理所当然的可以想到一些提升的地方
平均的划分任务文件，尽量任务均衡 流式计算，在中间结果产生的时候，直接保存中间文件到reduce节点，避免最后集中处理中间结果时候的网络带宽消耗 本地计算mr，有的mr任务没必要在不同节点上执行，直接划分到一个节点或把的某些任务划分到一个节点上，实现本地计算。避免网络IO 提前进行reduce操作，可以使用reduce任务提前处理中间结果，减少中间结果的大小 记录计算节点的状态，多次执行任务的时候，可以记录某节点的处理速度，在下一个mr任务划分的时候，按照此信息划分任务 https://www.zhihu.com/question/303101438
map和reduce之间是完全串行的，如果有多个MR任务嵌套的话，由于每个mr必须实现map和reduce，会导致链路过长，实现和调试困难 性能无法达到要求 6.824 LAB # 先掌握go，重点为go的协程，管道，以及channel 代码框架已经给出来了，需要自己实现分布式的worker和master 可以先实现简单的无状态的mr，可以通过test-mr.sh中的前面的测试 worker # map和reduce的执行节点，需要从master获得任务，按照任务的类型，执行不同的job
func Worker(mapf func(string, string) []KeyValue, reducef func(string, []string) string) { for { job := getJob() if job.</description></item><item><title>A Tour of Go速通</title><link>https://askyx.github.io/posts/go_1/</link><pubDate>Tue, 17 May 2022 22:34:11 +0800</pubDate><guid>https://askyx.github.io/posts/go_1/</guid><description>
2022-05-17 基础语法 2022-05-24 复合类型，goroutine，channel 基础语法 # Packages # go使用Packages维护模块，使用import导入模块，import最后一个元素才是需要导入的模块
import ( &amp;#34;fmt&amp;#34; &amp;#34;math/rand&amp;#34; ) import 可以单独一个导入一个模块，也可以批量导入， 与之对应的是export，go不显示声明export，首字母大写的变量或方法自动export，外部只能使用导出的变量或者方法，类似c++中类的私有和共有的概念。
Functions # 与c++或者Java或者其他语言不同的是，go的函数签名格式为func func_name(parm1 [type], parm2 [type]....) retype {}，先声明名字，再声明变量的类型，参数列表中有多个参数且类型一致的时候，前面的参数类型可以省略，只需要保留之后一个
func add(x, y int) int { return x + y } 且go可以很轻易的实现多返回值的功能，如下
func swap(x, y string) (string, string) { return y, x } func main() { a, b := swap(&amp;#34;hello&amp;#34;, &amp;#34;world&amp;#34;) fmt.Println(a, b) } 上面的功能在c++中需要使用结构体或者tuple或者Paris才能实现。
go的return还可以使用不带参数的 &amp;ldquo;naked&amp;rdquo; return，此时要求函数签名中的return参数必须有名字，且在函数体中必须为参数赋值，此时使用return直接返回，参数可以直接传递到外部，但是需要注意的时候，如果函数体过于庞大且有多个出口，不建议使用，难于阅读
func split(sum int) (x, y int) { x = sum * 4 / 9 y = sum - x return } 变量 # 使用var声明变量，声明多个变量的时候可以类似参数列表中的参数，前面参数不需要声明类型。初始化的时候按顺序初始化，且初始化的参数个数必须前后一致
var i, j, k int = 1,2,0 // true var i, j, k int = 1,2 // false 初始化的时候还可以省略类型，程序会进行参数推导。 函数内部还可以使用 :=替换var声明变量，此时必须初始化，但是在函数体外部，由于go规定，每条语句必须由特定的关键字开头，所以外部不可使用此语法。</description></item><item><title>Coursenote</title><link>https://askyx.github.io/posts/coursenote/</link><pubDate>Tue, 17 May 2022 13:17:04 +0800</pubDate><guid>https://askyx.github.io/posts/coursenote/</guid><description>
随堂笔记 # Why do people build distributed systems? to increase capacity via parallel processing to tolerate faults via replication to match distribution of physical devices e.g. sensors to achieve security via isolation
分布式的困难点：
大量的并发操作 具有容错性 难于实现 Lab 1: distributed big-data framework (like MapReduce) Lab 2: fault tolerance library using replication (Raft) Lab 3: a simple fault-tolerant database Lab 4: scalable database performance via sharding
A big goal: hide the complexity of distribution from applications.
Topic: fault tolerance 1000s of servers, big network -&amp;gt; always something broken We&amp;rsquo;d like to hide these failures from the application.
&amp;ldquo;High availability&amp;rdquo;: service continues despite failures</description></item><item><title>LevelDB源码阅读</title><link>https://askyx.github.io/posts/leveldb/</link><pubDate>Sun, 15 May 2022 21:59:53 +0800</pubDate><guid>https://askyx.github.io/posts/leveldb/</guid><description>
leveldb 源码总结分析</description></item><item><title>VolcanoOptimizer</title><link>https://askyx.github.io/posts/volcanooptimizer/</link><pubDate>Mon, 04 Apr 2022 22:10:50 +0800</pubDate><guid>https://askyx.github.io/posts/volcanooptimizer/</guid><description>
NOTE # 论文阅读笔记The Volcano Optimizer Generator: Extensibility and Efficient Search
可扩展
面向对象
自顶向下
剪枝
原型是EXODUS， Volcano是对他的改进
可以单独使用的优化器 优化搜索时间和搜索空间 可扩展 可以使用启发式算法和有效的代价模型来扩展和减少搜索空间，【剪枝】 灵活的成本计算模型 一个框架，优化器生成器，可以由“optimizer implementor”自行实现关键函数，整个优化器框架的输入是AST，输出是一个执行计划，算子的集合
SQL是基于关系代数，Volcano把关系表达式分为逻辑表达式和物理表达式，逻辑表达式之间使用transformation进行转换，物理表达式使用基于代价的implementation和逻辑表达式映射的，关系不一定是意义对应的，例如scan可以同时一起实现projection
在表达式进行转换的时候可以使用condition进行模式判断，满足条件的时候可以进行变换
表达式使用特征描述输出，
enforcers会强制添加某属性，用于指导优化器进行优化，例如指定表的scan方式
Logical Operator
Operator set，也就是可以描述在目标data model上可以执行的代数运算合
Transformation rules + Condition，对每条等价变换规则，在满足condition时才可以应用
Logical properties : 逻辑属性，用来描述代数运算的输出所具有的一些特征，这些特征与运算的具体执行方式无关，是逻辑的，例如输出的行数，结果集的schema等
Physical Operator
Algorithm + Enforcer set，即可应用的物理实现算法 + 可添加的Enforcer集合
Implementation rules + Condition，满足Condition的前提下，可以尝试该物理算法
Cost model + Cost formula，基于cost选择最优的物理算法
Physical property，与logical property对应，物理属性是选择了特定的算法实现后，输出的数据所具有的物理上的特性，例如数据是否有序、是否具有唯一性，数据在多机上的分布情况等，不同的物理算法，会决定执行该operator产生的物理属性，例如sort merge join会在join key上产生有序属性
Applicability function : 决定一个物理算法，其输出是否可以满足要求父算子对自身的physical property要求，且决定它对自身的输入具有什么样的physical property要求
Enforcer是search engine中一个重要的概念，它用来强制产生某种物理属性。例如上层是join算子，在枚举时会考虑使用sort merge join的物理执行方式(Implementation），但当递归到下层时，子节点可以选择table scan（无序输出），或者index scan（目标序输出），当选择table scan时，由于输出不满足父算子对自身输出的物理属性要求，就可以通过Order Enforcer来产生目标输出，Enforcer表示了排序这个操作，同时也包含了排序操作会产生的代价。
The Search Engine # 搜索实现
// PhysProp：： 此LogExpr锁具有的物理属性的要求 FindBestPlan (LogExpr, PhysProp, Limit) // 如果可以在look-up table找到满足的计划，则代表以及算过，直接返回 if the pair LogExpr and PhysProp is in the look-up table if the cost in the look-up table &amp;lt; Limit return Plan and Cost else return failure /* else: optimization required */ // 否则进行优化，由三种优化方式 // 1.</description></item><item><title>Columbia Optimizer</title><link>https://askyx.github.io/posts/columbia-optimizer/</link><pubDate>Sat, 02 Apr 2022 16:55:12 +0800</pubDate><guid>https://askyx.github.io/posts/columbia-optimizer/</guid><description>
start # EFFICIENCY IN THE COLUMBIA DATABASE QUERY OPTIMIZER
优化器发展版本 # 第一代
模块化的，分层的，可扩展的，基于规则的优化器 扩展的复杂性，搜索性能 第二代
类似Volcano，更加优秀的优化规则，且使用物理属性参与优化，使用新的搜索方式 更加灵活，但是还是难与扩展 第三代
使用面对象的思想实现的优化器，易于扩展，更灵活 可以按照搜索策略分为两类 1. 自底向上 2. 自顶向下 Cascades Optimizer Framework 对关键操作定义为抽象类，通过实现抽象类来添加规则或者进行表达式变换来扩展优化器， * 使用hash来消除重复的表达式 * 再group中把逻辑表达式和物理表达式分开 * 剪枝 先计算上层group的cost 阈值，在计算下层节点的时候，直接判断是否还需要继续进行优化 预先对执行计划设置阈值，当执行计划的代价和阈值足够接近的时候，则判定已完成搜索
术语 #</description></item><item><title>现代C++白皮书</title><link>https://askyx.github.io/posts/%E7%8E%B0%E4%BB%A3c-%E7%99%BD%E7%9A%AE%E4%B9%A6/</link><pubDate>Sun, 06 Mar 2022 20:46:08 +0800</pubDate><guid>https://askyx.github.io/posts/%E7%8E%B0%E4%BB%A3c-%E7%99%BD%E7%9A%AE%E4%B9%A6/</guid><description>
读者序 # 之前没有好好的阅读过一本任何技术书籍，一般都是打开前几张，然后慢慢的失去耐心，所有造成的问题是一些书籍上的知识，只会对前面的章节有记忆，而大多数的书籍前面的章节也只是他书籍的入门介绍而已，所以我是个半吊子程序员，工作两年半之后，这个问题越来越困扰着我，有时候看见别人的面帖，感觉那些问题其实都因该是知道答案的，但是当我想要在脑海中把答案整理出来的时候却无从说起，简单的来说就是有的东西我是知道的，但是无法表示出来，不成体系，这给我一个错觉就是我感觉我能力可以，但是落到实地的时候却啥也做不了，脱离了谷歌百度或者其他我之前的资料，我啥都不行。
我个人觉得问题的解决方式是学会输出，把自己的知识整理输出，通过自己让别人知道一项新技能，新知识，那就代表自己其实已经有了闹靠的基础，知识的输出需要一个载体，我不是老师，公司也没有这个渠道，因为公司的知识交流与工作内容是密切相关的，所以这也是我搭建这个博客的原因，但愿我可以长期的坚持下去，说实话，之前已经有了还几次类似的经历，但是都半途而废了，我希望这是最后一次
前言 # 书籍是Bjarne Stroustup为HOPL所撰写的论文，目的是介绍c++在过去到现在的发展历程，以及其中一些大的功能点的演化。促发展上来划分C++可以分为两个阶段，一是C++98之前的类C版C++，二是之后的C++11之后的现代C++，在进40年的时间里C++还没有被取代，还可以在如此多的编程语言中占据一些之地，引用Bjarne Stroustup大佬的话说就是因为他填补了编程语言中一个重要的生态位。C++的核心是直接映射硬件和林开销抽象，
ISO 编程语言可以分为三种，一是有公司主导的编程语言，例如Google的go，C#以及苹果的swift等，二是由社区主导如php，python等，这两种在除了显而易见的好处之外的，都有各自的问题，公司主导的语言的，可能哎公司强势的时候还可以得到发展，但是公司没落之后，语言没有支持可能就无了，还有那家公司主导，那语言就是那家公司的产品，技术上的map由公司指定，小公司没有能力可以影响到语言的后续发展，对于社区，则可能会由于没有一个核心的个人或者组织来引导方向，导致语言偏离最初顶下的发展道路。Bjarne Stroustup就是基于以上的原因，提出组建一个标准委员会来引导C++ 的发展，
语言特性 具体的定义的语言的规则，有对应的具体的实现
1. 起源 # C++核心特性
语言到设备之间的直接映射 零开销抽象 不使用的东西就不需要付出任何代价 使用到的东西就是可以实现的最好的 抽象具体为类，函数，模板，概念和别名 simula 最早的面向对象的语言，之后几乎所有的面向对象的语言都是直接或者间接的受奥他的印象。
C++最初是在1979年推出的，那时候是真正的带类的C。 Bjarne Stroustup的目的是想要一个可以直接映射硬件，同时又有类似于simula的具有抽象能力的语言，那是一个实验性质的语言的，实现就是把编码从C++逐行翻译到C，之后的1982年，随着人数的增加，他重写了前端，实现了一个功能完整的编译器，但是实际上在代码生成的是时候，还是生成的是C，
之后就是平稳的发展到推出98版本的C++，不考虑最近的一些新特性的话，我们大部分人的C++ 知识就到这里了。此时C++实现了
类 多态 运算符重载 类型安全连接 抽象类 模板 更好的泛型编程。大佬最初的时候使用宏实现的泛型编程 异常 RAII *_cast bool STL标准库 上述就是最初的98的C++实现的功能点，实际上也是大多是C++的开发人员知道的最详细的C++知识。之后就是漫长过渡期，直到11版本的推出，使C++进入新时代， 06年单核处理器新能几乎不再提升，所以大部分应用开始寻找可以提升性能的编程语言， C++11 新时代 # 许多新的特性的引入，使得C++类似一个新语言 特性如下
内存模型 高效的为现代硬件设计的底层抽象，描述并发的基础， auto|declytype range for 更好的遍历容器 移动语义和右值引用 统一初始化 nullptrt constexpr 用户自定义字面量 原始字符串字面量 属性 lambda表达式 变参模板 模板别名 noexcept override和final static_assert longlong 默认成员初始化 enum class 组件如下
智能指针 unique_ptr和shared_ptr atomic thread库 future，promise等 tuple type trait 正则 随机数 时间 容器 上面的东西就是后续C++在98 的基础上推出的新11功能点，在我自己写这边文档的时候，其实有些东西我是没概念的😂，这些看似不相关的东西，可以分为下面的几个大的主题
并发支持 简化使用 泛型编程的改进 增加静态类型的安全 支持对库的开发 标准库组件 1. 并发支持 #</description></item><item><title>Envs</title><link>https://askyx.github.io/posts/envs/</link><pubDate>Mon, 21 Feb 2022 19:00:25 +0800</pubDate><guid>https://askyx.github.io/posts/envs/</guid><description>
hugo # wget https://github.com/gohugoio/hugo/releases/download/v0.92.1/hugo_0.92.1_Linux-64bit.deb https://github.91chi.fun/https://github.com//gohugoio/hugo/releases/download/v0.92.2/hugo_extended_0.92.2_Linux-64bit.deb sudo dpkg -i hugo*.deb
140.82.113.3
aria2c -s 5 https://github.com/gohugoio/hugo/releases/download/v0.92.1/hugo_0.92.1_Linux-64bit.deb
https://github.com/gohugoio/hugo/releases/download/v0.92.1/hugo_0.92.1_Linux-64bit.deb
可以使用aria2下载，ubuntu使用apt install aria2直接安装工具，使用-s开启多路下载 aria2c -s 5 https://github.com/gohugoio/hugo/releases/download/v0.92.1/hugo_0.92.1_Linux-64bit.deb
manager用户
https://www.jianshu.com/p/a76a93e8c662
Unix # 分区问题，集群上多块磁盘分区挂载到指定目录
fdisk disk 可以对一个磁盘进行分区的添加和删除等操作 p d w h 添加磁盘挂载
lsblk -f 查看磁盘 mkfs.xfs -f -n ftype=1 /dev/sdb1 格式化磁盘 mount /dev/sdb1 /var/lib/docker 挂载 xfs_info /dev/sdb1 | grep ftype=1 blkid /dev/sdb1 查看UUID UUID=&amp;lt;UUID&amp;gt; /var/lib/docker xfs defaults 0 0 写进/etc/fstab 问题Couldn't find device with uuid 4mhUbb-Ls1h-jp0d-JuJK-C38V-T3tX-f7s2IN
原因未知，疑似但是这个UUID是前面挂载的分区格式化之前的UUID，所以可能是挂载的时候出了什么问题，但是之前对其他机器操作无问题，此问题只出现在集群中的一两太机器上。
解决：
使用 vgreduce --removemissing --verbose lvname 解决，但是需要视情况而定，需要知道自己在做什么 其中会使用的命令 lsblk vgscan pvscan cat /etc/lvm/archive/* | less 查看UUID和盘符之前的关系 lvextend -L +300G /dev/mapper/centos-root 扩展分区大小 xfs_growfs /dev/mapper/centos-root 扩展且生效 lvremove /dev/mapper/centos-home 删除lv lvcreate -L 100G -n /dev/mapper/centos-home 创建lv mkdf.</description></item><item><title>Docker</title><link>https://askyx.github.io/posts/docker/</link><pubDate>Sun, 20 Feb 2022 21:17:58 +0800</pubDate><guid>https://askyx.github.io/posts/docker/</guid><description>
docker 常用命令速查，私用</description></item><item><title>C++ Primer Plus</title><link>https://askyx.github.io/posts/cpp/</link><pubDate>Sun, 20 Feb 2022 20:54:01 +0800</pubDate><guid>https://askyx.github.io/posts/cpp/</guid><description>
编译器 # 把高级语言编译成可执行语言工具，分为前端后后端，前端值得是高级语言的解析，后端是指翻译解析之后的结果为机器语言
多文件 ** 连接 多文件编译可以有两种方式，一是直接编译为一个可以执行文件，二是按模块或者按文件编译为库，然后连接到执行文件
连接方式有两种， 一是静态连接，把所有的库文件打包到最后的生成文件中，优点是不需要额外的依赖外部环境，独立性强，缺点是文件体积大 二是动态链接，为了解决静态链接的缺点，执行文件在执行到库相关的代码的时候才加载库，有一点需要注意的是，程序运行的时候，在使用到动态库的时候才映射动态库到内存空间中。原理是编译待援在编译的时候，会更具声明生成函数的调用逻辑，但是只是一个地址跳转语句，所以，只要不调用，就不会有问题，当调用到了。才会加载库然后映射库的地址，这个完整的过程称为重定向。 动态连接 C语言编程透视 声明 声明是为了在编译的时候编译器能进行完整的上下文编译。他需要更具声明来确定编译信息，否则编译器无法确定编译中的语句信息，声明可以辅助完成这个情况， 所以理论上编译的时候是可以不需要实现的，可以在其他编译单元中实现声明的函数，其声明的文件可以不引用头文件，即两个编译单元完全可以无任何联系，除了声明之外，在连接的时候，连接器会根据编译出来的信息去确定函数调用情况，这里有一个问题，按上述的描述，是一个声明对应一个实现，如果有一个声明对应多个实现呢 == ： 会有覆盖问题，如果多个动态链接库都有同一个声明的实现，则连接的时候连接第一个，后面的则忽略，这也提醒我们，在大型项目中，避免同名全局函数或者变量，使用namespace或者static限制作用域，
g++ -o tt ../main.cpp -ldl ./libhellolib.so ./libhellolib1.so LD_LIBRARY_PATH=$PWD ./tt 头文件，避免公用代码的重复，预处理时展开头文件，需要使用#pragma once避免重复引用，头文件只是简单的文件替换，理论上的可以替换任何文本。 cmake * 子模块，使用add_subdirectory引入 * 第三方库 * 只是头文件，直接指定头文件目录编译即可 * 使用子模块 * 使用为连接库 * 使用git模块
STL
重点为容器和算法 lambda表达式，实质上是仿函数，是一个结构体实现()运算的重载，捕获的时候按照声明的新式捕获参数，建议使用的时候明确使用的参数，使用哪个就捕获哪一个，否则他实际上会占据一定的大小的，配合std::function使用
CTAD &amp;mdash; complie-time argument deduction，编译器参数推断，C++17引入的，可以在编译器按照上下文推断类型，具体表现在lambda参数可以使用auto，容器可以不适用&amp;lt;&amp;gt;
ranges https://zhuanlan.zhihu.com/p/350068132
module
raii 获取资源即初始化，释放资源即销毁，具体的实现是使用构造函数和析构函数，当前的实现为智能指针，其他用户自己管理的资源最好也使用raii，遮这样在函数有多个出口的时候，就不会有意外的情况，本质上还是自己管理资源，不想其他的语言有GC
异常安全，C++中异常机制在回溯栈的时候会析构对象，所以如果没有实现RAII，则自己管理的内存则无法释放，C++的异常可以发生在任何地方，如果发生在析构函数中，则需要自己处理，不要在析构函数中抛出异常的，在构造函数中的时候，也需要捕获异常然后释放已经申请的资源，构造函数异常的时候，是不会调用析构函数的， 构造函数
构造函数有时候会隐士的生成对象，即使没有显示声明，使用explicit避免这种情况，单参数的时候会，多参数使用{}，调用的时候也会 直接使用多参数的时候，()和{}是有区别的，()除了正常的使用外，其他情况不具备特殊含义 int a = (10, 11); int a = {10, 11}; tt t(1, 2); tt q{1, 3}; tt w = {1, 4}; tests({1,5}); ``` 上面的语句1正确，a的值为11，2错误，{}这种用法的意义是参数列表，是会构造对象的。ps，调用构造函数的时候，有具体的对象的时候两种括号无差别，但是无对象的时候有区别，如上，细品
默认构造函数 拷贝构造( A(A const &amp;amp; a) ) A a = aa; 移动构造( A(A &amp;amp;&amp;amp; a) ) 赋值构造( A&amp;amp;operator=(A const&amp;amp; a) ) A a; a = aa; 移动赋值( A&amp;amp;operator=(A &amp;amp;&amp;amp; a) ) =delte和=default 类内部变量可以赋初值 三五法则 拷贝构造或者赋值构造需要区分深拷贝和浅拷贝，这也是构造函数肯可能引入的问题，例如浅拷贝导致内存的重复释放， 各种构造函数更多的是需要考虑当前对象的来源，如果是直接从零开始的，则是普通的构造函数，如果是从别的对象来的，则需要考虑深浅拷贝的问题，以及构造之后别的对象是否还需要的问题，简而言之，就是资源细节上的考虑，只要内涉及到资源的操作，则需要多话费一些心思区考虑， 函数返回多值</description></item><item><title/><link>https://askyx.github.io/posts/adbplan/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://askyx.github.io/posts/adbplan/</guid><description>
issues # 1490 # 1921 # 1699 # http://10.20.16.216:9090/ADB/AntDB/-/issues/1490 http://10.20.16.216:9090/ADB/AntDB/-/issues/1921 http://10.20.16.216:9090/ADB/AntDB/-/issues/1699
问题 # 使用到reduce的地方（包括查询）偶现以下错误，再次执行sql就正常；
ERROR: remote node 16389 closed socket CONTEXT: dynamic reduce 复现方法 # 使用修改分布方式的方式去复现问题，过程如下： 创建100张表，然后并发100，不停执行下面的语句，5分钟之内会出现报错：
alter table xxx distribute by replication; alter table xxx distribute by random; 无法直接复现 1779 # http://10.20.16.216:9090/ADB/AntDB/-/issues/1779
问题 # 执行计划不正确导致dyreduce执行出错
复现方法 # create table tttb1( c1 int,c2 varchar(100),c3 varchar(100)); create table tttb2(c1 int,sheet_num varchar(100)); create table tttb3(c1 int,order_no varchar(100)); explain select count(distinct c2) from tttb1 where c2 in (select distinct sheet_num from tttb2,tttb3 where sheet_num=order_no and c3=&amp;#39;1&amp;#39;); create table tb1(c1 int,c2 varchar(100),c3 varchar(100)); create table tb2(c1 int,sheet_num varchar(100)); create table tb3(c1 int,order_no varchar(100)); explain select count(distinct c2) from tb1 where c2 in (select distinct sheet_num from tb2,tb3 where sheet_num=order_no and c3=&amp;#39;1&amp;#39;); insert into tb1 select (random()*10000000)::int, (random()*10000000)::int, (random()*10000000)::int from generate_series(1,100000); insert into tb2 select (random()*10000000)::int, (random()*10000000)::int from generate_series(1,100000); insert into tb3 select (random()*10000000)::character varying, (random()*10000000)::int from generate_series(1,100000); create table tb1int(c1 int, c2 int,c3 int); create table tb2int(c1 int, sheet_num int); create table tb3int(c1 int, order_no int); explain select count(distinct c2) from tb1int where c2 in (select distinct sheet_num from tb2int,tb3int where sheet_num=order_no and c3=1); insert into tb1int select (random()*10000000)::int, (random()*10000000)::int, (random()*10000000)::int from generate_series(1,100000); insert into tb2int select (random()*10000000)::int, (random()*10000000)::int from generate_series(1,100000); insert into tb3int select (random()*10000000)::int, (random()*10000000)::int from generate_series(1,100000); 1875 # http://10.</description></item><item><title/><link>https://askyx.github.io/posts/log/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://askyx.github.io/posts/log/</guid><description>
语句
prepare s3(int, int) as select no_o_id from bmsql_new_order where no_w_id = $1 and no_d_id = $2 order by no_o_id asc; QUERY PLAN --------------------------------------------------------------------------------------------------- Cluster Gather (cost=291.52..430.37 rows=459 width=4) Remote node: 16386 -&amp;gt; Sort (cost=291.52..292.67 rows=459 width=4) Output: no_o_id Sort Key: bmsql_new_order.no_o_id -&amp;gt; Bitmap Heap Scan on public.bmsql_new_order (cost=13.46..271.23 rows=459 width=4) Output: no_o_id Recheck Cond: ((bmsql_new_order.no_w_id = 1) AND (bmsql_new_order.no_d_id = 1)) -&amp;gt; Bitmap Index Scan on bmsql_new_order_pkey (cost=0.00..13.34 rows=918 width=0) Index Cond: ((bmsql_new_order.no_w_id = 1) AND (bmsql_new_order.no_d_id = 1)) Remote node: 16386 (11 rows) QUERY PLAN -------------------------------------------------------------------------------------------------------------------- Data Node Scan on &amp;#34;__REMOTE_SORT_QUERY__&amp;#34; (cost=0.00..0.00 rows=1000 width=4) Output: bmsql_new_order.no_o_id Node/s: data_1 Remote query: SELECT no_o_id FROM ONLY public.</description></item><item><title/><link>https://askyx.github.io/posts/%E5%87%BD%E6%95%B0%E8%BF%90%E8%A1%8C%E9%80%BB%E8%BE%91/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://askyx.github.io/posts/%E5%87%BD%E6%95%B0%E8%BF%90%E8%A1%8C%E9%80%BB%E8%BE%91/</guid><description>
predicate_refuted_by 和 make_new_qual_list的运行逻辑以及PARAM 无法选出一个节点的原因
make_new_qual_list需要使用表达式和分区信息构造新的表达式，但是PARAM不是常量，所以无法构造， 所以predicate_refuted_by判定变大时和约束的时候无法正确的选择节点，动态语句只要使用到分区键都不行
node_count = 2 Table &amp;#34;public.bmsql_new_order&amp;#34; Column | Type | Nullable | Storage | ---------+---------+----------+---------+ no_w_id | integer | not null | plain | no_d_id | integer | not null | plain | no_o_id | integer | not null | plain | Indexes: &amp;#34;bmsql_new_order_pkey&amp;#34; PRIMARY KEY, btree (no_w_id, no_d_id, no_o_id) Foreign-key constraints: &amp;#34;no_order_fkey&amp;#34; FOREIGN KEY (no_w_id, no_d_id, no_o_id) REFERENCES bmsql_oorder(o_w_id, o_d_id, o_id) DISTRIBUTE BY HASH(no_w_id) TO NODE(dn1, dn2) Access method: heap 数据分布 benchmarksql=# execute direct on (dn1) &amp;#39;select distinct no_w_id from public.bmsql_new_order&amp;#39;; no_w_id --------- 1 5 2 (3 rows) benchmarksql=# execute direct on (dn2) &amp;#39;select distinct no_w_id from public.</description></item><item><title/><link>https://askyx.github.io/posts/%E7%AE%80%E5%8E%86/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://askyx.github.io/posts/%E7%AE%80%E5%8E%86/</guid><description>
文磊 # 个人信息 # 性 别：男 年 龄：29 手 机：18705169510 邮 箱：404061090@qq.com
工作及教育经历 # 湖南亚信安慧科技有限公司 2022.7~now AntDB-T SQL内核研发工程师
主要负责优化器对分布式执行计划的优化 星环科技有限公司 2022.2~2022.3 基础架构部-数据库研发工程师
主要职责为负责ArgoDB数据库存储引擎的研发工作 易鲸捷信息技术有限公司 2019.7~2022.1 SQL内核研发工程师
负责EsgynDB和Oracle的SQL兼容工作 负责BUG修复 负责一些需求开发 与交付同事一起排查项目现场问题，SQL语句优化等 南京邮电大学 2015.9~2019.6 软件工程-本科
专业技能 # 编程语言 c++(熟悉)，Java(了解)，GO(了解)
数据库
工作开始就从事数据库内核开发，有一定的数据库基础，曾系统学习过相关课程
熟悉多种数据库内核实现原理，主要为trafodion和postgres。对其他pg类数据库也有一定的理解，
如greenplum，opengause等
了解SQL优化器的原理，了解常用逻辑优化规则及代价优化规则等
了解执行器的实现原理，对于其常用优化手段有一定了解，了解postgres执行器原理
了解存储引擎，对于一些通用存储架构有一定了解，如B+tree，LSM等
工作中常常进行BUG修复或者性能调优等，所以具备良好的问题定位，分析能力
主要工作环境为Linux，掌握基础的Linux命令，掌握基础开发工具以及Linux下的调试工具的使用
掌握基础数据结构和算法，具备常规操作系统知识
CET-6
项目经历 # AntDB
2022.7-now
主要工作范围为优化器及执行器部分 fast query ship功能优化 进入优化器之前快速判断语句能否从cn直接下发到dn，优化其判断规则，支持较复杂语句 odbc项目维护 项目支持 EsgynDB
2019.7-2022.1
分区表功能实现 兼容Oracle分区表实现 range 分区表功能 主要负责分区表的部分SQL DDL、DML语句，以及index的设计和实现，且后期负责分区表功能的主要维护工作 memtable(简易分布式内存表)功能实现 由于数据库的架构问题，导致语句执行链路过长，部分场景无法满足客户性能需求，所以设计实现内存表，加速查询 负责具体功能的实现，主要功能点为 内存表架构实现 缓存一致性的检查机制 缓存操作及维护的DDL语句，DML语句等 性能明显有比较大的提升，表宽为1K，大小为10W行的数据，进行查询操性能较原来提 升有10X，满足现场同事的性能需求 一些现场支援，需求开发、SQL兼容、SQL函数实现、SQL优化等，例如 greatest，least，beginkey，endkey等SQL函数实现 临时表，in语句，reverse scan，大字段查询的优化</description></item><item><title/><link>https://askyx.github.io/posts/remotequery/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://askyx.github.io/posts/remotequery/</guid><description>
remote Query # 精确选择数据源，需要从语句的约束条件中计算出具体的执行数据源节点，然后把语句下发的对应的 DN 操作尽可能下推，下推一些操作到对应的DN上执行 remote query当前使用两阶段优化
第一阶段是FQS，对语句进行简单的判断，如果语句可以完全在DN上执行，则直接在这里创建remote plan，然后直接返回，如下例子
benchmarksql=# explain select * from t1; QUERY PLAN ---------------------------------------------------------------------------- Data Node Scan on &amp;#34;__REMOTE_FQS_QUERY__&amp;#34; (cost=0.00..0.00 rows=0 width=0) Primary node/s: dn1 Node/s: dn1, dn2 (3 rows) 第二阶段，FQS判断失败的语句，此时需要进行常规优化，一般是语句需要DN之间的数据发生交换的时候，例如join使用多表， 但是关联条件不是分区键，此时需要把DN的数据读取到 CN 上，然后进行关联，
postgres=# explain select * from t1 join t2 on t1.c1 = t2.c1; QUERY PLAN --------------------------------------------------------------------------------------------------- Hash Join (cost=2752.50..5509.65 rows=3000 width=16) Hash Cond: (t2.c1 = t1.c1) -&amp;gt; Data Node Scan on t2 &amp;#34;_REMOTE_TABLE_QUERY_&amp;#34; (cost=0.00..2715.90 rows=3001 width=8) Primary node/s: dn1 Node/s: dn1, dn2, dn3 -&amp;gt; Hash (cost=2715.00..2715.00 rows=3000 width=8) -&amp;gt; Data Node Scan on t1 &amp;#34;_REMOTE_TABLE_QUERY__1&amp;#34; (cost=0.00..2715.00 rows=3000 width=8) Primary node/s: dn1 Node/s: dn1, dn2, dn3 (9 rows) 1.</description></item><item><title/><link>https://askyx.github.io/posts/sublink/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://askyx.github.io/posts/sublink/</guid><description>
typedef struct SubPlan { pg_node_attr(no_query_jumble) Expr xpr; /* Fields copied from original SubLink: */ SubLinkType subLinkType; /* see above */ /* The combining operators, transformed to an executable expression: */ Node *testexpr; /* OpExpr or RowCompareExpr expression tree */ List *paramIds; /* IDs of Params embedded in the above */ /* Identification of the Plan tree to use: */ int plan_id; /* Index (from 1) in PlannedStmt.subplans */ /* Identification of the SubPlan for EXPLAIN and debugging purposes: */ char *plan_name; /* A name assigned during planning */ /* Extra data useful for determining subplan&amp;#39;s output type: */ Oid firstColType; /* Type of first column of subplan result */ int32 firstColTypmod; /* Typmod of first column of subplan result */ Oid firstColCollation; /* Collation of first column of subplan result */ /* Information about execution strategy: */ bool useHashTable; /* true to store subselect output in a hash table (implies we are doing &amp;#34;IN&amp;#34;) */ bool unknownEqFalse; /* true if it&amp;#39;s okay to return FALSE when the * spec result is UNKNOWN; this allows much * simpler handling of null values */ bool parallel_safe; /* is the subplan parallel-safe?</description></item><item><title/><link>https://askyx.github.io/posts/%E9%85%8D%E7%BD%AE/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://askyx.github.io/posts/%E9%85%8D%E7%BD%AE/</guid><description>
配置文件guc.c
http://www.postgres.cn/docs/12/view-pg-settings.html
Column | Type | Collation | Nullable | Default | Storage | Description &amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;&amp;ndash;+&amp;mdash;&amp;mdash;&amp;mdash;+&amp;mdash;&amp;mdash;&amp;mdash;&amp;ndash;+&amp;mdash;&amp;mdash;&amp;mdash;-+&amp;mdash;&amp;mdash;&amp;mdash;+&amp;mdash;&amp;mdash;&amp;mdash;-+&amp;mdash;&amp;mdash;&amp;mdash;&amp;mdash;- name | text | | | | extended | 名称 setting | text | | | | extended | 配置 unit | text | | | | extended | 单位 category | text | | | | extended | 分类 short_desc | text | | | | extended | 描述 extra_desc | text | | | | extended | 附加描述 context | text | | | | extended | 上下文 vartype | text | | | | extended | 参数类型 source | text | | | | extended | 来源 min_val | text | | | | extended | 最小值 max_val | text | | | | extended | 最大值 enumvals | text[] | | | | extended | 枚举的允许值 boot_val | text | | | | extended | 默认值 reset_val | text | | | | extended | 当前session中reset 之后会设置的值 sourcefile | text | | | | extended | 设置文件 sourceline | integer | | | | plain | 文件行号 pending_restart | boolean | | | | plain | 修改文件是否需要重启生效 select name, setting, boot_val, reset_val, sourcefile, sourceline, pending_restart from pg_settings ; View definition: SELECT a.</description></item><item><title/><link>https://askyx.github.io/posts/mysql/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://askyx.github.io/posts/mysql/</guid><description/></item></channel></rss>