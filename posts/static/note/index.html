<!doctype html><html lang=zh-Hans x-data :class=$store.darkMode.class() :data-theme=$store.darkMode.theme()><head><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><title>数据库文章资源汇总 | Askyx's Blog</title><link rel=icon href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%2210 0 100 100%22><text y=%22.90em%22 font-size=%2290%22>🌱</text></svg>"></link>
<link rel=canonical href=https://askyx.github.io/posts/static/note/><meta name=author content="Askyx"><meta name=description content="爬虫 import requests from bs4 import BeautifulSoup prefix = 'http://mysql.taobao.org' # 获取文章名和url（文章名,url） def query_name_url(url: str): resp = requests.get(url) soup = BeautifulSoup(resp.content.decode('utf-8'), &#34;html.parser&#34;) tags = soup.findAll('a', {'target': {'_top'}}) urls = [v for v in tags if v['href'].find('/monthly/') != -1] return [(str(v.string).strip(), prefix + v['href']) for v in urls] # 获取所有月报链接（月报名,url） def query_monthly_url(): resp = requests.get('http://mysql.taobao.org/monthly/') soup = BeautifulSoup(resp.content.decode('utf-8'), &#34;html.parser&#34;) tags = soup.findAll('a', {'class': {'main'}}) urls = [v for v in tags if v['href'].find('/monthly/') != -1] return [(str(v.string).strip(), prefix + v['href']) for v in urls] # 获取所有文章名、URL和对应的月报链接（文章类型，文章名，url，月报名，url） def query_all_name_url(): result = [] monthly_urls = query_monthly_url() for data1 in monthly_urls: name_urls = query_name_url(data1[1]) for data2 in name_urls: result.append((data2[0][0:data2[0].find('·')].strip(), data2[0], data2[1], data1[0], data1[1])) return result # 下载所有数据库月报，并按照类别进行分类，写入到mysql.md文件中 name = '' data = [] result = query_all_name_url() result.sort(key=lambda v: v[0]) for v in result: if v[0] != name: name = v[0] data.append('## {}'.format(v[0])) data.append('[{}]({}) [[{}]({})]\n'.format(v[1], v[2], v[3][v[3].find(' － ') + 3:], v[4])) with open('mysql.md', 'w') as file: for v in data: print(v) file.write(v + '\n') "><meta name=keywords content="资源,数据库"><meta name=generator content="Hugo 0.148.1"><meta property="og:url" content="https://askyx.github.io/posts/static/note/"><meta property="og:site_name" content="Askyx's Blog"><meta property="og:title" content="数据库文章资源汇总"><meta property="og:description" content="爬虫 import requests from bs4 import BeautifulSoup prefix = 'http://mysql.taobao.org' # 获取文章名和url（文章名,url） def query_name_url(url: str): resp = requests.get(url) soup = BeautifulSoup(resp.content.decode('utf-8'), &#34;html.parser&#34;) tags = soup.findAll('a', {'target': {'_top'}}) urls = [v for v in tags if v['href'].find('/monthly/') != -1] return [(str(v.string).strip(), prefix + v['href']) for v in urls] # 获取所有月报链接（月报名,url） def query_monthly_url(): resp = requests.get('http://mysql.taobao.org/monthly/') soup = BeautifulSoup(resp.content.decode('utf-8'), &#34;html.parser&#34;) tags = soup.findAll('a', {'class': {'main'}}) urls = [v for v in tags if v['href'].find('/monthly/') != -1] return [(str(v.string).strip(), prefix + v['href']) for v in urls] # 获取所有文章名、URL和对应的月报链接（文章类型，文章名，url，月报名，url） def query_all_name_url(): result = [] monthly_urls = query_monthly_url() for data1 in monthly_urls: name_urls = query_name_url(data1[1]) for data2 in name_urls: result.append((data2[0][0:data2[0].find('·')].strip(), data2[0], data2[1], data1[0], data1[1])) return result # 下载所有数据库月报，并按照类别进行分类，写入到mysql.md文件中 name = '' data = [] result = query_all_name_url() result.sort(key=lambda v: v[0]) for v in result: if v[0] != name: name = v[0] data.append('## {}'.format(v[0])) data.append('[{}]({}) [[{}]({})]\n'.format(v[1], v[2], v[3][v[3].find(' － ') + 3:], v[4])) with open('mysql.md', 'w') as file: for v in data: print(v) file.write(v + '\n')"><meta property="og:locale" content="zh_Hans"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2022-07-20T17:44:29+08:00"><meta property="article:modified_time" content="2025-07-16T23:38:40+08:00"><meta property="article:tag" content="资源"><meta property="article:tag" content="数据库"><meta property="og:image" content="https://askyx.github.io/img/global-background.jpg"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://askyx.github.io/img/global-background.jpg"><meta name=twitter:title content="数据库文章资源汇总"><meta name=twitter:description content="爬虫 import requests from bs4 import BeautifulSoup prefix = 'http://mysql.taobao.org' # 获取文章名和url（文章名,url） def query_name_url(url: str): resp = requests.get(url) soup = BeautifulSoup(resp.content.decode('utf-8'), &#34;html.parser&#34;) tags = soup.findAll('a', {'target': {'_top'}}) urls = [v for v in tags if v['href'].find('/monthly/') != -1] return [(str(v.string).strip(), prefix + v['href']) for v in urls] # 获取所有月报链接（月报名,url） def query_monthly_url(): resp = requests.get('http://mysql.taobao.org/monthly/') soup = BeautifulSoup(resp.content.decode('utf-8'), &#34;html.parser&#34;) tags = soup.findAll('a', {'class': {'main'}}) urls = [v for v in tags if v['href'].find('/monthly/') != -1] return [(str(v.string).strip(), prefix + v['href']) for v in urls] # 获取所有文章名、URL和对应的月报链接（文章类型，文章名，url，月报名，url） def query_all_name_url(): result = [] monthly_urls = query_monthly_url() for data1 in monthly_urls: name_urls = query_name_url(data1[1]) for data2 in name_urls: result.append((data2[0][0:data2[0].find('·')].strip(), data2[0], data2[1], data1[0], data1[1])) return result # 下载所有数据库月报，并按照类别进行分类，写入到mysql.md文件中 name = '' data = [] result = query_all_name_url() result.sort(key=lambda v: v[0]) for v in result: if v[0] != name: name = v[0] data.append('## {}'.format(v[0])) data.append('[{}]({}) [[{}]({})]\n'.format(v[1], v[2], v[3][v[3].find(' － ') + 3:], v[4])) with open('mysql.md', 'w') as file: for v in data: print(v) file.write(v + '\n')"><link rel=stylesheet href=/css/output.min.css><style>pre{padding:1em;overflow:auto}</style><link rel=stylesheet href=/css/custom.css><script defer src=https://cdn.jsdelivr.net/npm/alpinejs@3/dist/cdn.min.js integrity="sha256-PtHu0lJIiSHfZeNj1nFd6wTX+Squ255SGZ/fc8seCtM=" crossorigin=anonymous></script></head><body x-data="{
    flip: false,
  }"><div id=dream-global-bg></div><nav x-data="{ isSticky: false }" x-init="window.addEventListener('scroll', () => { isSticky = window.scrollY > 30 })" class="sticky top-0 z-30 mt-4 lg:mt-8 py-4" :class="{ 'bg-base-100 shadow-lg dark:border-b dark:border-base-content/30': isSticky }"><div class="container flex justify-between px-4"><section class="flex items-center gap-4"><div class="avatar cursor-pointer hover:avatar-online" @click="flip = !flip" title="Flip it!"><div class="h-10 rounded-full"><img src=/img/personal/avatar.jpg alt="Askyx's Blog"></div></div><div><a href=https://askyx.github.io/ class="text-lg font-semibold cursor-pointer">Askyx's Blog</a><div class="text-base-content/60 text-sm">life is short, use Python</div></div></section><div class="dropdown dropdown-end sm:hidden"><div tabindex=0 role=button class="btn btn-ghost btn-square" aria-label="Select an option"><ion-icon name=menu class=text-2xl></ion-icon></div><ul tabindex=0 class="dropdown-content menu w-36 bg-base-100 rounded-box z-1 shadow-md"><li><div role=link tabindex=0 class="inline-flex items-center p-2 cursor-pointer" @click="flip = !flip" title=About><ion-icon name=information-circle></ion-icon>About</div></li><li><a class="group inline-flex items-center p-2 cursor-pointer" href=/search title=Search><ion-icon name=search></ion-icon>Search</a></li><li><a class="inline-flex items-center p-2 cursor-pointer" href=https://github.com/askyx target=_blank title=GitHub><ion-icon name=logo-github></ion-icon>GitHub</a></li><li><a class="inline-flex items-center p-2 cursor-pointer" href=/posts title=Archives><ion-icon name=archive></ion-icon>Archives</a></li><li><a class="inline-flex items-center p-2 cursor-pointer" href=/tags title="All Tags"><ion-icon name=pricetags></ion-icon>All Tags</a></li><li><a class="inline-flex items-center p-2 cursor-pointer" href=/index.xml title=RSS><ion-icon name=logo-rss></ion-icon>RSS</a></li></ul></div><section class="hidden sm:flex sm:items-center sm:gap-2 md:gap-4"><div role=link tabindex=0 class="text-sm font-semibold cursor-pointer hover:underline" @click="flip = !flip" title=About>About</div><a class="group inline-flex items-center p-2 rounded-full cursor-pointer hover:bg-primary" href=/search title=Search><ion-icon class=group-hover:text-primary-content name=search></ion-icon></a><a class="group inline-flex items-center p-2 rounded-full cursor-pointer hover:bg-primary" href=https://github.com/askyx target=_blank title=GitHub><ion-icon class=group-hover:text-primary-content name=logo-github></ion-icon></a><div class="dropdown dropdown-end dropdown-hover"><div tabindex=0 role=button class="group inline-flex items-center p-2 rounded-full cursor-pointer hover:bg-primary" aria-label="Select an option"><ion-icon class="group-hover:text-primary-content text-xl" name=menu></ion-icon></div><ul tabindex=0 class="dropdown-content menu w-36 bg-base-100 rounded-box z-1 shadow-xl"><li><a class="inline-flex items-center p-2 cursor-pointer" href=/posts title=Archives><ion-icon name=archive></ion-icon>Archives</a></li><li><a class="inline-flex items-center p-2 cursor-pointer" href=/tags title="All Tags"><ion-icon name=pricetags></ion-icon>All Tags</a></li><li><a class="inline-flex items-center p-2 cursor-pointer" href=/index.xml title=RSS><ion-icon name=logo-rss></ion-icon>RSS</a></li></ul></div></section></div></nav><div class=flip-container :class="{ 'flip-it': flip }"><div class=flipper><div class=front><div class=container><div class="lg:grid lg:grid-cols-4 gap-4 mt-4 px-4"><div class="hidden lg:block"></div><div class=lg:col-span-2><article class="mx-auto prose prose-quoteless dark:prose-invert" id=dream-single-post-main itemscope itemtype=http://schema.org/Article><meta itemprop=name content="数据库文章资源汇总"><meta itemprop=description content="爬虫 import requests from bs4 import BeautifulSoup prefix = 'http://mysql.taobao.org' # 获取文章名和url（文章名,url） def query_name_url(url: str): resp = requests.get(url) soup = BeautifulSoup(resp.content.decode('utf-8'), &#34;html.parser&#34;) tags = soup.findAll('a', {'target': {'_top'}}) urls = [v for v in tags if v['href'].find('/monthly/') != -1] return [(str(v.string).strip(), prefix + v['href']) for v in urls] # 获取所有月报链接（月报名,url） def query_monthly_url(): resp = requests.get('http://mysql.taobao.org/monthly/') soup = BeautifulSoup(resp.content.decode('utf-8'), &#34;html.parser&#34;) tags = soup.findAll('a', {'class': {'main'}}) urls = [v for v in tags if v['href'].find('/monthly/') != -1] return [(str(v.string).strip(), prefix + v['href']) for v in urls] # 获取所有文章名、URL和对应的月报链接（文章类型，文章名，url，月报名，url） def query_all_name_url(): result = [] monthly_urls = query_monthly_url() for data1 in monthly_urls: name_urls = query_name_url(data1[1]) for data2 in name_urls: result.append((data2[0][0:data2[0].find('·')].strip(), data2[0], data2[1], data1[0], data1[1])) return result # 下载所有数据库月报，并按照类别进行分类，写入到mysql.md文件中 name = '' data = [] result = query_all_name_url() result.sort(key=lambda v: v[0]) for v in result: if v[0] != name: name = v[0] data.append('## {}'.format(v[0])) data.append('[{}]({}) [[{}]({})]\n'.format(v[1], v[2], v[3][v[3].find(' － ') + 3:], v[4])) with open('mysql.md', 'w') as file: for v in data: print(v) file.write(v + '\n')"><meta itemprop=datePublished content="2022-07-20T17:44:29+08:00"><meta itemprop=dateModified content="2025-07-16T23:38:40+08:00"><meta itemprop=wordCount content="328"><meta itemprop=image content="https://askyx.github.io/img/global-background.jpg"><meta itemprop=keywords content="资源,数据库"><header><h1 itemprop=headline>数据库文章资源汇总</h1><p class=text-sm><span data-format=luxon>2022-07-20T17:44:29+08:00</span>
| <span>1 minute read</span>
| <span>Updated at
<span data-format=luxon>2025-07-16T23:38:40+08:00</span></span></p></header><section id=dream-single-post-content itemprop=articleBody><h2 id=爬虫>爬虫</h2><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>import</span> requests
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> bs4 <span style=color:#f92672>import</span> BeautifulSoup
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>prefix <span style=color:#f92672>=</span> <span style=color:#e6db74>&#39;http://mysql.taobao.org&#39;</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 获取文章名和url（文章名,url）</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>query_name_url</span>(url: str):
</span></span><span style=display:flex><span>    resp <span style=color:#f92672>=</span> requests<span style=color:#f92672>.</span>get(url)
</span></span><span style=display:flex><span>    soup <span style=color:#f92672>=</span> BeautifulSoup(resp<span style=color:#f92672>.</span>content<span style=color:#f92672>.</span>decode(<span style=color:#e6db74>&#39;utf-8&#39;</span>), <span style=color:#e6db74>&#34;html.parser&#34;</span>)
</span></span><span style=display:flex><span>    tags <span style=color:#f92672>=</span> soup<span style=color:#f92672>.</span>findAll(<span style=color:#e6db74>&#39;a&#39;</span>, {<span style=color:#e6db74>&#39;target&#39;</span>: {<span style=color:#e6db74>&#39;_top&#39;</span>}})
</span></span><span style=display:flex><span>    urls <span style=color:#f92672>=</span> [v <span style=color:#66d9ef>for</span> v <span style=color:#f92672>in</span> tags <span style=color:#66d9ef>if</span> v[<span style=color:#e6db74>&#39;href&#39;</span>]<span style=color:#f92672>.</span>find(<span style=color:#e6db74>&#39;/monthly/&#39;</span>) <span style=color:#f92672>!=</span> <span style=color:#f92672>-</span><span style=color:#ae81ff>1</span>]
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>return</span> [(str(v<span style=color:#f92672>.</span>string)<span style=color:#f92672>.</span>strip(), prefix <span style=color:#f92672>+</span> v[<span style=color:#e6db74>&#39;href&#39;</span>]) <span style=color:#66d9ef>for</span> v <span style=color:#f92672>in</span> urls]
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 获取所有月报链接（月报名,url）</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>query_monthly_url</span>():
</span></span><span style=display:flex><span>    resp <span style=color:#f92672>=</span> requests<span style=color:#f92672>.</span>get(<span style=color:#e6db74>&#39;http://mysql.taobao.org/monthly/&#39;</span>)
</span></span><span style=display:flex><span>    soup <span style=color:#f92672>=</span> BeautifulSoup(resp<span style=color:#f92672>.</span>content<span style=color:#f92672>.</span>decode(<span style=color:#e6db74>&#39;utf-8&#39;</span>), <span style=color:#e6db74>&#34;html.parser&#34;</span>)
</span></span><span style=display:flex><span>    tags <span style=color:#f92672>=</span> soup<span style=color:#f92672>.</span>findAll(<span style=color:#e6db74>&#39;a&#39;</span>, {<span style=color:#e6db74>&#39;class&#39;</span>: {<span style=color:#e6db74>&#39;main&#39;</span>}})
</span></span><span style=display:flex><span>    urls <span style=color:#f92672>=</span> [v <span style=color:#66d9ef>for</span> v <span style=color:#f92672>in</span> tags <span style=color:#66d9ef>if</span> v[<span style=color:#e6db74>&#39;href&#39;</span>]<span style=color:#f92672>.</span>find(<span style=color:#e6db74>&#39;/monthly/&#39;</span>) <span style=color:#f92672>!=</span> <span style=color:#f92672>-</span><span style=color:#ae81ff>1</span>]
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>return</span> [(str(v<span style=color:#f92672>.</span>string)<span style=color:#f92672>.</span>strip(), prefix <span style=color:#f92672>+</span> v[<span style=color:#e6db74>&#39;href&#39;</span>]) <span style=color:#66d9ef>for</span> v <span style=color:#f92672>in</span> urls]
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 获取所有文章名、URL和对应的月报链接（文章类型，文章名，url，月报名，url）</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>query_all_name_url</span>():
</span></span><span style=display:flex><span>    result <span style=color:#f92672>=</span> []
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    monthly_urls <span style=color:#f92672>=</span> query_monthly_url()
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>for</span> data1 <span style=color:#f92672>in</span> monthly_urls:
</span></span><span style=display:flex><span>        name_urls <span style=color:#f92672>=</span> query_name_url(data1[<span style=color:#ae81ff>1</span>])
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>for</span> data2 <span style=color:#f92672>in</span> name_urls:
</span></span><span style=display:flex><span>            result<span style=color:#f92672>.</span>append((data2[<span style=color:#ae81ff>0</span>][<span style=color:#ae81ff>0</span>:data2[<span style=color:#ae81ff>0</span>]<span style=color:#f92672>.</span>find(<span style=color:#e6db74>&#39;·&#39;</span>)]<span style=color:#f92672>.</span>strip(), data2[<span style=color:#ae81ff>0</span>], data2[<span style=color:#ae81ff>1</span>], data1[<span style=color:#ae81ff>0</span>], data1[<span style=color:#ae81ff>1</span>]))
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>return</span> result
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 下载所有数据库月报，并按照类别进行分类，写入到mysql.md文件中</span>
</span></span><span style=display:flex><span>name <span style=color:#f92672>=</span> <span style=color:#e6db74>&#39;&#39;</span>
</span></span><span style=display:flex><span>data <span style=color:#f92672>=</span> []
</span></span><span style=display:flex><span>result <span style=color:#f92672>=</span> query_all_name_url()
</span></span><span style=display:flex><span>result<span style=color:#f92672>.</span>sort(key<span style=color:#f92672>=</span><span style=color:#66d9ef>lambda</span> v: v[<span style=color:#ae81ff>0</span>])
</span></span><span style=display:flex><span><span style=color:#66d9ef>for</span> v <span style=color:#f92672>in</span> result:
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>if</span> v[<span style=color:#ae81ff>0</span>] <span style=color:#f92672>!=</span> name:
</span></span><span style=display:flex><span>        name <span style=color:#f92672>=</span> v[<span style=color:#ae81ff>0</span>]
</span></span><span style=display:flex><span>        data<span style=color:#f92672>.</span>append(<span style=color:#e6db74>&#39;## </span><span style=color:#e6db74>{}</span><span style=color:#e6db74>&#39;</span><span style=color:#f92672>.</span>format(v[<span style=color:#ae81ff>0</span>]))
</span></span><span style=display:flex><span>    data<span style=color:#f92672>.</span>append(<span style=color:#e6db74>&#39;[</span><span style=color:#e6db74>{}</span><span style=color:#e6db74>](</span><span style=color:#e6db74>{}</span><span style=color:#e6db74>) [[</span><span style=color:#e6db74>{}</span><span style=color:#e6db74>](</span><span style=color:#e6db74>{}</span><span style=color:#e6db74>)]</span><span style=color:#ae81ff>\n</span><span style=color:#e6db74>&#39;</span><span style=color:#f92672>.</span>format(v[<span style=color:#ae81ff>1</span>], v[<span style=color:#ae81ff>2</span>], v[<span style=color:#ae81ff>3</span>][v[<span style=color:#ae81ff>3</span>]<span style=color:#f92672>.</span>find(<span style=color:#e6db74>&#39; － &#39;</span>) <span style=color:#f92672>+</span> <span style=color:#ae81ff>3</span>:], v[<span style=color:#ae81ff>4</span>]))
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>with</span> open(<span style=color:#e6db74>&#39;mysql.md&#39;</span>, <span style=color:#e6db74>&#39;w&#39;</span>) <span style=color:#66d9ef>as</span> file:
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>for</span> v <span style=color:#f92672>in</span> data:
</span></span><span style=display:flex><span>        print(v)
</span></span><span style=display:flex><span>        file<span style=color:#f92672>.</span>write(v <span style=color:#f92672>+</span> <span style=color:#e6db74>&#39;</span><span style=color:#ae81ff>\n</span><span style=color:#e6db74>&#39;</span>)
</span></span></code></pre></div></section><div class=divider></div><div class="flex flex-col md:flex-row justify-between gap-4 py-4"><a role=button class="btn btn-outline h-12" href=/posts/postgres/storage/ title="Postgres Storage"><ion-icon name=chevron-back></ion-icon><div class="inline-flex flex-col items-start"><span class="text-base-content/60 text-xs font-normal">Previous page</span>
<span class="max-w-48 truncate">Postgres Storage</span></div></a><a role=button class="btn btn-outline h-12" href=/posts/course/15445/note/ title=15445课程笔记><div class="inline-flex flex-col items-end"><span class="text-base-content/60 text-xs font-normal">Next page</span>
<span class="max-w-48 truncate">15445课程笔记</span></div><ion-icon name=chevron-forward></ion-icon></a></div></article></div><div x-data=tocHighlighter() @scroll.window=debouncedScroll class="hidden lg:flex lg:flex-col lg:items-end lg:self-start"><nav id=TableOfContents><ul><li><a href=#爬虫>爬虫</a></li></ul></nav></div></div><footer class="flex justify-between items-center gap-2 px-4 py-12"><div><p>© 2016 - 2025 Askyx's Blog</p><p class=text-sm>🌱
<span class=text-base-content/60>Powered by <a class=hover:underline href=https://gohugo.io/ target=_blank>Hugo</a> with theme
<a class=hover:underline href=https://github.com/g1eny0ung/hugo-theme-dream target=_blank>Dream</a>.</span></p></div><div x-data="{ icons: [
    { name: 'sunny', status: 'n' },
    { name: 'moon', status: 'y' },
    { name: 'desktop', status: 'auto' }
  ] }" class="flex items-center gap-2 h-[32px] px-2 bg-base-100 border border-base-content/30 rounded-full"><template x-for="icon in icons"><div role=button tabindex=0 :aria-label="'Select ' + icon.name + ' mode'" class="group inline-flex justify-center items-center p-1 rounded-full cursor-pointer hover:bg-primary" :class="$store.darkMode.icon() === icon.name && 'bg-primary'" @click=$store.darkMode.toggle(icon.status)><ion-icon :name="`${icon.name}-outline`" class=group-hover:text-primary-content :class="$store.darkMode.icon() === icon.name && 'text-primary-content'"></ion-icon></div></template></div></footer></div></div><div class=back><div class=container><div class="dream-grid dream-grid-about"><div class="w-full md:w-1/2 lg:w-1/3 xl:w-1/4 p-4 dream-column"><article class="card bg-base-100 hover:bg-base-content/10 shadow-xl dark:border dark:border-base-content/30"><div class=card-body><div class=card-title>About Me</div><div class="prose dark:prose-invert"><p>Hi, my name is Yue Yang.</p><p>This is my blog.</p><h2 id=ヾωo>ヾ(•ω•`)o</h2><p>比较胆小，出门都得贴墙走</p></div></div></article></div></div><footer class="flex justify-between items-center gap-2 px-4 py-12"><div><p>© 2016 - 2025 Askyx's Blog</p><p class=text-sm>🌱
<span class=text-base-content/60>Powered by <a class=hover:underline href=https://gohugo.io/ target=_blank>Hugo</a> with theme
<a class=hover:underline href=https://github.com/g1eny0ung/hugo-theme-dream target=_blank>Dream</a>.</span></p></div><div x-data="{ icons: [
    { name: 'sunny', status: 'n' },
    { name: 'moon', status: 'y' },
    { name: 'desktop', status: 'auto' }
  ] }" class="flex items-center gap-2 h-[32px] px-2 bg-base-100 border border-base-content/30 rounded-full"><template x-for="icon in icons"><div role=button tabindex=0 :aria-label="'Select ' + icon.name + ' mode'" class="group inline-flex justify-center items-center p-1 rounded-full cursor-pointer hover:bg-primary" :class="$store.darkMode.icon() === icon.name && 'bg-primary'" @click=$store.darkMode.toggle(icon.status)><ion-icon :name="`${icon.name}-outline`" class=group-hover:text-primary-content :class="$store.darkMode.icon() === icon.name && 'text-primary-content'"></ion-icon></div></template></div></footer></div></div></div></div><script>window.lightTheme="emerald",window.darkTheme="forest"</script><script src=https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin=anonymous></script><script src=https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin=anonymous></script><script src=/js/grid.min.js></script><script src=/js/main.min.js></script><script src=https://cdn.jsdelivr.net/npm/luxon@1.26.0 integrity="sha256-4sbTzmCCW9LGrIh5OsN8V5Pfdad1F1MwhLAOyXKnsE0=" crossorigin=anonymous></script><script>format();function format(){document.querySelectorAll('span[data-format="luxon"]').forEach(e=>{const t=e.textContent;e.textContent=luxon.DateTime.fromISO(t,{locale:"en"}).toFormat("yyyy年MM月dd日")})}</script><script src=/js/toc.min.js></script><script type=module>
      import mediumZoom from 'https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/+esm';
      mediumZoom('#dream-single-post-content img', {
        background: 'oklch(var(--b1))',
        margin: 24,
      })
    </script><script type=module src=https://cdn.jsdelivr.net/npm/ionicons@7.4.0/dist/ionicons/ionicons.esm.js integrity="sha256-/IFmi82bIhdYWctu0UddSlJqpnzWm7Vh2C4CM32wF/k=" crossorigin=anonymous></script><script nomodule src=https://cdn.jsdelivr.net/npm/ionicons@7.4.0/dist/ionicons/ionicons.js integrity="sha256-mr7eJMX3VC3F7G32mk4oWp1C6a2tlMYxUdptfT7uKI8=" crossorigin=anonymous></script></body></html>