<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>资源 on Asky</title><link>https://askyx.github.io/tags/%E8%B5%84%E6%BA%90/</link><description>Recent content in 资源 on Asky</description><generator>Hugo -- gohugo.io</generator><language>en</language><lastBuildDate>Wed, 20 Jul 2022 17:44:29 +0800</lastBuildDate><atom:link href="https://askyx.github.io/tags/%E8%B5%84%E6%BA%90/index.xml" rel="self" type="application/rss+xml"/><item><title>数据库文章资源汇总</title><link>https://askyx.github.io/posts/note/</link><pubDate>Wed, 20 Jul 2022 17:44:29 +0800</pubDate><guid>https://askyx.github.io/posts/note/</guid><description>
爬虫 # import requests from bs4 import BeautifulSoup prefix = &amp;#39;http://mysql.taobao.org&amp;#39; # 获取文章名和url（文章名,url） def query_name_url(url: str): resp = requests.get(url) soup = BeautifulSoup(resp.content.decode(&amp;#39;utf-8&amp;#39;), &amp;#34;html.parser&amp;#34;) tags = soup.findAll(&amp;#39;a&amp;#39;, {&amp;#39;target&amp;#39;: {&amp;#39;_top&amp;#39;}}) urls = [v for v in tags if v[&amp;#39;href&amp;#39;].find(&amp;#39;/monthly/&amp;#39;) != -1] return [(str(v.string).strip(), prefix + v[&amp;#39;href&amp;#39;]) for v in urls] # 获取所有月报链接（月报名,url） def query_monthly_url(): resp = requests.get(&amp;#39;http://mysql.taobao.org/monthly/&amp;#39;) soup = BeautifulSoup(resp.content.decode(&amp;#39;utf-8&amp;#39;), &amp;#34;html.parser&amp;#34;) tags = soup.findAll(&amp;#39;a&amp;#39;, {&amp;#39;class&amp;#39;: {&amp;#39;main&amp;#39;}}) urls = [v for v in tags if v[&amp;#39;href&amp;#39;].find(&amp;#39;/monthly/&amp;#39;) != -1] return [(str(v.string).strip(), prefix + v[&amp;#39;href&amp;#39;]) for v in urls] # 获取所有文章名、URL和对应的月报链接（文章类型，文章名，url，月报名，url） def query_all_name_url(): result = [] monthly_urls = query_monthly_url() for data1 in monthly_urls: name_urls = query_name_url(data1[1]) for data2 in name_urls: result.</description></item></channel></rss>